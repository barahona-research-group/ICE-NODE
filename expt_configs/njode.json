{
    "emb": {
        "dx": {
           "decoder_n_layers": 3,
           "classname":  "MatrixEmbeddings",      
           "embeddings_size": 200
        }
    },
    "model": {
        "ode_init_var": 1e-7,
        "timescale": 7,
        "ode_nlayers": 3
    },
    "training": {
        "batch_size": 128,
        "decay_rate": [0.5, 0.66],
        "lr": [1e-3,  1e-3],
        "epochs": 60,
        "reg_hyperparams": {
            "L_dyn": 1000.0,
            "L_l1": 0,
            "L_l2": 0
        },
        "tay_reg": 0,
        "opt": "adam",
        "classname": "ODETrainer2LR"
    }
}
