{
    "emb": {
        "dx": {
            "decoder_n_layers": 2,
             "classname": "GRAM", 
             "attention_size": 100,
             "attention_method": "tanh",
             "embeddings_size": 200,
             "glove_iterations": 200, 
             "cooc_window_size_days": 360
         }
    },
    "model": {
        "ode_dyn_label": "mlp3",
        "ode_init_var": 1e-07,
        "state_size": 30,
        "timescale": 30
    },
    "training": {
        "batch_size": 256,
        "epochs": 60,
        "decay_rate": [0.25, 0.33],
        "lr": [7e-5,  1e-3],
        "reg_hyperparams": {
            "L_dyn": 1000.0,
            "L_l1": 0,
            "L_l2": 0
        },
        "tay_reg": 3,
        "opt": "adam",
        "classname": "ODETrainer2LR"
    }
}
