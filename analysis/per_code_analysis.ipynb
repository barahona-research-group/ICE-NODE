{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effdb280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a58f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "HOME = os.environ.get('HOME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2769359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenode.train_icenode_2lr import ICENODE\n",
    "from icenode.train_icenode_uniform2lr import ICENODE as ICENODE_UNIFORM\n",
    "from icenode.train_gram import GRAM\n",
    "from icenode.train_retain import RETAIN\n",
    "from icenode.metrics import codes_auc_pairwise_tests\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79615e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyDict(dict):\n",
    "    def __getitem__(self, k):\n",
    "        v = super().__getitem__(k)\n",
    "        if callable(v):\n",
    "            v = v()\n",
    "            super().__setitem__(k, v)\n",
    "        return v\n",
    "\n",
    "    def get(self, k, default=None):\n",
    "        if k in self:\n",
    "            return self.__getitem__(k)\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from icenode.utils import load_config, load_params\n",
    "\n",
    "\n",
    "mimic_dir = {\n",
    "    'M3': f'{HOME}/GP/ehr-data/mimic3-transforms',\n",
    "    'M4': f'{HOME}/GP/ehr-data/mimic4-transforms'\n",
    "}\n",
    "\n",
    "trained_dir = {\n",
    "    'M3': f'{HOME}/GP/ehr-data/icenode-m3-exp/train_config_v0.2.25_M3',\n",
    "    'M4': f'{HOME}/GP/ehr-data/icenode-m4-exp/train_config_v0.2.25_M4'\n",
    "}\n",
    "\n",
    "model_dir = {\n",
    "    'ICENODE': 'icenode_2lr',\n",
    "    'ICENODE_UNIFORM': 'icenode_uniform2lr',\n",
    "    'GRU': 'gru',\n",
    "    'RETAIN': 'retain'\n",
    "}\n",
    "\n",
    "model_cls = {\n",
    "    'ICENODE': ICENODE,\n",
    "    'ICENODE_UNIFORM': ICENODE_UNIFORM,\n",
    "    'GRU': GRAM,\n",
    "    'RETAIN': RETAIN\n",
    "}   \n",
    "\n",
    "def get_trained_models(data_tag, clfs, criterion, comp):\n",
    "    params = {}\n",
    "    config = {}\n",
    "    clfs_params_dir = trained_dir[data_tag]\n",
    "    \n",
    "    for clf in clfs:\n",
    "        clf_dir = model_dir[clf]\n",
    "        csv_files =  glob.glob(f'{clfs_params_dir}/{clf_dir}/*.csv', recursive=False)\n",
    "        dfs = [pd.read_csv(csv_file, index_col=[0]) for csv_file in csv_files]\n",
    "        max_i = comp(range(len(dfs)), key=lambda i: dfs[i].loc[criterion, 'VAL'])\n",
    "        \n",
    "        print(f'{clf}@{max_i} {criterion}={dfs[max_i].loc[criterion, \"VAL\"]}')\n",
    "        csv_file = csv_files[max_i]\n",
    "        prefix = csv_file.split('_')\n",
    "        prefix[-1] = 'params.pickle'\n",
    "        params_file = '_'.join(prefix)\n",
    "        params[clf] = load_params(params_file)\n",
    "        config[clf] = load_config(f'{clfs_params_dir}/{clf_dir}/config.json')\n",
    "    return config, params\n",
    "\n",
    "def get_patient_interface(data_tag, clfs):\n",
    "    interface_by_kind = LazyDict({\n",
    "        'timestamped': lambda: ICENODE.create_patient_interface(mimic_dir[data_tag], data_tag),\n",
    "        'sequential': lambda: GRAM.create_patient_interface(mimic_dir[data_tag], data_tag)\n",
    "    })\n",
    "    \n",
    "    interface_kind = {\n",
    "        'ICENODE':  'timestamped',\n",
    "        'ICENODE_UNIFORM': 'timestamped',\n",
    "        'GRU': 'sequential',\n",
    "        'RETAIN': 'sequential'\n",
    "    }\n",
    "\n",
    "    return {clf: interface_by_kind[interface_kind[clf]] for clf in clfs}\n",
    "    \n",
    "\n",
    "clfs = (\n",
    "    'ICENODE', \n",
    "    'ICENODE_UNIFORM',\n",
    "    'GRU',\n",
    "    'RETAIN'\n",
    ")\n",
    "\n",
    "data_tag = 'M3'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c22807",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, params = get_trained_models(data_tag, clfs, 'MICRO-AUC', comp=max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b11dc3",
   "metadata": {},
   "source": [
    "## Patient Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72bd1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = get_patient_interface(data_tag, clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d6be67",
   "metadata": {},
   "source": [
    "## Dataset Partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4afdade",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, valid_ids, test_ids = interface[clfs[0]].random_splits(split1=0.7, split2=0.85, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb9e720",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2de48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_eval(clfs):\n",
    "    evals = {}\n",
    "    for clf in clfs:\n",
    "        model = model_cls[clf].create_model(config[clf], interface[clf], train_ids, None)\n",
    "        state = model.init_with_params(config[clf], params[clf])\n",
    "        evals[clf] = lambda ids: model.eval(state, ids)['diag_detectability']\n",
    "    return evals\n",
    "\n",
    "evals = get_model_eval(clfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339215b",
   "metadata": {},
   "source": [
    "## Per-code performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e30720",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res = {clf: eval_(test_ids) for clf, eval_ in evals.items()} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4894825",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_raw = codes_auc_pairwise_tests(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9da3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_raw_fast = codes_auc_pairwise_tests(test_res, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994b07dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ed90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_raw_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1008e623",
   "metadata": {},
   "source": [
    "## Correlation between AUC and N_POS_CODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c1ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests_raw_auc_corr = tests_raw[[f'AUC({clf})' for clf in test_res] + ['N_POSITIVE_CODES']]\n",
    "# sns.pairplot(tests_raw_auc_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41009df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatccs_idx2code = {idx: code for code, idx in m3_timestamped_interface.diag_flatccs_idx.items()}\n",
    "# idx2desc = lambda i: m3_timestamped_interface.dag.diag_flatccs_desc[flatccs_idx2code[i]]\n",
    "# tests_raw['DESC'] = tests_raw['CODE_INDEX'].apply(idx2desc)\n",
    "# tests_raw\n",
    "\n",
    "flatccs_idx2code = {idx: code for code, idx in m4_timestamped_interface.diag_flatccs_idx.items()}\n",
    "idx2desc = lambda i: m4_timestamped_interface.dag.diag_flatccs_desc[flatccs_idx2code[i]]\n",
    "tests_raw['DESC'] = tests_raw['CODE_INDEX'].apply(idx2desc)\n",
    "tests_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63040f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove codes that no classifier has scored above 0.7\n",
    "at_least_AUC_07 = tests_raw.loc[:,[f'AUC({clf})' for clf in test_res]].max(axis=1) > 0.7\n",
    "tests = tests_raw[at_least_AUC_07]\n",
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1aa9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tests.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc065c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "auc_sets = defaultdict(set)\n",
    "# clfs = tuple(sorted(m3_model.keys()))\n",
    "clfs = tuple(sorted(m4_model.keys()))\n",
    "\n",
    "clfs_pairs = []\n",
    "for i in range(len(clfs)):\n",
    "    for j in range(i + 1, len(clfs)):\n",
    "        clfs_pairs.append((clfs[i], clfs[j]))\n",
    "clfs_pairs = tuple(sorted(clfs_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3d472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract codes that are predicted with equivalent performance with all classifiers.\n",
    "test_cols = tuple(f'P0(AUC_{clf1}==AUC_{clf2})' for (clf1, clf2) in clfs_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_perf = tests[(tests[test_cols[0]] > 0.05) & (tests[test_cols[1]] > 0.05) & (tests[test_cols[2]] > 0.05)]\n",
    "auc_sets[clfs] = set(common_perf.CODE_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034eb546",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_tests = tests.drop(index=common_perf.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ae400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in competing_tests.iterrows():\n",
    "    max_auc_clf = max(clfs, key=lambda clf: row[f'AUC({clf})'])\n",
    "    relevant_tests = {(clf1, clf2): f'P0(AUC_{clf1}==AUC_{clf2})' for (clf1, clf2) in clfs_pairs if max_auc_clf in (clf1, clf2)}\n",
    "    \n",
    "    significant_max = True\n",
    "    for (clf1, clf2), test_col in relevant_tests.items():\n",
    "        # If max_auc_clf has maximum AUC, but without insigificant difference with another classifier\n",
    "        # then consider both outperforming the third classifier.\n",
    "        if row[test_col] > 0.05:\n",
    "            significant_max = False\n",
    "            auc_sets[(clf1, clf2)].add(int(row['CODE_INDEX']))\n",
    "    \n",
    "    if significant_max:\n",
    "        auc_sets[max_auc_clf].add(int(row['CODE_INDEX']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare for using Upset plot\n",
    "\n",
    "best_sets = {}\n",
    "for clf in clfs:\n",
    "    best_sets[clf] = auc_sets[clf] | auc_sets[clfs]\n",
    "    for clf1, clf2 in clfs_pairs:\n",
    "        if clf in (clf1, clf2):\n",
    "            best_sets[clf].update(auc_sets[(clf1, clf2)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9d5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from upsetplot import from_contents, plot, UpSet\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa089612",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_contents = from_contents(best_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a1db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "UpSet(upset_contents, subset_size='count', show_counts=True).plot()\n",
    "current_figure = plt.gcf()\n",
    "current_figure.savefig(\"auc_upset.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2da428",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_best_tests = {clf: competing_tests[competing_tests['CODE_INDEX'].isin(best_sets[clf])] for clf in clfs}\n",
    "model_exc_best_tests = {clf: competing_tests[competing_tests['CODE_INDEX'].isin(auc_sets[clf])] for clf in clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9d08b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for clf, best_tests in model_best_tests.items():\n",
    "    print(clf)\n",
    "    display(best_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ee969",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf, best_tests in model_exc_best_tests.items():\n",
    "    print(clf)\n",
    "    display(best_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0f5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_best_tests = model_best_tests['ICENODE']\n",
    "icenode_best_test_above07 = icenode_best_tests[icenode_best_tests['AUC(ICENODE)'] > 0.8]\n",
    "icenode_best_test_above07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca3ec0",
   "metadata": {},
   "source": [
    "## AUC Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc67052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = common_perf[['AUC(ICENODE)', 'DESC', 'VAR[AUC(ICENODE)]']].sort_values('AUC(ICENODE)')\n",
    "df = df[df['AUC(ICENODE)'] > 0.65]\n",
    "df.columns = ['AUC', 'CCS', 'VAR']\n",
    "error = df['VAR'].apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f53cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69151819",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,20))\n",
    "sns.set_theme()\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "\n",
    "ax = sns.barplot(x=\"AUC\", y=\"CCS\", color=\"salmon\", xerr=error*1,capsize=.2, data=df)\n",
    "# plt.title('ICE-NODE AUC on CCS Codes of Comparable AUC with GRU/RETAIN', fontsize=20)\n",
    "\n",
    "fig.tight_layout(pad=4)\n",
    "plt.xlabel('AUC', fontsize=24)\n",
    "plt.xlim(0.65, 1.0)\n",
    "plt.xticks(fontsize=20)\n",
    "\n",
    "plt.ylabel('CCS', fontsize=24)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "sns.despine(left=True)\n",
    "ax.grid(True)\n",
    "ax.tick_params(bottom=True, left=False)\n",
    "\n",
    "current_figure = plt.gcf()\n",
    "current_figure.savefig(\"common_performance.pdf\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8bacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_df = []\n",
    "comp_tests = competing_tests[competing_tests[[f'AUC({clf})' for clf in clfs]].max(axis=1) > 0.7]\n",
    "\n",
    "for clf in clfs:\n",
    "    comp_auc = comp_tests[f'AUC({clf})']\n",
    "    comp_var = comp_tests[f'VAR[AUC({clf})]']\n",
    "    comp_std = comp_var.apply(np.sqrt)\n",
    "    comp_desc = comp_tests['DESC'].apply(lambda t: t if len(t) < 15 else t[:14] + '...')\n",
    "    df = pd.DataFrame({'AUC': comp_auc, 'std': comp_std, 'CCS': comp_desc, 'Classifier': clf})\n",
    "    df = df.sort_values('AUC').reset_index(drop=True)\n",
    "    competing_df.append(df)\n",
    "\n",
    "competing_df = pd.concat(competing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b7423",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 15))\n",
    "sns.set_theme()\n",
    "sns.set_style(\"darkgrid\", {\"axes.facecolor\": \".9\"})\n",
    "colors = sns.xkcd_palette([\"windows blue\", \"amber\", \"greyish\"])\n",
    "\n",
    "ax = sns.barplot(x=\"AUC\", y=\"CCS\", hue='Classifier', palette =colors , data=competing_df)\n",
    "# plt.title('Performance of ICE-NODE/GRU/RETAIN', fontsize=40)\n",
    "\n",
    "fig.tight_layout(pad=10)\n",
    "plt.xlabel('AUC', fontsize=32)\n",
    "plt.xlim(0.5, 1.0)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "plt.ylabel('CCS', fontsize=36)\n",
    "plt.legend(fontsize='xx-large', title_fontsize='40')\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "sns.despine(left=True)\n",
    "ax.grid(True)\n",
    "ax.tick_params(bottom=True, left=False)\n",
    "current_figure = plt.gcf()\n",
    "current_figure.savefig(\"competing_performance.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c537e",
   "metadata": {},
   "source": [
    "## Trajectories for Patients with CCS codes best predicted with ICENODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a1b9ca",
   "metadata": {},
   "source": [
    "### Analyse AUC for Each Admission in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e771e1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode = ICENODE.create_model(config['ICENODE'], m4_interface['ICENODE'], m4_train_ids, None)\n",
    "icenode_state = icenode.init_with_params(config['ICENODE'], m4_params['ICENODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20e5e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_visit_auc_df = icenode.admissions_auc_scores(icenode_state, m4_test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ef671",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_visit_auc_df['N_VISITS'] = icenode_visit_auc_df['SUBJECT_ID'].apply(lambda i: (icenode_visit_auc_df['SUBJECT_ID'] == i).sum())\n",
    "icenode_visit_auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_auc_subject = icenode_visit_auc_df.groupby('SUBJECT_ID').agg({'AUC': 'mean', 'N_VISITS': 'max', 'N_CODES': ['min', 'max', 'mean', 'median'], 'INTERVALS': ['mean', 'max', 'min'], 'R/T': ['min', 'max', 'mean'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81032f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_visit_auc_subjects =  visit_auc_subject[(visit_auc_subject.AUC['mean'] > 0.85) & (visit_auc_subject.N_VISITS['max'] > 1) & (visit_auc_subject.N_VISITS['max'] <10) & (visit_auc_subject.INTERVALS['max'] < 90)]\n",
    "best_visit_auc_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e63979",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_history = {i: m4_interface['ICENODE'].diag_flatccs_history(i)[1] for i in best_visit_auc_subjects.index}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db32f613",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_history_icenode_best = {i: history for i, history in ccs_history.items() if len(set(history) & set(icenode_best_test_above07['CODE_INDEX']))> 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436007f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_history_icenode_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ecbed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ccs_history_icenode_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2f68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = icenode.sample_trajectory(icenode_state, ccs_history_icenode_best.keys(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956b3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ccs_index = list(icenode_best_test_above07['CODE_INDEX'])\n",
    "idx2desc = lambda idx: m4_interface['ICENODE'].dag.diag_flatccs_desc[flatccs_idx2code[idx]]\n",
    "ccs_description = list(map(idx2desc, ccs_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a92cf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i, traj in trajectory.items():\n",
    "    diag_times = m4_interface['ICENODE'].diag_times(i)\n",
    "    \n",
    "    t = traj['t']\n",
    "    d = traj['d']\n",
    "    \n",
    "    prob = []\n",
    "    time = []\n",
    "    code = []\n",
    "    \n",
    "    for ccs_desc, ccs_idx in zip(ccs_description, ccs_index):\n",
    "        time.append(t)\n",
    "        code.extend([ccs_desc]*len(t))\n",
    "        prob.append(d[:, ccs_idx])\n",
    "\n",
    "    prob = np.hstack(prob)\n",
    "    time = np.hstack(time)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({'t': time, r'$\\hat{v}$': prob, 'code': code})\n",
    "    data[i] = (df, diag_times)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5d747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "import math\n",
    "for i, (df, diag_times) in data.items():\n",
    "\n",
    "    plt.figure(i)\n",
    "    \n",
    "    g = sns.lineplot(data=df, x=\"t\", y=r'$\\hat{v}$', hue='code', marker='o')\n",
    "    for diag_time in diag_times:\n",
    "        g.axvline(x=diag_time, ymin=0, ymax=1, c=\"red\", ls='--', linewidth=0.8, zorder=0, clip_on=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39601f70",
   "metadata": {},
   "source": [
    "It seems that we cannot catch the smoothness of the trajectory as it evolves very quickly to the saturation value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a6db6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
