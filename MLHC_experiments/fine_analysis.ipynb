{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f4d3c",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "<a name=\"outline\"></a>\n",
    "\n",
    "## Setup\n",
    "\n",
    "- [A](#seca) External Imports\n",
    "- [B](#secb) Internal Imports\n",
    "- [C](#secc) Lazy Dictionary (Lazy Caching)\n",
    "- [D](#secd) Configurations and Paths \n",
    "- [E](#sece) Patient Interface and Train/Val/Test Partitioning\n",
    "- [F](#secf) General Utility Functions\n",
    "\n",
    "\n",
    "## Evaluations\n",
    "\n",
    "- [1](#sec1) Performance Analysis for Training/Testing on MIMIC-III\n",
    "- [2](#sec2) Performance Analysis for Training/Testing on MIMIC-IV\n",
    "- [3](#sec3) Performance Analysis for Training on MIMIC-IV and Testing on MIMIC-III\n",
    "- [4](#sec4) Risk Trajectories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a491c",
   "metadata": {},
   "source": [
    "<a name=\"seca\"></a>\n",
    "\n",
    "### A External Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import from_contents, plot, UpSet, from_indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0d568",
   "metadata": {},
   "source": [
    "<a name=\"secb\"></a>\n",
    "\n",
    "### B Internal Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sys.path.append('..')\n",
    "sys.path.append('repo')\n",
    "from icenode.train_icenode_2lr import ICENODE\n",
    "from icenode.train_icenode_uniform2lr import ICENODE as ICENODE_UNIFORM\n",
    "from icenode.train_gram import GRAM\n",
    "from icenode.train_retain import RETAIN\n",
    "from icenode.metrics import codes_auc_pairwise_tests\n",
    "from icenode.metrics import evaluation_table\n",
    "from icenode.utils import write_params, load_config, load_params\n",
    "\n",
    "\n",
    "from icenode.mimic3.dag import CCSDAG\n",
    "from icenode.mimic3.concept import DiagSubject\n",
    "from icenode.jax_interface import SubjectDiagSequenceJAXInterface,  DiagnosisJAXInterface \n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9340794",
   "metadata": {},
   "source": [
    "<a name=\"secd\"></a>\n",
    "\n",
    "### D Configurations and Paths [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d78296",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic3_files = {\n",
    "    'adm_df': 'data/mimic3_adm_df.csv.gz',\n",
    "    'diag_df': 'data/mimic3_diag_df.csv.gz'\n",
    "}\n",
    "\n",
    "mimic4_files = {\n",
    "    'adm_df': 'data/mimic4_adm_df.csv.gz',\n",
    "    'diag_df': 'data/mimic4_diag_df.csv.gz'\n",
    "}\n",
    "\n",
    "m3_trained_dir = {\n",
    "    'ICE-NODE': 'pretrained_models/M3/icenode',\n",
    "    'ICE-NODE_UNIFORM': 'pretrained_models/M3/icenode_uniform',\n",
    "    'GRU': 'pretrained_models/M3/gru',\n",
    "    'RETAIN': 'pretrained_models/M3/retain'\n",
    "}\n",
    "\n",
    "m4_trained_dir = {\n",
    "    'ICE-NODE': 'pretrained_models/M4/icenode',\n",
    "    'ICE-NODE_UNIFORM': 'pretrained_models/M4/icenode_uniform',\n",
    "    'GRU': 'pretrained_models/M4/gru',\n",
    "    'RETAIN': 'pretrained_models/M4/retain'\n",
    "}\n",
    "\n",
    "model_cls = {\n",
    "    'ICE-NODE': ICENODE,\n",
    "    'ICE-NODE_UNIFORM': ICENODE_UNIFORM,\n",
    "    'GRU': GRAM,\n",
    "    'RETAIN': RETAIN\n",
    "}   \n",
    "\n",
    "# Same configurations for models between MIMIC-III and MIMIC-IV.\n",
    "model_config = {\n",
    "    clf: load_config(f'{m_dir}/config.json') for clf, m_dir in m3_trained_dir.items()\n",
    "}\n",
    "\n",
    "clfs = list(m3_trained_dir.keys())\n",
    "\n",
    "relative_auc_config = {\n",
    "    'pvalue': 0.01, \n",
    "    'min_auc': 0.9\n",
    "}\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Loma\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d26707",
   "metadata": {},
   "source": [
    "<a name=\"sece\"></a>\n",
    "\n",
    "### E Patient Interface and Train/Val/Test Patitioning [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c24ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_interface(mimic_files, clfs):\n",
    "    adm_df = pd.read_csv(mimic_files['adm_df'])\n",
    "    diag_df = pd.read_csv(mimic_files['diag_df'], dtype={'ICD9_CODE': str})\n",
    "    # Cast columns of dates to datetime64\n",
    "    adm_df['ADMITTIME'] = pd.to_datetime(adm_df['ADMITTIME'], infer_datetime_format=True).dt.normalize()\n",
    "    adm_df['DISCHTIME'] = pd.to_datetime(adm_df['DISCHTIME'], infer_datetime_format=True).dt.normalize()\n",
    "\n",
    "    # From the DataFrame representation to List[Subject] representation.\n",
    "    subjects = DiagSubject.to_list(adm_df, diag_df)\n",
    "    \n",
    "    # The coding scheme of CCS\n",
    "    ccs_dag = CCSDAG()\n",
    "    \n",
    "    # JAX vectorisation of subjects.\n",
    "    interface_by_kind =  {\n",
    "        'timestamped': DiagnosisJAXInterface(subjects, ccs_dag),\n",
    "        'sequential': SubjectDiagSequenceJAXInterface(subjects, ccs_dag)\n",
    "    }\n",
    "    \n",
    "    interface_kind = {\n",
    "        'ICE-NODE':  'timestamped',\n",
    "        'ICE-NODE_UNIFORM': 'timestamped',\n",
    "        'GRU': 'sequential',\n",
    "        'RETAIN': 'sequential'\n",
    "    }\n",
    "\n",
    "    return {clf: interface_by_kind[interface_kind[clf]] for clf in clfs}\n",
    "    \n",
    "    \n",
    "m4_interface = get_patient_interface(mimic4_files, clfs)\n",
    "m3_interface = get_patient_interface(mimic3_files, clfs)\n",
    "\n",
    "m4_train_ids, m4_valid_ids, m4_test_ids = m4_interface[clfs[0]].random_splits(split1=0.7, split2=0.85, random_seed=42)\n",
    "m3_train_ids, m3_valid_ids, m3_test_ids = m3_interface[clfs[0]].random_splits(split1=0.7, split2=0.85, random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_percentiles = m4_interface[clfs[0]].diag_flatccs_by_percentiles(20)\n",
    "m3_percentiles = m3_interface[clfs[0]].diag_flatccs_by_percentiles(20)\n",
    "\n",
    "m4_train_percentiles = m4_interface[clfs[0]].diag_flatccs_by_percentiles(20, m4_train_ids)\n",
    "m3_train_percentiles = m3_interface[clfs[0]].diag_flatccs_by_percentiles(20, m3_train_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a27d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_params = {clf: load_params(f'{m3_trained_dir[clf]}/params.pickle') for clf in clfs}\n",
    "\n",
    "m4_params = {clf: load_params(f'{m4_trained_dir[clf]}/params.pickle') for clf in clfs}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085bb85c",
   "metadata": {},
   "source": [
    "<a name=\"secf\"></a>\n",
    "\n",
    "### F Utility Functions [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63239443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_(model, ids):\n",
    "    model, state = model\n",
    "    return model.eval(state, ids)['diag_detectability']\n",
    "\n",
    "def eval2_(model, ids):\n",
    "    model, state = model\n",
    "    return model.eval(state, ids)\n",
    "\n",
    "def test_eval_table(dfs, metric):\n",
    "    data = {}\n",
    "    clfs = dfs.keys()\n",
    "    for clf, df in dfs.items():\n",
    "        data[clf] = df.loc[metric, \"TST\"].tolist()\n",
    "    return pd.DataFrame(data=data, index=metric).transpose()\n",
    "\n",
    "def get_model(clf, config, params, interface):\n",
    "    model = model_cls[clf].create_model(config, interface, [], None)\n",
    "    state = model.init_with_params(config, params)\n",
    "    return model, state\n",
    "        \n",
    "def get_models(clfs, config, params, interface):\n",
    "    return {clf: get_model(clf, config[clf], params[clf], interface[clf]) for clf in clfs}\n",
    "\n",
    "def cross_predictor(clf, source_tag, target_tag):   \n",
    "    _params = {'M3': m3_params[clf],\n",
    "               'M4': m4_params[clf]}\n",
    "\n",
    "    _interface = {'M3': m3_interface[clf],\n",
    "                  'M4': m4_interface[clf]}\n",
    "        \n",
    "    return get_model(clf, model_config[clf], _params[source_tag], _interface[target_tag])\n",
    "            \n",
    "    \n",
    "def selected_auc_barplot(clfs, auctest_df, horizontal=False, rotate_ccs=True):\n",
    "    \n",
    "    clfs = sorted(clfs)\n",
    "    auc_df = []\n",
    "\n",
    "    for clf in clfs:\n",
    "        comp_auc = auctest_df[f'AUC({clf})']\n",
    "        comp_var = auctest_df[f'VAR[AUC({clf})]']\n",
    "        comp_std = comp_var.apply(np.sqrt)\n",
    "        comp_desc = auctest_df['DESC'].apply(lambda t: t if len(t) < 15 else t.replace(' ', '\\n'))\n",
    "        df = pd.DataFrame({'AUC': comp_auc, 'std': comp_std, 'CCS': comp_desc, 'Classifier': clf})\n",
    "        auc_df.append(df)\n",
    "    auc_df = pd.concat(auc_df)\n",
    "    \n",
    "    min_auc_tick = int(auc_df['AUC'].min() * 20)/20\n",
    "    max_auc_tick = int(auc_df['AUC'].max() * 20 + 1)/20\n",
    "    \n",
    "    vals = auc_df.pivot(index='CCS', columns='Classifier', values='AUC')\n",
    "    err = auc_df.pivot(index='CCS', columns='Classifier', values='std')\n",
    "    \n",
    "    icenode_idx = clfs.index('ICE-NODE')\n",
    "\n",
    "    \n",
    "    colors = ['green', 'gray', 'skyblue', 'brown', 'purple', 'navy', 'pink']\n",
    "    patterns = ['o',    '',     '+',       '',      '',       '',     '/']\n",
    "    patterns[icenode_idx] = 'x'\n",
    "\n",
    "    colors[icenode_idx] = 'white'\n",
    "    \n",
    "    pltbarconf = dict(rot=0, figsize=(10, 10), width=0.7,\n",
    "                      error_kw=dict(lw=5, capsize=8, capthick=5, ecolor='salmon'),\n",
    "                      color=colors, \n",
    "                      edgecolor='black') \n",
    "    if horizontal:\n",
    "        # plot vals with yerr\n",
    "        ax = vals.plot.barh(xerr=err, **pltbarconf)\n",
    "        plt.xlabel('AUC', fontsize=32)\n",
    "        plt.xticks(fontsize=30)    \n",
    "        plt.xlim(min_auc_tick, max_auc_tick)\n",
    "\n",
    "        xstart, xend = ax.get_xlim()\n",
    "        ax.xaxis.set_ticks(np.arange(xstart, xend+0.01, 0.05))\n",
    "\n",
    "        plt.yticks(fontsize=24)\n",
    "\n",
    "        plt.ylabel(None)\n",
    "        ax.tick_params(bottom=True, left=False) \n",
    "        \n",
    "        ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "        ax.xaxis.set_zorder(3)\n",
    "\n",
    "\n",
    "        \n",
    "    else:\n",
    "        # plot vals with yerr\n",
    "        ax = vals.plot.bar(yerr=err, **pltbarconf)\n",
    "        plt.ylabel('AUC', fontsize=32)\n",
    "        plt.yticks(fontsize=24)    \n",
    "        plt.ylim(min_auc_tick, max_auc_tick)\n",
    "\n",
    "        ystart, yend = ax.get_ylim()\n",
    "        ax.yaxis.set_ticks(np.arange(ystart, yend+0.01, 0.05))\n",
    "\n",
    "        plt.xticks(fontsize=30, rotation=90 * rotate_ccs)\n",
    "\n",
    "        plt.xlabel(None)\n",
    "        ax.tick_params(bottom=False, left=True) \n",
    "        \n",
    "        ax.yaxis.grid(color='gray', linestyle='dashed')\n",
    "        ax.yaxis.set_zorder(3)\n",
    "        \n",
    "    for axis in ['top', 'bottom', 'left', 'right']:\n",
    "        ax.spines[axis].set_linewidth(6)  # change width\n",
    "        ax.spines[axis].set_color('red')    # change color\n",
    "\n",
    "\n",
    "\n",
    "    # Add hatches\n",
    "#     patterns =('.', 'x', 'O','o','/','-', '+','O','o','\\\\','\\\\\\\\')\n",
    "    bars = ax.patches\n",
    "\n",
    "    hatches = [p for p in patterns for i in range(len(df))]\n",
    "    for bar, hatch in zip(bars, hatches):\n",
    "        bar.set_hatch(hatch)\n",
    "    \n",
    "    _ = ax.legend(loc='upper right',  fontsize=22)\n",
    "    return ax\n",
    "\n",
    "def make_clf_paris(clfs):\n",
    "    clfs_pairs = []\n",
    "    for i in range(len(clfs)):\n",
    "        for j in range(i + 1, len(clfs)):\n",
    "            clfs_pairs.append((clfs[i], clfs[j]))\n",
    "    return tuple(sorted(clfs_pairs))\n",
    "    \n",
    "def relative_performance_upset(auc_tests, selected_clfs, patient_interface, train_ids, pvalue, min_auc):\n",
    "    flatccs_idx2code = {idx: code for code, idx in patient_interface.diag_flatccs_idx.items()}\n",
    "    flatccs_frequency_train = patient_interface.diag_flatccs_frequency(train_ids)\n",
    "    \n",
    "    idx2desc = lambda i: patient_interface.dag.diag_flatccs_desc[flatccs_idx2code[i]]\n",
    "    auc_tests['DESC'] = auc_tests['CODE_INDEX'].apply(idx2desc)\n",
    "    \n",
    "    # remove codes that no classifier has scored above `min_auc`\n",
    "    accepted_aucs = auc_tests.loc[:,[f'AUC({clf})' for clf in selected_clfs]].max(axis=1) > min_auc\n",
    "    accepted_auc_tests = auc_tests[accepted_aucs]\n",
    "    print(f'{len(accepted_auc_tests)} codes predicted an AUC higher than {min_auc} by at least one model.')\n",
    "    \n",
    "    test_cols = [col for col in auc_tests.columns if col[:2] == 'P0']\n",
    "\n",
    "    # exclude tests with nans\n",
    "    accepted_auc_tests = accepted_auc_tests[accepted_auc_tests.loc[:,test_cols].isnull().max(axis=1) == 0]\n",
    "    \n",
    "    print(f'{len(accepted_auc_tests)} codes predicted an AUC higher than {min_auc} by at least one model, with valid tests.')\n",
    "    \n",
    "    tests = accepted_auc_tests\n",
    "    \n",
    "    # Codes when no significant difference of AUCs among all pairs of models.\n",
    "    common_perf = tests[tests.loc[:,test_cols].min(axis=1) > pvalue]\n",
    "    \n",
    "    \n",
    "    auc_sets = defaultdict(set)\n",
    "    clfs = tuple(sorted(selected_clfs))\n",
    "    auc_sets[clfs] = set(common_perf.CODE_INDEX)\n",
    "    competing_tests = tests.drop(index=common_perf.index)\n",
    "\n",
    "    clfs_pairs = make_clf_paris(clfs)\n",
    "\n",
    "    # Assign each code to the best model (max AUC), then assign it as well \n",
    "    # to any model with no significant difference with the best.\n",
    "    for index, row in competing_tests.iterrows():\n",
    "        max_auc_clf = max(clfs, key=lambda clf: row[f'AUC({clf})'])\n",
    "        insignificant_diff = {(clf1, clf2): f'P0(AUC_{clf1}==AUC_{clf2})' for (clf1, clf2) in clfs_pairs \\\n",
    "                          if max_auc_clf in (clf1, clf2) and row[f'P0(AUC_{clf1}==AUC_{clf2})'] > pvalue}\n",
    "\n",
    "        # Case 1: The best model is significantly outperforming all others.\n",
    "        if len(insignificant_diff) == 0:\n",
    "            auc_sets[max_auc_clf].add(int(row['CODE_INDEX']))\n",
    "        # Case 2: Some insigificant difference with others though.\n",
    "        else:\n",
    "            for (clf1, clf2), test_col in insignificant_diff.items():\n",
    "                # Populate the intersections.\n",
    "                auc_sets[(clf1, clf2)].add(int(row['CODE_INDEX']))            \n",
    "            \n",
    "    # Prepare for using Upset plot -> Set Layout (passed to `from_contents`)\n",
    "    content_sets = {}\n",
    "    for clf in clfs:\n",
    "        content_sets[clf] = auc_sets[clf] | auc_sets[clfs]\n",
    "        for clf1, clf2 in clfs_pairs:\n",
    "            if clf in (clf1, clf2):\n",
    "                content_sets[clf].update(auc_sets[(clf1, clf2)])\n",
    "    \n",
    "    # Prepare for using Upset plot -> DataFrame Layout (passed to `from_indicators`)\n",
    "    code_index = tests.CODE_INDEX.tolist()\n",
    "    competence_assignments = {}\n",
    "    for clf in clfs:\n",
    "        competence_assignments[clf] = [c in content_sets[clf] for c in code_index]\n",
    "    indicator_df = pd.DataFrame(competence_assignments, index=code_index)\n",
    "    \n",
    "    # Descriptive statistics for each code.    \n",
    "    avg_aucs, n_codes = [], []\n",
    "    for c in code_index:\n",
    "        competent_clfs = [clf for clf in clfs if indicator_df.loc[c, clf]]\n",
    "        avg_auc = tests.loc[c, list(f'AUC({clf})' for clf in competent_clfs)].mean()\n",
    "        avg_aucs.append(avg_auc)\n",
    "        n_codes.append(flatccs_frequency_train[c])\n",
    "    data = pd.DataFrame({'Avg. AUC': avg_aucs, '#codes (train)': n_codes}, index=code_index)    \n",
    "    return content_sets, indicator_df, data, common_perf, competing_tests\n",
    "\n",
    "\n",
    "def styled_df(df):  \n",
    "    pd.set_option('precision', 3)\n",
    "    def highlight_max(s, props=''):\n",
    "        return np.where(s == np.nanmax(s.values), props, '')\n",
    "    \n",
    "    s_df = df.style\n",
    "    s_df = s_df.apply(highlight_max, props='bfseries: ;color:white;background-color:darkblue', axis=0)\n",
    "    texttt = [{'selector': 'th', 'props': 'font-family: monospace;'}]\n",
    "\n",
    "    latex_str = s_df.to_latex(convert_css=True)\n",
    "    for clf in df.index.tolist():\n",
    "        latex_str = latex_str.replace(clf, f'\\\\texttt{{{clf}}}', 1)\n",
    "    latex_str = latex_str.replace('_', '\\\\_')\n",
    "    return s_df, latex_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6323308",
   "metadata": {},
   "source": [
    "<a name=\"sec1\"></a>\n",
    "\n",
    "## 1 Performance Analysis for Training/Testing on MIMIC-III [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "m3_predictors = {clf: cross_predictor(clf, 'M3', 'M3') for clf in m3_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m3 = {clf: eval2_(model, m3_test_ids) for clf, model in m3_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f74ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m3 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m3.items()}, fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = [col for col in auctests_m3.columns if col[:2] == 'P0']\n",
    "auctests_m3.loc[:, test_cols].isnull().max(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee80b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upset_clfs = ['ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN']\n",
    "upsetcontents_m3, upsetindicator_m3, data_m3,  _, compete_codesm3 = relative_performance_upset(auctests_m3, \n",
    "                                                                                               upset_clfs, \n",
    "                                                                                               m3_interface[clfs[0]],\n",
    "                                                                                               m3_train_ids,\n",
    "                                                                                               **relative_auc_config)\n",
    "\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\", font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m3, data=data_m3)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(max_subset_size=1,\n",
    "                               facecolor=\"red\",\n",
    "                               edgecolor=\"red\", linewidth=3)\n",
    "    g = upset_object.plot()\n",
    "\n",
    "    current_figure = plt.gcf()\n",
    "    w, h = 3.5, 3\n",
    "    wi, hi = current_figure.get_size_inches()\n",
    "    current_figure.set_size_inches(hi*(w/h), hi)\n",
    "    current_figure.savefig(f\"upset_M3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m3_k15, _ = evaluation_table(test_res_m3, m3_train_percentiles, top_k=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc15 = results_m3_k15.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc15 = df_acc15.apply(lambda x: round(x, 3))\n",
    "df_acc15.to_csv(f'acc15_mimic3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc15)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_tests_df = auctests_m3[auctests_m3.CODE_INDEX.isin(upsetindicator_m3[upsetindicator_m3.sum(axis=1)<len(m3_clfs)].index)]\n",
    "competing_tests_df.loc[:, [col for col in competing_tests_df.columns if col[:2]=='P0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ['ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN']#, 'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G']\n",
    "\n",
    "ax = selected_auc_barplot(upset_clfs, competing_tests_df,  horizontal=True)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(-0.02, 1), ncol=2)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "current_figure = plt.gcf()\n",
    "w, h = 4, 4\n",
    "wi, hi = current_figure.get_size_inches()\n",
    "current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "current_figure.savefig(\"icenode_m3.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d43833",
   "metadata": {},
   "source": [
    "<a name=\"sec2\"></a>\n",
    "\n",
    "## 2 Performance Analysis for Training/Testing on MIMIC-IV [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "m4_predictors = {clf: cross_predictor(clf, 'M4', 'M4') for clf in m4_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m4 = {clf: eval2_(model, m4_test_ids) for clf, model in m4_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m4 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m4.items()}, fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "\n",
    "upsetcontents_m4, upsetindicator_m4, data_m4,  _, compete_codesm4 = relative_performance_upset(auctests_m4, \n",
    "                                                                                               upset_clfs, \n",
    "                                                                                               m4_interface[clfs[0]], \n",
    "                                                                                               m4_train_ids,\n",
    "                                                                                               **relative_auc_config)\n",
    "\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\",  font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m4, data=data_m4)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(present=['ICE-NODE'], absent=('ICE-NODE_UNIFORM', 'GRU', 'RETAIN'),\n",
    "                               edgecolor=\"red\", linewidth=3, facecolor=\"red\")\n",
    "#     upset_object.add_catplot(value='#codes (train)', kind=\"strip\")\n",
    "\n",
    "    g = upset_object.plot()\n",
    "#     g['extra1'].set_yscale('log')\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    w, h = 5, 3\n",
    "    wi, hi = current_figure.get_size_inches()\n",
    "    current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "    current_figure.savefig(f\"upset_M4.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec332ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_k15, _ = evaluation_table(test_res_m4, m4_train_percentiles, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8714f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc15 = results_m4_k15.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc15 = df_acc15.apply(lambda x: round(x, 3))\n",
    "df_acc15.to_csv(f'acc15_mimic4.csv')\n",
    "s_df, ltx_s = styled_df(df_acc15)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4_excl = upsetcontents_m4['ICE-NODE'] - set.union(*list(upsetcontents_m4[clf] for clf in ('RETAIN', 'GRU', 'ICE-NODE_UNIFORM')))\n",
    "icenode_m4_excl = compete_codesm4[compete_codesm4['CODE_INDEX'].isin(icenode_m4_excl)]\n",
    "icenode_m4_excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22935ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "w, h = 4, 3\n",
    "ax = selected_auc_barplot(upset_clfs, icenode_m4_excl, horizontal=True)\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(-0.02, 1), ncol=2)\n",
    "current_figure = plt.gcf()\n",
    "w, h = 4, 4\n",
    "wi, hi = current_figure.get_size_inches()\n",
    "current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "current_figure.savefig(\"icenode_m4.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7e699",
   "metadata": {},
   "source": [
    "<a name=\"sec3\"></a>\n",
    "\n",
    "## 3 Performance Analysis for Training on MIMIC-IV and Testing on MIMIC-III [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "\n",
    "m3_subjects = list(m3_interface[clfs[0]].subjects.keys())\n",
    "m4m3_predictors = {clf: cross_predictor(clf, 'M4', 'M3') for clf in m4m3_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2555b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m4m3 = {clf: eval2_(model, m3_subjects) for clf, model in m4m3_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06aac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m4m3 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m4m3.items()}, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "\n",
    "# upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "#                 'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "\n",
    "upsetcontents_m4m3, upsetindicator_m4m3, data_m4m3,  _, compete_codesm4m3 = relative_performance_upset(auctests_m4m3, \n",
    "                                                                                                       upset_clfs, \n",
    "                                                                                                       m4_interface[clfs[0]],\n",
    "                                                                                                       m4_train_ids,\n",
    "                                                                                                       **relative_auc_config)\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\", font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m4m3, data=data_m4m3)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(present='ICE-NODE', absent=['ICE-NODE_UNIFORM', 'GRU', 'RETAIN'],\n",
    "                              edgecolor=\"red\", facecolor=\"red\")\n",
    "    # upset_object.add_catplot(value='Avg. AUC', kind=\"strip\")\n",
    "#     upset_object.add_catplot(value='#codes (train)', kind=\"strip\")\n",
    "    g = upset_object.plot()\n",
    "#     g['extra1'].set_yscale('log')\n",
    "\n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"upset_M4M3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c06568",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4m3_excl = upsetcontents_m4m3['ICE-NODE'] - set.union(*list(upsetcontents_m4m3[clf] for clf in ('RETAIN', 'GRU', 'ICE-NODE_UNIFORM')))\n",
    "icenode_m4m3_excl = compete_codesm4m3[compete_codesm4m3['CODE_INDEX'].isin(icenode_m4m3_excl)]\n",
    "icenode_m4m3_excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f942b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = selected_auc_barplot(upset_clfs, icenode_m4m3_excl, horizontal=True)\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "# ax.legend(fontsize=22, title_fontsize=32,\n",
    "#           bbox_to_anchor=(0.02, 1), ncol=2)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(1, 1.17), ncol=2)\n",
    "\n",
    "current_figure = plt.gcf()\n",
    "current_figure.savefig(\"icenode_m4m3.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86634c4c",
   "metadata": {},
   "source": [
    "<a name=\"sec4\"></a>\n",
    "\n",
    "## 4 Risk Trajectories [^](#outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc4c29",
   "metadata": {},
   "source": [
    "### Analyse AUC for Each Admission in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df33d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def admissions_auc_scores(model, test_ids):\n",
    "    model, state = model\n",
    "    return model.admissions_auc_scores(state, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatccs_idx2code = {idx: code for code, idx in m4_interface[clfs[0]].diag_flatccs_idx.items()}\n",
    "flatccs_code2idx = m4_interface[clfs[0]].diag_flatccs_idx\n",
    "idx2desc = lambda idx: m4_interface[clfs[0]].dag.diag_flatccs_desc[flatccs_idx2code[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode_visit_auc_df = admissions_auc_scores(m4_predictors['ICE-NODE'], m4_test_ids)\n",
    "m4_icenode_visit_auc_df['N_VISITS'] = m4_icenode_visit_auc_df['SUBJECT_ID'].apply(lambda i: (m4_icenode_visit_auc_df['SUBJECT_ID'] == i).sum())\n",
    "m4_visit_auc_subject = m4_icenode_visit_auc_df.groupby('SUBJECT_ID').agg({'AUC': 'mean', 'N_VISITS': 'max', 'N_CODES': ['min', 'max', 'mean', 'median'], 'INTERVALS': ['mean', 'max', 'min'], 'R/T': ['min', 'max', 'mean'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_icenode_visit_auc_df = admissions_auc_scores(m4m3_predictors['ICE-NODE'], m3_interface[clfs[0]].subjects.keys())\n",
    "m4m3_icenode_visit_auc_df['N_VISITS'] = m4m3_icenode_visit_auc_df['SUBJECT_ID'].apply(lambda i: (m4m3_icenode_visit_auc_df['SUBJECT_ID'] == i).sum())\n",
    "m4m3_visit_auc_subject = m4m3_icenode_visit_auc_df.groupby('SUBJECT_ID').agg({'AUC': 'mean', 'N_VISITS': 'max', 'N_CODES': ['min', 'max', 'mean', 'median'], 'INTERVALS': ['mean', 'max', 'min'], 'R/T': ['min', 'max', 'mean'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ed05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_best_visit_auc_subjects =  m4_visit_auc_subject[(m4_visit_auc_subject.N_VISITS['max'] > 2) & (m4_visit_auc_subject.INTERVALS['max'] < 150)]\n",
    "m4m3_best_visit_auc_subjects =  m4m3_visit_auc_subject[(m4m3_visit_auc_subject.N_VISITS['max'] > 1) & (m4m3_visit_auc_subject.INTERVALS['max'] < 150)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429952cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m4_best_visit_auc_subjects), len(m4m3_best_visit_auc_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfcd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_ccs_history = {i: m4_interface[clfs[0]].diag_flatccs_history(i) for i in m4_best_visit_auc_subjects.index}\n",
    "m4m3_ccs_history = {i: m3_interface[clfs[0]].diag_flatccs_history(i) for i in m4m3_best_visit_auc_subjects.index}\n",
    "\n",
    "m4_ccs_idx_frequency = m4_interface[clfs[0]].diag_flatccs_frequency(list(m4_best_visit_auc_subjects.index))\n",
    "m3_ccs_idx_frequency = m3_interface[clfs[0]].diag_flatccs_frequency(list(m4m3_best_visit_auc_subjects.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_history_all_ccs_codes = set(map(flatccs_code2idx.get, set.union(*[set(h.keys()) for h in m4_ccs_history.values()])))\n",
    "m3_history_all_ccs_codes = set(map(flatccs_code2idx.get, set.union(*[set(h.keys()) for h in m4m3_ccs_history.values()])))\n",
    "m4_history_all_ccs_codes = {idx for idx in m4_history_all_ccs_codes if m4_ccs_idx_frequency[idx] < 10}\n",
    "m3_history_all_ccs_codes = {idx for idx in m3_history_all_ccs_codes if m3_ccs_idx_frequency[idx] < 10}\n",
    "\n",
    "len(m4_history_all_ccs_codes), len(m3_history_all_ccs_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4_competent = upsetcontents_m4['ICE-NODE'] \n",
    "icenode_m4_competent = auctests_m4[auctests_m4['CODE_INDEX'].isin(icenode_m4_competent)]\n",
    "icenode_m4_competent = icenode_m4_competent[['N_POSITIVE_CODES', 'AUC(ICE-NODE)', 'DESC']].sort_values('N_POSITIVE_CODES',ascending=False)\n",
    "# icenode_m4_competent.head(50)\n",
    "trajectory_ccs_codes_level2 = [\n",
    "    173, 168, 169, 156, 165, 216, 171, 100, 167\n",
    "]\n",
    "icenode_m4_competent[icenode_m4_competent.index.isin(trajectory_ccs_codes_level2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_ccs_codes_level1 = [\n",
    "    64, #renal fail \n",
    "    6, # pulm heart dx\n",
    "    236, # ear dx \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6524fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_ccs_history_level1 = {i: history for i, history in m4_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level1)) & set(history.keys())) > 0}\n",
    "m4m3_ccs_history_level1 = {i: history for i, history in m4m3_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level1)) & set(history.keys())) > 0}\n",
    "\n",
    "m4_ccs_history_level2 = {i: history for i, history in m4_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level2)) & set(history.keys())) > 0}\n",
    "m4m3_ccs_history_level2 = {i: history for i, history in m4m3_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level2)) & set(history.keys())) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m4_ccs_history_level1), len(m4m3_ccs_history_level1), len(m4_ccs_history_level2), len(m4m3_ccs_history_level2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b952bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_cases = set(m4_ccs_history_level1.keys()) | set(m4_ccs_history_level2.keys())\n",
    "m4m3_cases = set(m4m3_ccs_history_level1.keys()) | set(m4m3_ccs_history_level2.keys())\n",
    "len(m4_cases), len(m4m3_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode, m4_icenode_state = m4_predictors['ICE-NODE']\n",
    "m4_trajectory = m4_icenode.sample_trajectory(m4_icenode_state, m4_cases, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_icenode, m4m3_icenode_state = m4m3_predictors['ICE-NODE']\n",
    "m4m3_trajectory = m4m3_icenode.sample_trajectory(m4m3_icenode_state, m4m3_cases, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eef088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4_selected_subjects = [\n",
    "#     13798593, #acute-renal\n",
    "#     13965528, #acute-renal\n",
    "#     11907876, #pulmonary heart dx\n",
    "#     13557547, #ear dx\n",
    "#     10139504, #acute renal fail\n",
    "#     12367864, #pulomonary-heart dx\n",
    "# ]\n",
    "\n",
    "# m4_selected_trajectory = {i: m4_trajectory[i] for i in m4_selected_subjects}\n",
    "\n",
    "# m3_selected_subjects = [\n",
    "#     50093 #pulmonary-heart dx\n",
    "# ]\n",
    "\n",
    "# m3_selected_trajectory = {i: m4m3_trajectory[i] for i in m3_selected_subjects}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "trajectory_ccs_codes_level1 = [\n",
    "    64, #renal fail \n",
    "    6, # pulm heart dx\n",
    "    236, # ear dx \n",
    "    # Others\n",
    "    100, # Brnch/lng ca\n",
    "    168, # Kidney/rnl ca\n",
    "    194, # Immunity dx\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# icenode_m4_competent.head(50)\n",
    "trajectory_ccs_codes_level2 = [\n",
    "    173, 168, 169, 156, 165, 216, 171, 100, 167\n",
    "]\n",
    "\n",
    "\n",
    "ccs_color = {\n",
    "    6: 'blue',\n",
    "    64: 'purple',\n",
    "    236: 'orange',\n",
    "    # Others\n",
    "    100: 'salmon', # Brnch/lng ca\n",
    "    168: 'navy', # Kidney/rnl ca\n",
    "    194: 'pink', # Immunity dx\n",
    "    **{idx: \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                   for idx in trajectory_ccs_codes_level2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = m4_interface[clfs[0]]\n",
    "trajectories = m4_trajectory\n",
    "save_dir = \"m4_trajectories_level2\"\n",
    "ccs_indexes = trajectory_ccs_codes_level2# + trajectory_ccs_codes_level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interface.dag.diag_flatccs_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "\n",
    "def plot_codes(codes_dict):\n",
    "    for ccs_idx in codes_dict:\n",
    "        ccs_desc = idx2desc(ccs_idx)\n",
    "        time, traj_vals = zip(*codes_dict[ccs_idx])\n",
    "        plt.scatter(time,  traj_vals, s=100,  marker='^', \n",
    "                    color=ccs_color[ccs_idx], linewidths=2,\n",
    "                    label=f'code: {ccs_desc if len(ccs_desc) < 15 else ccs_desc[:15]+\"..\"}')\n",
    "        \n",
    "def plot_admission_lines(adms):\n",
    "    adms, dischs = zip(*adms)\n",
    "    for i, (adm_ti, disch_ti) in enumerate(zip(adms, dischs)):\n",
    "        plt.axvline(x=adm_ti, color='green', linestyle='-.', label='admission' if i == 0 else None)\n",
    "        plt.axvline(x=disch_ti, color='red', linestyle='--', label='discharge' if i == 0 else None)\n",
    "        plt.fill_between([adm_ti, disch_ti], [1.0, 1.0], alpha=0.1, color='green')\n",
    "        \n",
    "        \n",
    "\n",
    "def plot_risk_traj(trajs):\n",
    "    for ccs_idx in trajs: \n",
    "        ccs_desc = idx2desc(ccs_idx)\n",
    "        time, traj_vals = zip(*trajs[ccs_idx])\n",
    "        time = np.concatenate(time)\n",
    "        traj_vals = np.concatenate(traj_vals)\n",
    "        \n",
    "        plt.plot(time, traj_vals,  color=ccs_color[ccs_idx], \n",
    "                 marker='o', markersize=2, linewidth=1,\n",
    "                 label=f'risk: {ccs_desc if len(ccs_desc) < 15 else ccs_desc[:15]+\"..\"}')\n",
    "    \n",
    "for i, traj in list(trajectories.items()):\n",
    "    plt.figure(i)\n",
    "    \n",
    "    adm_times = interface.adm_times(i)\n",
    "    \n",
    "    plot_admission_lines(adm_times)\n",
    "    \n",
    "    history = interface.diag_flatccs_history(i)\n",
    "    \n",
    "    t = traj['t']\n",
    "    d = traj['d']\n",
    "    \n",
    "\n",
    "    plt_codes = defaultdict(list)\n",
    "    plt_trajs = defaultdict(list)\n",
    "    max_min = (-np.inf, np.inf)\n",
    "    for code in history:\n",
    "        ccs_idx = flatccs_code2idx[code]\n",
    "        code = flatccs_idx2code[ccs_idx]\n",
    "        \n",
    "        if ccs_idx not in ccs_indexes:\n",
    "            continue\n",
    "\n",
    "        code_history = history[code]\n",
    "        code_history_adm, code_history_disch = zip(*code_history)\n",
    "\n",
    "        if code_history_adm[0] == adm_times[0][0]:\n",
    "            plt_codes[ccs_idx].append((adm_times[0][1], d[0][0, ccs_idx]))\n",
    "            \n",
    "        for ti, di, (adm_time_i, disch_time_i) in zip(t, d, adm_times[1:]):\n",
    "            max_min = max(max_min[0], di[:, ccs_idx].max()), min(max_min[1], di[:, ccs_idx].min())\n",
    "            plt_trajs[ccs_idx].append((ti, di[:, ccs_idx]))\n",
    "\n",
    "            \n",
    "            if disch_time_i in code_history_disch:\n",
    "                plt_codes[ccs_idx].append((disch_time_i, di[-1, ccs_idx]))\n",
    "            \n",
    "\n",
    "    if len(plt_codes) == 0:\n",
    "        continue\n",
    "\n",
    "    plot_codes(plt_codes)       \n",
    "    plot_risk_traj(plt_trajs)\n",
    "\n",
    "            \n",
    "    # Make the major grid\n",
    "    plt.grid(which='major', linestyle=':', color='gray', linewidth='1')\n",
    "    # Turn on the minor ticks on\n",
    "    plt.minorticks_on()\n",
    "    # Make the minor grid\n",
    "    plt.grid(which='minor', linestyle=':', color='black', linewidth='0.5')\n",
    "    \n",
    "    plt.ylim(math.floor(max_min[1]/0.05)*0.05, \n",
    "             math.ceil(max_min[0]/0.05)*0.05)\n",
    "    \n",
    "    ystart, yend = plt.gca().get_ylim()\n",
    "    plt.gca().yaxis.set_ticks(np.arange(ystart, yend+0.01, 0.05))\n",
    "\n",
    "    plt.ylabel('Predicted Risk ($\\widehat{v}(t)$)', fontsize=26)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.xlabel('Days Since First Admission ($t$)', fontsize=26)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.title(f'Disease Risk Trajectory for Subject ID: {i}', fontsize=28)\n",
    "    plt.legend(fontsize=22, title_fontsize=32,\n",
    "          loc='upper right', bbox_to_anchor=(1.5, 0.5), ncol=1)\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{save_dir}/trajectory_{i}.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959861b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
