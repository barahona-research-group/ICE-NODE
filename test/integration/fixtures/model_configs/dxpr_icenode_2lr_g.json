{
    "emb": {
        "dx": {
           "decoder_n_layers": 2,
            "classname": "CachedGRAM", 
            "attention_size": 10,
            "attention_method": "tanh",
            "embeddings_size": 10,
            "glove_iterations": 10, 
            "cooc_window_size_days": 360
        },
        "pr": {
            "classname": "CachedGRAM", 
            "attention_size": 5,
            "attention_method": "tanh",
            "embeddings_size": 5,
            "glove_iterations": 10, 
            "cooc_window_size_days": 360
        }
    },
    "model": {
        "ode_dyn_label": "mlp3",
        "ode_init_var": 1.0776395319697402e-07,
        "state_size": 20,
        "timescale": 7
    },
    "training": {
        "batch_size": 32,
        "decay_rate": [0.27729587471948475, 0.3293406876704547],
        "lr": [7.156197978746877e-05,  0.0011484691965460785],
        "epochs": 0.5,
        "reg_hyperparams": {
            "L_dyn": 1000.0,
            "L_l1": 0,
            "L_l2": 0
        },
        "opt": "adam",
        "classname": "ODETrainer2LR"
    }
}
