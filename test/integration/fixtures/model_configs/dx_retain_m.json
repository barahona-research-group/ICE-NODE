{
    "emb": {
        "dx": {
           "decoder_n_layers": 2,
           "classname":  "MatrixEmbeddings",      
           "embeddings_size": 270
        }
    },
    "model": {
        "state_a_size": 200,
        "state_b_size": 100
    },
    "training": {
        "batch_size": 27,
        "decay_rate": null,
        "epochs": 2,
        "reg_hyperparams": {
            "L_l1": 0,
            "L_l2": 0
        },
        "lr": 0.0016534371369143167,
        "opt": "adam",
        "classname": "Trainer"
    }
}
