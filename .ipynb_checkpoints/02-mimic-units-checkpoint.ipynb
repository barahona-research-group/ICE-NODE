{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf45d070",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import collections\n",
    "from collections import defaultdict \n",
    "from functools import partial\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "343145f1",
   "metadata": {},
   "source": [
    "### This notebook transforms information in tables into points with \"day\" as smallest time unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c00dddc",
   "metadata": {},
   "source": [
    "# Good read: https://iq-inc.com/importerror-attempted-relative-import/\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from mimicnet import concept\n",
    "\n",
    "importlib.reload(sys.modules['mimicnet.concept'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f14df8e7",
   "metadata": {},
   "source": [
    "# multi_visit_mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "multi_visit_mimic_dir = '/home/asem/GP/ehr-data/mimic3-multi-visit'\n",
    "\n",
    "PATIENTS = pd.read_csv(f'{multi_visit_mimic_dir}/PATIENTS.csv.gz')\n",
    "ADMISSIONS = pd.read_csv(f'{multi_visit_mimic_dir}/ADMISSIONS.csv.gz')\n",
    "DIAGNOSES_ICD = pd.read_csv(f'{multi_visit_mimic_dir}/DIAGNOSES_ICD.csv.gz', dtype = {'ICD9_CODE': str})\n",
    "PROCEDURES_ICD = pd.read_csv(f'{multi_visit_mimic_dir}/PROCEDURES_ICD.csv.gz', dtype = {'ICD9_CODE': str})\n",
    "LABEVENTS = pd.read_csv(f'{multi_visit_mimic_dir}/LABEVENTS.csv.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51442959",
   "metadata": {},
   "source": [
    "LABEVENTS = LABEVENTS[['SUBJECT_ID', 'ITEMID', 'CHARTTIME', 'VALUE', 'VALUENUM', 'VALUEUOM']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1732e6",
   "metadata": {},
   "source": [
    "N_PATIENTS = PATIENTS.shape[0]\n",
    "N_PATIENTS "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51508f6c",
   "metadata": {},
   "source": [
    "chunksize = 10 ** 7\n",
    "CHARTEVENTS_dfs = []\n",
    "with pd.read_csv(f'{multi_visit_mimic_dir}/CHARTEVENTS.csv.gz', chunksize=chunksize) as reader:\n",
    "    for chunk in tqdm(reader):\n",
    "        CHARTEVENTS_dfs.append(chunk[['SUBJECT_ID', 'ITEMID', 'CHARTTIME', 'VALUE', 'VALUENUM', 'VALUEUOM']])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3f93f689",
   "metadata": {},
   "source": [
    "### Load dictionary stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f08543",
   "metadata": {},
   "source": [
    "# mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "mimic_dir = '/home/asem/GP/ehr-data/mimic3-v1.4/physionet.org/files/mimiciii/1.4'\n",
    "\n",
    "\n",
    "D_LABITEMS = pd.read_csv(f'{mimic_dir}/D_LABITEMS.csv.gz')\n",
    "D_ITEMS = pd.read_csv(f'{mimic_dir}/D_ITEMS.csv.gz')\n",
    "\n",
    "itemid_label = dict(zip(D_ITEMS.ITEMID, D_ITEMS.LABEL))\n",
    "itemid_category = dict(zip(D_ITEMS.ITEMID, D_ITEMS.LABEL))\n",
    "\n",
    "\n",
    "labitem_label = dict(zip(D_LABITEMS.ITEMID, D_LABITEMS.LABEL))\n",
    "labitem_category = dict(zip(D_LABITEMS.ITEMID, D_LABITEMS.CATEGORY))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222a651a",
   "metadata": {},
   "source": [
    "D_ITEMS.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4cfc73",
   "metadata": {},
   "source": [
    "D_LABITEMS.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "baabcdf4",
   "metadata": {},
   "source": [
    "CHARTEVENTS_dfs[0].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a327a3d3",
   "metadata": {},
   "source": [
    "LABEVENTS.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f705d97",
   "metadata": {},
   "source": [
    "CHARTEVENTS_dfs[0].ITEMID.value_counts()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "070757b1",
   "metadata": {},
   "source": [
    "## (A) Select CHARTEVENTS with ITEMID covering at least 5% of all patients in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c46af6",
   "metadata": {},
   "source": [
    "### (A-1) Drop non-numerical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16ee073a",
   "metadata": {},
   "source": [
    "non_numeric_chartevents_dfs = []\n",
    "non_numeric_chartevents_vals = defaultdict(set)\n",
    "non_numeric_chartevents_units = defaultdict(set)\n",
    "\n",
    "for i, chunk_df in enumerate(CHARTEVENTS_dfs):\n",
    "    numeric_chunk_df = chunk_df[chunk_df.VALUENUM.notnull()].reset_index(drop=True)\n",
    "    CHARTEVENTS_dfs[i] = numeric_chunk_df\n",
    "    \n",
    "    non_numeric_chunk_df = chunk_df[chunk_df.VALUENUM.isnull() & chunk_df.VALUE.notnull()].reset_index(drop=True)\n",
    "    non_numeric_chartevents_dfs.append(non_numeric_chunk_df)\n",
    "    for itemid, df in non_numeric_chunk_df.groupby(['ITEMID']):\n",
    "        non_numeric_chartevents_vals[itemid].update(set(df.VALUE))\n",
    "        non_numeric_chartevents_units[itemid].update(set(df.VALUEUOM))\n",
    "\n",
    "non_numeric_chartevents_df = pd.DataFrame({'ITEMID': non_numeric_chartevents_vals.keys(),\n",
    "                                       'LABEL': map(itemid_label.get, non_numeric_chartevents_vals.keys()),\n",
    "                                       'CATEGORY': map(itemid_category.get, non_numeric_chartevents_vals.keys()),\n",
    "                                       'VALS': map(lambda vals: \"|\".join(vals), non_numeric_chartevents_vals.values())})\n",
    "non_numeric_chartevents_df.to_csv('non_numeric_chartevents_df.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97302b72",
   "metadata": {},
   "source": [
    "non_numeric_chartevents_units"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "756b6020",
   "metadata": {},
   "source": [
    "### (A-2) Filter below 5% patients coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0887da1",
   "metadata": {},
   "source": [
    "# For each chartevent item_id, store a set of patient that have at least one measurement of that type.\n",
    "chartevents_item_patients = defaultdict(set)\n",
    "for df in CHARTEVENTS_dfs:\n",
    "    item_subject_df = df.drop_duplicates(subset=['ITEMID', 'SUBJECT_ID'], ignore_index=True)\n",
    "    for item_id, subjects_df in item_subject_df.groupby('ITEMID'):\n",
    "        chartevents_item_patients[item_id].update(subjects_df.SUBJECT_ID.tolist())\n",
    "        \n",
    "        "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f4c6fc0e",
   "metadata": {},
   "source": [
    "#### CONCLUSION: No duplicate info between LABEVENTS and CHARTEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91932b09",
   "metadata": {},
   "source": [
    "print(len(chartevents_item_patients))\n",
    "print(len(set(LABEVENTS.ITEMID)))\n",
    "print(len(set(chartevents_item_patients.keys()) & set(LABEVENTS.ITEMID)))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f7fd2b0",
   "metadata": {},
   "source": [
    "chartevents_item_patients_count_df = pd.DataFrame({'ITEMID': chartevents_item_patients.keys(),\n",
    "                                                 'N_PATIENTS': map(len, chartevents_item_patients.values())})\n",
    "chartevents_item_patients_count_df['P_PATIENTS'] = chartevents_item_patients_count_df['N_PATIENTS'] / N_PATIENTS\n",
    "chartevents_item_patients_count_df = chartevents_item_patients_count_df.sort_values(by='N_PATIENTS', ascending=False)\n",
    "chartevents_item_patients_count_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84545971",
   "metadata": {},
   "source": [
    "np.mean(chartevents_item_patients_count_df.P_PATIENTS > 0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6428304c",
   "metadata": {},
   "source": [
    "selected_chartevents_itemid_set = set(chartevents_item_patients_count_df[chartevents_item_patients_count_df.P_PATIENTS > 0.05].ITEMID)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fad0990",
   "metadata": {},
   "source": [
    "len(selected_chartevents_itemid_set)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "193cb45c",
   "metadata": {},
   "source": [
    "for i, df in enumerate(CHARTEVENTS_dfs):\n",
    "    CHARTEVENTS_dfs[i] = df[df.ITEMID.isin(selected_chartevents_itemid_set)].reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64855c0e",
   "metadata": {},
   "source": [
    "for i, df_chunk in enumerate(tqdm(CHARTEVENTS_dfs)):\n",
    "    # Set writing mode to append after first chunk\n",
    "    mode = 'w' if i == 0 else 'a'\n",
    "    \n",
    "    # Add header if it is the first chunk\n",
    "    header = i == 0\n",
    "\n",
    "    df_chunk.to_csv(\n",
    "        f'{multi_visit_mimic_dir}/CHARTEVENTS_Q5.csv.gz', \n",
    "        compression='gzip', \n",
    "        index=False,\n",
    "        header=header, \n",
    "        mode=mode)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2733669f",
   "metadata": {},
   "source": [
    "## (B) Select LABEVENTS with ITEMID covering at least 5% of all patients in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880ffb2",
   "metadata": {},
   "source": [
    "### (B-1) Drop non-numerical measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9d3ce5b",
   "metadata": {},
   "source": [
    "non_numeric_labevents_vals = defaultdict(set)\n",
    "non_numeric_labevents_units = defaultdict(set)\n",
    "\n",
    "numeric_labevents_df = LABEVENTS[LABEVENTS.VALUENUM.notnull()].reset_index(drop=True)\n",
    "\n",
    "non_numeric_labevents_df = chunk_df[chunk_df.VALUENUM.isnull() & chunk_df.VALUE.notnull()].reset_index(drop=True)\n",
    "\n",
    "for itemid, df in non_numeric_labevents_df.groupby(['ITEMID']):\n",
    "    non_numeric_labevents_vals[itemid] = set(df.VALUE)\n",
    "    non_numeric_labevents_units[itemid] = set(df.VALUEUOM)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e91305cb",
   "metadata": {},
   "source": [
    "non_numeric_labevents_df = pd.DataFrame({'ITEMID': non_numeric_labevents_vals.keys(),\n",
    "                                       'LABEL': map(itemid_label.get, non_numeric_labevents_vals.keys()),\n",
    "                                       'CATEGORY': map(itemid_category.get, non_numeric_labevents_vals.keys()),\n",
    "                                       'VALS': map(lambda vals: \"|\".join(vals), non_numeric_labevents_vals.values())})\n",
    "                                \n",
    "non_numeric_labevents_df.to_csv('non_numeric_labevents_df.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4c46ff78",
   "metadata": {},
   "source": [
    "# For each labevents item_id, store a set of patient that have at least one measurement of that type.\n",
    "\n",
    "labevents_item_patients = defaultdict(set)\n",
    "\n",
    "labitem_subject_df = numeric_labevents_df.drop_duplicates(subset=['ITEMID', 'SUBJECT_ID'], ignore_index=True)\n",
    "for item_id, subjects_df in labitem_subject_df.groupby('ITEMID'):\n",
    "    labevents_item_patients[item_id].update(subjects_df.SUBJECT_ID.tolist())\n",
    "    \n",
    "labitem_patients_count_df = pd.DataFrame({'ITEMID': labevents_item_patients.keys(),\n",
    "                                                 'N_PATIENTS': map(len, labevents_item_patients.values())})\n",
    "labitem_patients_count_df['P_PATIENTS'] = labitem_patients_count_df['N_PATIENTS'] / N_PATIENTS\n",
    "\n",
    "labitem_patients_count_df = labitem_patients_count_df.sort_values(by='N_PATIENTS', ascending=False)\n",
    "labitem_patients_count_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8adefeb7",
   "metadata": {},
   "source": [
    "np.mean(labitem_patients_count_df.P_PATIENTS > 0.05)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0b609622",
   "metadata": {},
   "source": [
    "selected_labevents_itemid_set = set(labitem_patients_count_df[labitem_patients_count_df.P_PATIENTS > 0.05].ITEMID)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbf40667",
   "metadata": {},
   "source": [
    "LABEVENTS_Q5 = numeric_labevents_df[numeric_labevents_df.ITEMID.isin(selected_labevents_itemid_set)].reset_index(drop=True)\n",
    "LABEVENTS_Q5.to_csv(f'{multi_visit_mimic_dir}/LABEVENTS_Q5.csv.gz', \n",
    "                    compression='gzip', \n",
    "                    index=False,)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0434126",
   "metadata": {},
   "source": [
    "len(selected_labevents_itemid_set)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ae2336ab",
   "metadata": {},
   "source": [
    "## (C) Investigate the units used for each test type in CHARTEVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88de1959",
   "metadata": {},
   "source": [
    "### Load Filtered CHARTEVENTS (CHARTEVENTS_Q5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c988c088",
   "metadata": {},
   "source": [
    "CHARTEVENTS_Q5 = pd.read_csv(f'{multi_visit_mimic_dir}/CHARTEVENTS_Q5.csv.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "05c903a1",
   "metadata": {},
   "source": [
    "### Investigate numerical/categorical measurements in CHARTEVENTS_Q5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "215850b2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Group each ITEMID with the set of used units (to detect unit incosistency for each unique test).\n",
    "chartevents_item_units = defaultdict(dict)\n",
    "\n",
    "for item_id, item_df in CHARTEVENTS_Q5.groupby('ITEMID'):\n",
    "    item_df.loc[item_df.VALUEUOM.isnull(), 'VALUEUOM'] = ''\n",
    "    for unit, unit_df in item_df.groupby('VALUEUOM'):\n",
    "        vals_np = pd.to_numeric(unit_df.VALUENUM, errors='coerce')\n",
    "        chartevents_item_units[item_id][unit] = (np.size(vals_np), unit_df.VALUENUM.mean(skipna=True), unit_df.VALUENUM.std(skipna=True))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e0edecf",
   "metadata": {},
   "source": [
    "chartevents_item_units_count_df = pd.DataFrame({'ITEMID': chartevents_item_units.keys(),\n",
    "                                                'LABEL': map(itemid_label.get, chartevents_item_units.keys()),\n",
    "                                                'CATEGORY': map(itemid_category.get, chartevents_item_units.keys()),\n",
    "                                                'N_UNITS': map(len, chartevents_item_units.values())})\n",
    "chartevents_item_units_count_df = chartevents_item_units_count_df.sort_values(by='N_UNITS', ascending=False)\n",
    "chartevents_item_units_count_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5889727e",
   "metadata": {},
   "source": [
    "chartevents_item_tuples = []\n",
    "for itemid in chartevents_item_units_count_df.ITEMID:\n",
    "    for unit in chartevents_item_units[itemid]:\n",
    "        chartevents_item_tuples.append((itemid, unit))\n",
    "chartevents_units_df = pd.DataFrame(chartevents_item_tuples, columns=['ITEMID', 'VALUEUOM'])\n",
    "chartevents_units_df['LABEL'] = chartevents_units_df.ITEMID.map(itemid_label)\n",
    "chartevents_units_df['CATEGORY'] = chartevents_units_df.ITEMID.map(itemid_category)\n",
    "chartevents_units_df.to_csv('chartevents_units_df.csv')\n",
    "chartevents_units_df\n",
    "\n",
    "\n",
    "chartevents_item_tuples = []\n",
    "for itemid in chartevents_item_units_count_df.ITEMID:\n",
    "    for unit, (n, mean, std) in chartevents_item_units[itemid].items():\n",
    "        chartevents_item_tuples.append((itemid, unit, n, mean, std))\n",
    "chartevents_units_df = pd.DataFrame(chartevents_item_tuples, columns=['ITEMID', 'VALUEUOM', 'N', 'MEAN', 'STD'])\n",
    "chartevents_units_df['LABEL'] = chartevents_units_df.ITEMID.map(itemid_label)\n",
    "chartevents_units_df['CATEGORY'] = chartevents_units_df.ITEMID.map(itemid_category)\n",
    "\n",
    "chartevents_units_df.to_csv('chartevents_units_df.csv')\n",
    "chartevents_units_df\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "08e5822f",
   "metadata": {},
   "source": [
    "### CONCLUSION: Units are consistent for each measurement type in CHARTEVENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da20f7c9",
   "metadata": {},
   "source": [
    "## (D) Investigate the units used for each test type in LABEVENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "da94eb87",
   "metadata": {},
   "source": [
    "LABEVENTS_Q5 = pd.read_csv(f'{multi_visit_mimic_dir}/LABEVENTS_Q5.csv.gz')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebf446e5",
   "metadata": {},
   "source": [
    "# Group each ITEMID with the set of used units (to detect unit incosistency for each unique test).\n",
    "labevents_item_units = defaultdict(dict)\n",
    "for item_id, units_df in LABEVENTS_Q5.groupby('ITEMID'):\n",
    "    units_df.loc[units_df.VALUEUOM.isnull(), 'VALUEUOM'] = ''\n",
    "    for unit, vals_df in units_df.groupby('VALUEUOM'):\n",
    "        vals_np = pd.to_numeric(vals_df.VALUENUM, errors='coerce')\n",
    "        labevents_item_units[item_id][unit] = (np.size(vals_np), vals_df.VALUENUM.mean(skipna=True), vals_df.VALUENUM.std(skipna=True))\n",
    "\n",
    "        "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6d02562",
   "metadata": {},
   "source": [
    "labevents_item_units_count_df = pd.DataFrame({'ITEMID': labevents_item_units.keys(),\n",
    "                                              'LABEL': map(labitem_label.get, labevents_item_units.keys()),\n",
    "                                              'CATEGORY': map(labitem_category.get, labevents_item_units.keys()),\n",
    "                                              'N_UNITS': map(len, labevents_item_units.values())})\n",
    "labevents_item_units_count_df = labevents_item_units_count_df.sort_values(by='N_UNITS', ascending=False)\n",
    "labevents_item_units_count_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d1fc57ab",
   "metadata": {},
   "source": [
    "\n",
    "labitem_nunits = dict(zip(labevents_item_units_count_df.ITEMID, labevents_item_units_count_df.N_UNITS))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "90addca3",
   "metadata": {},
   "source": [
    "labevents_item_tuples = []\n",
    "for itemid in labevents_item_units_count_df.ITEMID:\n",
    "    for unit, (n, mean, std) in labevents_item_units[itemid].items():\n",
    "        labevents_item_tuples.append((itemid, unit, n, mean, std))\n",
    "labevents_units_df = pd.DataFrame(labevents_item_tuples, columns=['ITEMID', 'VALUEUOM', 'N', 'MEAN', 'STD'])\n",
    "labevents_units_df['LABEL'] = labevents_units_df.ITEMID.map(labitem_label)\n",
    "labevents_units_df['CATEGORY'] = labevents_units_df.ITEMID.map(labitem_category)\n",
    "labevents_units_df['N_UNITS'] = labevents_units_df.ITEMID.map(labitem_nunits)\n",
    "\n",
    "labevents_units_df.to_csv('labevents_units_df.csv')\n",
    "labevents_units_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "afe0dfac",
   "metadata": {},
   "source": [
    "### (D-1) Convert only units for (ITEMID=50889, C-Reactive Protein)\n",
    "\n",
    "- Convert from mg/dL to mg/L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2f1ba365",
   "metadata": {},
   "source": [
    "to_convert_units = ['MG/DL', 'mg/dL']\n",
    "cond = (LABEVENTS_Q5.ITEMID == 50889) & (LABEVENTS_Q5.VALUEUOM.isin(to_convert_units))\n",
    "LABEVENTS_Q5[cond]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aab28c",
   "metadata": {},
   "source": [
    "LABEVENTS_Q5.loc[cond, 'VALUE'] = LABEVENTS_Q5.loc[cond, 'VALUE'] * 10\n",
    "LABEVENTS_Q5.loc[cond, 'VALUEUOM'] = 'mg/L'\n",
    "LABEVENTS_Q5.loc[cond, 'VALUENUM'] = LABEVENTS_Q5.loc[cond, 'VALUENUM'] * 10\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fd47a16c",
   "metadata": {},
   "source": [
    "LABEVENTS_Q5[cond]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "497cb3f4",
   "metadata": {},
   "source": [
    "LABEVENTS_Q5.to_csv(f'{multi_visit_mimic_dir}/LABEVENTS_Q5_UNITS_FIXED.csv.gz', \n",
    "                    w,)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd82160",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
