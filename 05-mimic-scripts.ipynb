{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lucky-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict \n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "\n",
    "# Global flag to set a specific platform, must be used at startup.\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "jax.config.update(\"jax_debug_infs\", True)\n",
    "\n",
    "jax.config.update('jax_log_compiles', False)\n",
    "jax.config.update('jax_check_tracer_leaks', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prime-league",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(499500, dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "a = jnp.array(range(1000)) \n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "heavy-verification",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'mimicnet.models' from '/home/asem/GP/MIMIC-SNONET/mimicnet/models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good read: https://iq-inc.com/importerror-attempted-relative-import/\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from mimicnet import concept\n",
    "from mimicnet import jax_interface\n",
    "from mimicnet import dag\n",
    "from mimicnet import glove\n",
    "from mimicnet import gram\n",
    "from mimicnet import train\n",
    "from mimicnet import models\n",
    "\n",
    "importlib.reload(sys.modules['mimicnet.concept'])\n",
    "importlib.reload(sys.modules['mimicnet.dag'])\n",
    "importlib.reload(sys.modules['mimicnet.jax_interface'])\n",
    "importlib.reload(sys.modules['mimicnet.glove'])\n",
    "importlib.reload(sys.modules['mimicnet.gram'])\n",
    "importlib.reload(sys.modules['mimicnet.train'])\n",
    "importlib.reload(sys.modules['mimicnet.models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "demanding-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_visit_mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "multi_visit_mimic_dir = '/home/asem/GP/ehr-data/mimic3-multi-visit'\n",
    "transformed_mimic_dir = '/home/asem/GP/ehr-data/mimic3-transforms'\n",
    "mimic_dir = '/home/asem/GP/ehr-data/mimic3-v1.4/physionet.org/files/mimiciii/1.4'\n",
    "# mimic_dir = '/home/asem/GP/MIMIC-SNONET/RAW/mimic-iii-clinical-database-1.4'\n",
    "\n",
    "experiments_dir = '/home/asem/GP/ehr-data/mimic3-snonet-exp'\n",
    "experiment_prefix = 'DEC03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-wrong",
   "metadata": {},
   "source": [
    "### [FORK] Skip the cell below to load the jaxified data from a stored file on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "animal-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_df = pd.read_csv(f'{transformed_mimic_dir}/static_df.csv.gz')\n",
    "# adm_df = pd.read_csv(f'{transformed_mimic_dir}/adm_df.csv.gz')\n",
    "# diag_df = pd.read_csv(f'{transformed_mimic_dir}/diag_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# proc_df = pd.read_csv(f'{transformed_mimic_dir}/proc_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# test_df = pd.read_csv(f'{transformed_mimic_dir}/test_df.csv.gz')\n",
    "\n",
    "\n",
    "# # Cast columns of dates to datetime64\n",
    "\n",
    "# static_df['DOB'] = pd.to_datetime(static_df.DOB, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['ADMITTIME'] = pd.to_datetime(adm_df.ADMITTIME, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['DISCHTIME'] = pd.to_datetime(adm_df.DISCHTIME, infer_datetime_format=True).dt.normalize()\n",
    "# test_df['DATE'] = pd.to_datetime(test_df.DATE, infer_datetime_format=True).dt.normalize()\n",
    "\n",
    "\n",
    "# patients = concept.Subject.to_list(static_df, adm_df, diag_df, proc_df, test_df)\n",
    "\n",
    "# KG = dag.CCSDAG()\n",
    "\n",
    "# subjects_interface = jax_interface.SubjectJAXInterface(patients, set(test_df.ITEMID), KG)\n",
    "# import pickle\n",
    "# with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'wb') as pickleFile:\n",
    "#     pickle.dump(subjects_interface, pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "selective-marsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'rb') as pickleFile:\n",
    "    subjects_interface = pickle.load(pickleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-ceramic",
   "metadata": {},
   "source": [
    "## GloVe Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pediatric-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "written-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "utility-flight",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_args = {\n",
    "    'diag_idx': subjects_interface.diag_multi_ccs_idx,\n",
    "    'proc_idx': subjects_interface.proc_multi_ccs_idx,\n",
    "    'ccs_dag': subjects_interface.dag,\n",
    "    'subjects': subjects_interface.subjects.values(),\n",
    "    'diag_vector_size': 100,\n",
    "    'proc_vector_size': 60,\n",
    "    'iterations': 30,\n",
    "    'window_size_days': 2 * 365\n",
    "}\n",
    "\n",
    "diag_glove_rep, proc_glove_rep = glove.glove_representation(**glove_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "divided-wilderness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#point_indices: 1085\n",
      "#total_points: 129334\n"
     ]
    }
   ],
   "source": [
    "print(f'#point_indices: {len(subjects_interface.nth_points)}')\n",
    "print(f'#total_points: {sum(len(points) for n, points in subjects_interface.nth_points.items())}')\n",
    "\n",
    "#[len(points) for n, points in subjects_interface.nth_points.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-easter",
   "metadata": {},
   "source": [
    "## GRAM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "certified-court",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tensorboard/20211212-152131\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "daily_tracer = \"/tmp/tensorboard/\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "print(daily_tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suitable-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logs = '/tmp/tensorboard/20210708-182059'\n",
    "#server = jax.profiler.start_server(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "appreciated-inside",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# config = {\n",
    "#     'gram_config': {\n",
    "#         'diag': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh', #l2, tanh\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': diag_glove_rep\n",
    "#         },\n",
    "#         'proc': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh',\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': proc_glove_rep\n",
    "#         }\n",
    "#     },\n",
    "#     'model': {\n",
    "#         'ode_dyn': 'mlp', # gru, mlp\n",
    "#         'state_size': 50,\n",
    "#         'numeric_hidden_size': 50,\n",
    "#         'bias': True\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'train_validation_split': 0.8,\n",
    "#         'batch_size': 4,\n",
    "#         'epochs': 200,\n",
    "#         'lr': 1e-3,\n",
    "#         'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "#         'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "#         'loss_mixing': {\n",
    "#             'num_alpha': 0.1,\n",
    "#             'diag_alpha': 0.1,\n",
    "#             'ode_alpha': 1e-3,\n",
    "#             'l1_reg': 1e-6,\n",
    "#             'l2_reg': 1e-5,\n",
    "#             'dyn_reg': 1e-5\n",
    "#         },\n",
    "#         'eval_freq': 10,\n",
    "#         'save_freq': 100,\n",
    "#         'save_params_prefix': None\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlike-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "config = {\n",
    "    'gram_config': {\n",
    "        'diag': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "            'attention_method': 'tanh', #l2, tanh\n",
    "            'attention_dim': 150,\n",
    "            'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': diag_glove_rep\n",
    "        },\n",
    "        'proc': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "            'attention_method': 'tanh',\n",
    "            'attention_dim': 100,\n",
    "            'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': proc_glove_rep\n",
    "        }\n",
    "    },\n",
    "    'model': {\n",
    "        'ode_dyn': 'gru', # gru, mlp, res\n",
    "        'ode_depth': 2,\n",
    "        'state_size': 120,\n",
    "        'numeric_hidden_size': 200,\n",
    "        'init_depth': 2,\n",
    "        'bias': True,\n",
    "        'max_odeint_days': 8 * 7 # two months\n",
    "    },\n",
    "    'training': {\n",
    "        'train_validation_split': 0.8,\n",
    "        'batch_size': 20,\n",
    "        'epochs': 200,\n",
    "        'lr': 1e-3,\n",
    "        'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "        'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "        'loss_mixing': {\n",
    "            'num_alpha': 0.1,\n",
    "            'diag_alpha': 0.1,\n",
    "            'ode_alpha': 1e-6,\n",
    "            'l1_reg': 1e-6,\n",
    "            'l2_reg': 1e-5,\n",
    "            'dyn_reg': 1e3\n",
    "        },\n",
    "        'eval_freq': 5,\n",
    "        'save_freq': 100,\n",
    "        'save_params_prefix': None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "celtic-reader",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_gram = gram.DAGGRAM(**config['gram_config']['diag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sustained-claim",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gram = gram.DAGGRAM(**config['gram_config']['proc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-hindu",
   "metadata": {},
   "source": [
    "## GRU-ODE-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "maritime-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ode:#params: 731364\n",
      "INFO:ode:shape(params): {'diag_gram': ((589, 100), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (150,), 'w': (200, 150)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (150, 1)}),\n",
      "})), 'f_dec': FlatMap({\n",
      "  'f_dec/~/lin_gram': FlatMap({'b': (100,), 'w': (150, 100)}),\n",
      "  'f_dec/~/lin_h_hidden': FlatMap({'b': (50,), 'w': (120, 50)}),\n",
      "  'f_dec/~/lin_num_hidden1': FlatMap({'b': (50,), 'w': (550, 50)}),\n",
      "  'f_dec/~/lin_num_hidden2': FlatMap({'b': (100,), 'w': (50, 100)}),\n",
      "  'f_dec/~/lin_out': FlatMap({'b': (284,), 'w': (100, 284)}),\n",
      "}), 'f_num': FlatMap({\n",
      "  'f_numeric/linear': FlatMap({'b': (200,), 'w': (120, 200)}),\n",
      "  'f_numeric/~/linear': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "  'f_numeric/~/linear_1': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "}), 'f_state_init': FlatMap({\n",
      "  'f_init/~/lin_0': FlatMap({'b': (100,), 'w': (110, 100)}),\n",
      "  'f_init/~/lin_1': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_out': FlatMap({'b': (120,), 'w': (100, 120)}),\n",
      "}), 'gru_bayes': FlatMap({\n",
      "  'gru_bayes/~/gru': FlatMap({'b': (360,), 'w_h': (120, 360), 'w_i': (120, 360)}),\n",
      "  'gru_bayes/~/gru_bayes_prep1': FlatMap({'b': (120,), 'w': (650, 120)}),\n",
      "  'gru_bayes/~/gru_bayes_prep2': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "}), 'ode_dyn': FlatMap({\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/hc_r': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/hc_z': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/rhc_g': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "}), 'proc_gram': ((345, 60), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (100,), 'w': (120, 100)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (100, 1)}),\n",
      "}))}\n",
      "info retrieval:   0%|                                                                                                                                              | 1/35470 [06:30<3849:54:45, 390.75s/it]INFO:ode:\n",
      "                        Training     Validation\n",
      "prejump_num_loss       116.57635      109.28396\n",
      "postjump_num_loss      78.715904       74.89206\n",
      "prejump_diag_loss   0.0013037492   0.0013169388\n",
      "postjump_diag_loss  0.0013356111   0.0013326093\n",
      "num_loss                112.7903     105.844765\n",
      "diag_loss           0.0013069353   0.0013185058\n",
      "ode_loss            0.0014197243   0.0014243494\n",
      "l1_loss                32015.828      32015.828\n",
      "l2_loss                2788.1067      2788.1067\n",
      "dyn_loss               0.1919199       9.870621\n",
      "dyn_loss_per_week    0.000624565  0.00065899536\n",
      "loss                   0.6858816      0.7203166\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                  0.467339   0.466622\n",
      "recall                    0.576802   0.578025\n",
      "npv                       0.964474   0.968463\n",
      "specificity               0.462928   0.462645\n",
      "precision                 0.041479   0.036985\n",
      "f1-score                  0.077392   0.069521\n",
      "tp                        0.022341   0.019926\n",
      "tn                        0.444998   0.446696\n",
      "fp                         0.51627   0.518831\n",
      "fn                        0.016391   0.014546\n",
      "all_points_count               581      25331\n",
      "integrable_points_count        527      23785\n",
      "predictable_count               20        964\n",
      "odeint weeks/point        0.583085   0.629737\n",
      "nfe/point                28.698292  29.343452\n",
      "nfe/week                  49.21804  46.596386\n",
      "nfex1000                    15.124    697.934\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=66 C=198)  0.121212   0.075758\n",
      "P1(N=67 C=31)   0.014925   0.104478\n",
      "P2(N=75 C=17)   0.040000   0.040000\n",
      "P3(N=79 C=10)   0.126582   0.088608\n",
      "P4(N=98 C=7)    0.020408   0.020408\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.098456   0.097169\n",
      "P1(N=3383 C=31)   0.068578   0.071534\n",
      "P2(N=3284 C=17)   0.082521   0.070341\n",
      "P3(N=3168 C=10)   0.075442   0.089331\n",
      "P4(N=3603 C=7)    0.012767   0.016930\n",
      "info retrieval:   0%|                                                                                                                                                | 6/35470 [11:54<677:20:29, 68.76s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss          91.3018       90.99672\n",
      "postjump_num_loss        56.81573       58.69952\n",
      "prejump_diag_loss    0.0012471155    0.001272928\n",
      "postjump_diag_loss      0.0012782   0.0012793681\n",
      "num_loss                87.853195         87.767\n",
      "diag_loss             0.001250224    0.001273572\n",
      "ode_loss             0.0013380758   0.0013613377\n",
      "l1_loss                 31427.725      31427.725\n",
      "l2_loss                  2699.624       2699.624\n",
      "dyn_loss               0.02663224      2.2375824\n",
      "dyn_loss_per_week   0.00013363847  0.00014938842\n",
      "loss                   0.19340052     0.20917372\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                  0.491874   0.497001\n",
      "recall                    0.652893   0.706555\n",
      "npv                       0.976391   0.979046\n",
      "specificity               0.486418   0.489519\n",
      "precision                 0.041296   0.047089\n",
      "f1-score                  0.077679   0.088294\n",
      "tp                        0.021398   0.024357\n",
      "tn                        0.470477   0.472645\n",
      "fp                         0.49675   0.492883\n",
      "fn                        0.011376   0.010116\n",
      "all_points_count               406      25331\n",
      "integrable_points_count        371      23785\n",
      "predictable_count               15        964\n",
      "odeint weeks/point        0.537158   0.629737\n",
      "nfe/point                26.469002  27.870255\n",
      "nfe/week                 49.275986     44.257\n",
      "nfex1000                      9.82    662.894\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=48 C=198)  0.083333   0.083333\n",
      "P1(N=63 C=31)   0.047619   0.031746\n",
      "P2(N=60 C=17)   0.150000   0.083333\n",
      "P3(N=47 C=10)   0.170213   0.191489\n",
      "P4(N=71 C=7)    0.098592   0.140845\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.085264   0.089768\n",
      "P1(N=3383 C=31)   0.026012   0.032811\n",
      "P2(N=3284 C=17)   0.158648   0.145859\n",
      "P3(N=3168 C=10)   0.110795   0.118056\n",
      "P4(N=3603 C=7)    0.089648   0.112129\n",
      "info retrieval:   0%|                                                                                                                                               | 11/35470 [20:06<958:22:47, 97.30s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss         98.50807        96.1016\n",
      "postjump_num_loss        65.27186      63.999355\n",
      "prejump_diag_loss    0.0012268418   0.0012321981\n",
      "postjump_diag_loss    0.001237797   0.0012328405\n",
      "num_loss                 95.18445       92.89137\n",
      "diag_loss            0.0012279374   0.0012322624\n",
      "ode_loss             0.0013231206   0.0013251525\n",
      "l1_loss                  30880.66       30880.66\n",
      "l2_loss                 2618.4053      2618.4053\n",
      "dyn_loss               0.00511018     0.64312845\n",
      "dyn_loss_per_week   3.4528242e-05  4.2937387e-05\n",
      "loss                   0.09291607    0.101327255\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                   0.52723   0.532013\n",
      "recall                    0.727273   0.726654\n",
      "npv                       0.981409   0.981752\n",
      "specificity               0.520005   0.525064\n",
      "precision                 0.051886   0.051796\n",
      "f1-score                  0.096861     0.0967\n",
      "tp                        0.025352   0.025049\n",
      "tn                        0.501878   0.506964\n",
      "fp                        0.463263   0.458564\n",
      "fn                        0.009507   0.009423\n",
      "all_points_count               371      25331\n",
      "integrable_points_count        340      23785\n",
      "predictable_count               19        964\n",
      "odeint weeks/point        0.435294   0.629737\n",
      "nfe/point                23.829412  26.885431\n",
      "nfe/week                 54.743244  42.693134\n",
      "nfex1000                     8.102     639.47\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=62 C=198)  0.032258   0.048387\n",
      "P1(N=63 C=31)   0.000000   0.000000\n",
      "P2(N=84 C=17)   0.166667   0.142857\n",
      "P3(N=62 C=10)   0.193548   0.193548\n",
      "P4(N=79 C=7)    0.430380   0.455696\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.055985   0.051158\n",
      "P1(N=3383 C=31)   0.005616   0.015371\n",
      "P2(N=3284 C=17)   0.210719   0.205542\n",
      "P3(N=3168 C=10)   0.279672   0.275884\n",
      "P4(N=3603 C=7)    0.540383   0.510686\n",
      "info retrieval:   0%|                                                                                                                                               | 16/35470 [25:15<556:04:36, 56.46s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss        121.29996      109.99777\n",
      "postjump_num_loss          83.986       76.87606\n",
      "prejump_diag_loss    0.0012483058   0.0011941451\n",
      "postjump_diag_loss   0.0012387255   0.0011901789\n",
      "num_loss                117.56856       106.6856\n",
      "diag_loss            0.0012473477   0.0011937484\n",
      "ode_loss             0.0013649149   0.0013004328\n",
      "l1_loss                 30345.627      30345.627\n",
      "l2_loss                 2545.5938      2545.5938\n",
      "dyn_loss             0.0041929577     0.26178044\n",
      "dyn_loss_per_week   1.5960142e-05  1.7477329e-05\n",
      "loss                   0.07312662     0.07457933\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                  0.538842   0.545579\n",
      "recall                    0.705202   0.760565\n",
      "npv                       0.978549   0.984356\n",
      "specificity               0.532258   0.537904\n",
      "precision                 0.056312   0.055502\n",
      "f1-score                  0.104296   0.103455\n",
      "tp                        0.026849   0.026218\n",
      "tn                        0.511994   0.519361\n",
      "fp                        0.449934   0.446167\n",
      "fn                        0.011224   0.008254\n",
      "all_points_count               518      25331\n",
      "integrable_points_count        468      23785\n",
      "predictable_count               24        964\n",
      "odeint weeks/point        0.561355   0.629737\n",
      "nfe/point                 29.75641   26.29363\n",
      "nfe/week                 53.008156  41.753376\n",
      "nfex1000                    13.926    625.394\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=83 C=198)  0.036145   0.048193\n",
      "P1(N=90 C=31)   0.000000   0.000000\n",
      "P2(N=68 C=17)   0.191176   0.205882\n",
      "P3(N=60 C=10)   0.333333   0.400000\n",
      "P4(N=81 C=7)    0.629630   0.629630\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.025097   0.030566\n",
      "P1(N=3383 C=31)   0.008277   0.008868\n",
      "P2(N=3284 C=17)   0.242083   0.228380\n",
      "P3(N=3168 C=10)   0.389520   0.369003\n",
      "P4(N=3603 C=7)    0.733278   0.710519\n",
      "  0%|                                                                                                                                                               | 21/35470 [28:58<610:50:24, 62.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value encountered in the output of a jit/pmap-ed function. Calling the de-optimized version.\n",
      "Invalid value encountered in the output of a jit/pmap-ed function. Calling the de-optimized version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ode:ValueError exception raised: Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 690, in _xla_call_impl\n",
      "    out = compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in transpose(jvp(apply_fn))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 690, in _xla_call_impl\n",
      "    out = compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in transpose(jvp(_odeint_wrapper))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_164528/1314418325.py\", line 8, in <module>\n",
      "    res = train.train_ehr(subject_interface=subjects_interface,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 923, in train_ehr\n",
      "    opt_state = update(step, train_batch, opt_state, update_batch_desc)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 880, in update\n",
      "    grads = jax.grad(loss_fn)(params, batch, iteration_text_callback)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 839, in loss_fn\n",
      "    res = ode_model(params,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 614, in __call__\n",
      "    h1, _dyn_loss, _nfe = nn_odeint(h0, delta_weeks,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 489, in <lambda>\n",
      "    nn_odeint = lambda h, t, c, s: self.__odeint(params, h, t, c,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 346, in __odeint\n",
      "    h_r_nfe = {\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 347, in <dictcomp>\n",
      "    i: self.n_ode(params['ode_dyn'], h[i], t[i], c[i], count_nfe)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 216, in apply_fn\n",
      "    return f.apply(params, None, *args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 127, in apply_fn\n",
      "    out, state = f.apply(params, {}, *args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 383, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 117, in wrap\n",
      "    return model(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/module.py\", line 428, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/module.py\", line 279, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/models.py\", line 265, in __call__\n",
      "    h, r = odeint(self.ode_dyn, (h, jnp.zeros(1)), jnp.array([0.0, t]),\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 175, in odeint\n",
      "    return _odeint_wrapper(converted, rtol, atol, mxstep, y0, t, *args, *consts)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 181, in _odeint_wrapper\n",
      "    out = _odeint(func, rtol, atol, mxstep, y0, ts, *args)\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: FloatingPointError: invalid value (nan) encountered in scan\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 923, in train_ehr\n",
      "    opt_state = update(step, train_batch, opt_state, update_batch_desc)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 880, in update\n",
      "    grads = jax.grad(loss_fn)(params, batch, iteration_text_callback)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 918, in grad_f\n",
      "    _, g = value_and_grad_f(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 1000, in value_and_grad_f\n",
      "    g = vjp_py(np.ones((), dtype=dtype))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/tree_util.py\", line 326, in <lambda>\n",
      "    func = lambda *args, **kw: original_func(*args, **kw)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 2219, in _vjp_pullback_wrapper\n",
      "    ans = fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/tree_util.py\", line 326, in <lambda>\n",
      "    func = lambda *args, **kw: original_func(*args, **kw)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 123, in unbound_vjp\n",
      "    arg_cts = backward_pass(jaxpr, reduce_axes, consts, dummy_args, cts)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 222, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 558, in call_transpose\n",
      "    out_flat = primitive.bind(fun, *all_args, **new_params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1632, in bind\n",
      "    return call_bind(self, fun, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1623, in call_bind\n",
      "    outs = primitive.process(top_trace, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1635, in process\n",
      "    return trace.process_call(self, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 627, in process_call\n",
      "    return primitive.impl(f, *tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 706, in _xla_call_impl\n",
      "    _ = clone.call_wrapped(*args)  # probably won't return\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 222, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 558, in call_transpose\n",
      "    out_flat = primitive.bind(fun, *all_args, **new_params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1632, in bind\n",
      "    return call_bind(self, fun, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1623, in call_bind\n",
      "    outs = primitive.process(top_trace, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1635, in process\n",
      "    return trace.process_call(self, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 627, in process_call\n",
      "    return primitive.impl(f, *tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 706, in _xla_call_impl\n",
      "    _ = clone.call_wrapped(*args)  # probably won't return\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 228, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(cts_in, *invals,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 690, in _custom_lin_transpose\n",
      "    cts_in = bwd.call_wrapped(*res, *cts_out)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 255, in _odeint_rev\n",
      "    (y_bar, t0_bar, args_bar), rev_ts_bar = lax.scan(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\", line 1357, in scan\n",
      "    out = scan_p.bind(*consts, *in_flat,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\", line 1933, in scan_bind\n",
      "    return core.AxisPrimitive.bind(scan_p, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 272, in bind\n",
      "    out = top_trace.process_primitive(self, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 624, in process_primitive\n",
      "    return primitive.impl(*tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 418, in apply_primitive\n",
      "    return compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in scan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "#with jax.profiler.trace(logs):\n",
    "res = train.train_ehr(subject_interface=subjects_interface,\n",
    "                diag_gram=diag_gram,\n",
    "                proc_gram=proc_gram,\n",
    "                rng=random.Random(42),\n",
    "                model_config=config['model'],\n",
    "                **config['training'],\n",
    "                verbose_debug=False,\n",
    "                shape_debug=False,\n",
    "                nan_debug=False,\n",
    "                memory_profile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-amplifier",
   "metadata": {},
   "source": [
    "#### Possible modifications:\n",
    "- Add more layers to the adjustment function\n",
    "- Use days instead of weeks for odeint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
