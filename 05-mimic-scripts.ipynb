{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict \n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "\n",
    "# Global flag to set a specific platform, must be used at startup.\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "jax.config.update(\"jax_debug_infs\", True)\n",
    "\n",
    "jax.config.update('jax_log_compiles', False)\n",
    "jax.config.update('jax_check_tracer_leaks', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latest-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(499500, dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "a = jnp.array(range(1000)) \n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "later-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'mimicnet.models' from '/home/asem/GP/MIMIC-SNONET/mimicnet/models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good read: https://iq-inc.com/importerror-attempted-relative-import/\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from mimicnet import concept\n",
    "from mimicnet import jax_interface\n",
    "from mimicnet import dag\n",
    "from mimicnet import glove\n",
    "from mimicnet import gram\n",
    "from mimicnet import train\n",
    "from mimicnet import models\n",
    "\n",
    "importlib.reload(sys.modules['mimicnet.concept'])\n",
    "importlib.reload(sys.modules['mimicnet.dag'])\n",
    "importlib.reload(sys.modules['mimicnet.jax_interface'])\n",
    "importlib.reload(sys.modules['mimicnet.glove'])\n",
    "importlib.reload(sys.modules['mimicnet.gram'])\n",
    "importlib.reload(sys.modules['mimicnet.train'])\n",
    "importlib.reload(sys.modules['mimicnet.models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chemical-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_visit_mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "multi_visit_mimic_dir = '/home/asem/GP/ehr-data/mimic3-multi-visit'\n",
    "transformed_mimic_dir = '/home/asem/GP/ehr-data/mimic3-transforms'\n",
    "mimic_dir = '/home/asem/GP/ehr-data/mimic3-v1.4/physionet.org/files/mimiciii/1.4'\n",
    "# mimic_dir = '/home/asem/GP/MIMIC-SNONET/RAW/mimic-iii-clinical-database-1.4'\n",
    "\n",
    "experiments_dir = '/home/asem/GP/ehr-data/mimic3-snonet-exp'\n",
    "experiment_prefix = 'DEC03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-idaho",
   "metadata": {},
   "source": [
    "### [FORK] Skip the cell below to load the jaxified data from a stored file on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_df = pd.read_csv(f'{transformed_mimic_dir}/static_df.csv.gz')\n",
    "# adm_df = pd.read_csv(f'{transformed_mimic_dir}/adm_df.csv.gz')\n",
    "# diag_df = pd.read_csv(f'{transformed_mimic_dir}/diag_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# proc_df = pd.read_csv(f'{transformed_mimic_dir}/proc_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# test_df = pd.read_csv(f'{transformed_mimic_dir}/test_df.csv.gz')\n",
    "\n",
    "\n",
    "# # Cast columns of dates to datetime64\n",
    "\n",
    "# static_df['DOB'] = pd.to_datetime(static_df.DOB, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['ADMITTIME'] = pd.to_datetime(adm_df.ADMITTIME, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['DISCHTIME'] = pd.to_datetime(adm_df.DISCHTIME, infer_datetime_format=True).dt.normalize()\n",
    "# test_df['DATE'] = pd.to_datetime(test_df.DATE, infer_datetime_format=True).dt.normalize()\n",
    "\n",
    "\n",
    "# patients = concept.Subject.to_list(static_df, adm_df, diag_df, proc_df, test_df)\n",
    "\n",
    "# KG = dag.CCSDAG()\n",
    "\n",
    "# subjects_interface = jax_interface.SubjectJAXInterface(patients, set(test_df.ITEMID), KG)\n",
    "# import pickle\n",
    "# with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'wb') as pickleFile:\n",
    "#     pickle.dump(subjects_interface, pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adult-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'rb') as pickleFile:\n",
    "    subjects_interface = pickle.load(pickleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-sweet",
   "metadata": {},
   "source": [
    "## GloVe Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arbitrary-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "personal-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hollywood-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_args = {\n",
    "    'diag_idx': subjects_interface.diag_multi_ccs_idx,\n",
    "    'proc_idx': subjects_interface.proc_multi_ccs_idx,\n",
    "    'ccs_dag': subjects_interface.dag,\n",
    "    'subjects': subjects_interface.subjects.values(),\n",
    "    'diag_vector_size': 100,\n",
    "    'proc_vector_size': 60,\n",
    "    'iterations': 30,\n",
    "    'window_size_days': 2 * 365\n",
    "}\n",
    "\n",
    "diag_glove_rep, proc_glove_rep = glove.glove_representation(**glove_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-birth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#point_indices: 1085\n",
      "#total_points: 129334\n"
     ]
    }
   ],
   "source": [
    "print(f'#point_indices: {len(subjects_interface.nth_points)}')\n",
    "print(f'#total_points: {sum(len(points) for n, points in subjects_interface.nth_points.items())}')\n",
    "\n",
    "#[len(points) for n, points in subjects_interface.nth_points.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-congress",
   "metadata": {},
   "source": [
    "## GRAM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exact-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tensorboard/20211212-085642\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "daily_tracer = \"/tmp/tensorboard/\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "print(daily_tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlike-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logs = '/tmp/tensorboard/20210708-182059'\n",
    "#server = jax.profiler.start_server(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outside-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# config = {\n",
    "#     'gram_config': {\n",
    "#         'diag': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh', #l2, tanh\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': diag_glove_rep\n",
    "#         },\n",
    "#         'proc': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh',\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': proc_glove_rep\n",
    "#         }\n",
    "#     },\n",
    "#     'model': {\n",
    "#         'ode_dyn': 'mlp', # gru, mlp\n",
    "#         'state_size': 50,\n",
    "#         'numeric_hidden_size': 50,\n",
    "#         'bias': True\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'train_validation_split': 0.8,\n",
    "#         'batch_size': 4,\n",
    "#         'epochs': 200,\n",
    "#         'lr': 1e-3,\n",
    "#         'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "#         'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "#         'loss_mixing': {\n",
    "#             'num_alpha': 0.1,\n",
    "#             'diag_alpha': 0.1,\n",
    "#             'ode_alpha': 1e-3,\n",
    "#             'l1_reg': 1e-6,\n",
    "#             'l2_reg': 1e-5,\n",
    "#             'dyn_reg': 1e-5\n",
    "#         },\n",
    "#         'eval_freq': 10,\n",
    "#         'save_freq': 100,\n",
    "#         'save_params_prefix': None\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floating-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "config = {\n",
    "    'gram_config': {\n",
    "        'diag': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "            'attention_method': 'tanh', #l2, tanh\n",
    "            'attention_dim': 150,\n",
    "            'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': diag_glove_rep\n",
    "        },\n",
    "        'proc': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "            'attention_method': 'tanh',\n",
    "            'attention_dim': 100,\n",
    "            'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': proc_glove_rep\n",
    "        }\n",
    "    },\n",
    "    'model': {\n",
    "        'ode_dyn': 'gru', # gru, mlp, res\n",
    "        'ode_depth': 2,\n",
    "        'state_size': 120,\n",
    "        'numeric_hidden_size': 200,\n",
    "        'init_depth': 2,\n",
    "        'bias': True,\n",
    "        'max_odeint_days': 8 * 7 # two months\n",
    "    },\n",
    "    'training': {\n",
    "        'train_validation_split': 0.8,\n",
    "        'batch_size': 20,\n",
    "        'epochs': 200,\n",
    "        'lr': 1e-3,\n",
    "        'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "        'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "        'loss_mixing': {\n",
    "            'num_alpha': 0.1,\n",
    "            'diag_alpha': 0.1,\n",
    "            'ode_alpha': 1e-6,\n",
    "            'l1_reg': 1e-6,\n",
    "            'l2_reg': 1e-5,\n",
    "            'dyn_reg': 1e3\n",
    "        },\n",
    "        'eval_freq': 5,\n",
    "        'save_freq': 100,\n",
    "        'save_params_prefix': None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "handled-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_gram = gram.DAGGRAM(**config['gram_config']['diag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "framed-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gram = gram.DAGGRAM(**config['gram_config']['proc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-dress",
   "metadata": {},
   "source": [
    "## GRU-ODE-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dried-corporation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ode:#params: 731364\n",
      "INFO:ode:shape(params): {'diag_gram': ((589, 100), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (150,), 'w': (200, 150)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (150, 1)}),\n",
      "})), 'f_dec': FlatMap({\n",
      "  'f_dec/~/lin_gram': FlatMap({'b': (100,), 'w': (150, 100)}),\n",
      "  'f_dec/~/lin_h_hidden': FlatMap({'b': (50,), 'w': (120, 50)}),\n",
      "  'f_dec/~/lin_num_hidden1': FlatMap({'b': (50,), 'w': (550, 50)}),\n",
      "  'f_dec/~/lin_num_hidden2': FlatMap({'b': (100,), 'w': (50, 100)}),\n",
      "  'f_dec/~/lin_out': FlatMap({'b': (284,), 'w': (100, 284)}),\n",
      "}), 'f_num': FlatMap({\n",
      "  'f_numeric/linear': FlatMap({'b': (200,), 'w': (120, 200)}),\n",
      "  'f_numeric/~/linear': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "  'f_numeric/~/linear_1': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "}), 'f_state_init': FlatMap({\n",
      "  'f_init/~/lin_0': FlatMap({'b': (100,), 'w': (110, 100)}),\n",
      "  'f_init/~/lin_1': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_out': FlatMap({'b': (120,), 'w': (100, 120)}),\n",
      "}), 'gru_bayes': FlatMap({\n",
      "  'gru_bayes/~/gru': FlatMap({'b': (360,), 'w_h': (120, 360), 'w_i': (120, 360)}),\n",
      "  'gru_bayes/~/gru_bayes_prep1': FlatMap({'b': (120,), 'w': (650, 120)}),\n",
      "  'gru_bayes/~/gru_bayes_prep2': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "}), 'ode_dyn': FlatMap({\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/hc_r': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/hc_z': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/rhc_g': FlatMap({'b': (120,), 'w': (190, 120)}),\n",
      "}), 'proc_gram': ((345, 60), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (100,), 'w': (120, 100)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (100, 1)}),\n",
      "}))}\n",
      "info retrieval:   0%|                                                                                                                                              | 1/35470 [06:25<3801:48:49, 385.87s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss      0.070995286   0.0016156828\n",
      "postjump_num_loss      0.30212548    0.007251174\n",
      "prejump_diag_loss    6.557723e-05  1.3592745e-06\n",
      "postjump_diag_loss   6.569696e-05  1.3603112e-06\n",
      "num_loss              0.094108306    0.002179232\n",
      "diag_loss             6.55892e-05  1.3593781e-06\n",
      "ode_loss             6.568324e-05   1.361556e-06\n",
      "l1_loss                 31997.793      31997.793\n",
      "l2_loss                 2786.3584      2786.3584\n",
      "dyn_loss               0.04055871      2.1379366\n",
      "dyn_loss_per_week   0.00013199022  0.00014273573\n",
      "loss                   0.19191729     0.20259845\n",
      "INFO:ode:\n",
      "                         Training  Valdation\n",
      "accuracy                 0.476688   0.472396\n",
      "recall                   0.517241   0.552463\n",
      "npv                      0.960664    0.96709\n",
      "specificity              0.475054   0.469537\n",
      "precision                0.038186   0.035851\n",
      "f1-score                 0.071121   0.067332\n",
      "tp                       0.020034   0.019045\n",
      "tn                       0.456654   0.453351\n",
      "fp                       0.504614   0.512177\n",
      "fn                       0.018698   0.015428\n",
      "all_points_count              581      25331\n",
      "integrable_points_count       527      23785\n",
      "predictable_count              20        964\n",
      "odeint weeks/point       0.583085   0.629737\n",
      "nfe/point                27.42315  27.650284\n",
      "nfe/week                 47.03115  43.907692\n",
      "nfex1000                   14.452    657.662\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=66 C=198)  0.030303   0.045455\n",
      "P1(N=67 C=31)   0.029851   0.104478\n",
      "P2(N=75 C=17)   0.053333   0.053333\n",
      "P3(N=79 C=10)   0.126582   0.101266\n",
      "P4(N=98 C=7)    0.091837   0.040816\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.102960   0.088481\n",
      "P1(N=3383 C=31)   0.073012   0.086314\n",
      "P2(N=3284 C=17)   0.063337   0.061510\n",
      "P3(N=3168 C=10)   0.096275   0.132260\n",
      "P4(N=3603 C=7)    0.059950   0.023036\n",
      "info retrieval:   0%|                                                                                                                                                | 6/35470 [11:56<707:01:25, 71.77s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss        0.0553393  0.00067163346\n",
      "postjump_num_loss      0.47278124   0.0068434863\n",
      "prejump_diag_loss   8.9253896e-05   1.360891e-06\n",
      "postjump_diag_loss   8.756777e-05  1.3547275e-06\n",
      "num_loss              0.097083494   0.0012888187\n",
      "diag_loss            8.908528e-05  1.3602746e-06\n",
      "ode_loss             8.918228e-05  1.3615621e-06\n",
      "l1_loss                 31241.725      31241.725\n",
      "l2_loss                 2680.7393      2680.7393\n",
      "dyn_loss              0.006596254      0.4452143\n",
      "dyn_loss_per_week    3.309948e-05  2.9723982e-05\n",
      "loss                   0.09123778    0.087774456\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                  0.458017    0.46772\n",
      "recall                    0.524793   0.594517\n",
      "npv                       0.965875   0.969693\n",
      "specificity               0.455755   0.463193\n",
      "precision                 0.031639   0.038037\n",
      "f1-score                   0.05968     0.0715\n",
      "tp                        0.017199   0.020494\n",
      "tn                        0.440818   0.447226\n",
      "fp                        0.526408   0.518302\n",
      "fn                        0.015574   0.013978\n",
      "all_points_count               406      25331\n",
      "integrable_points_count        371      23785\n",
      "predictable_count               15        964\n",
      "odeint weeks/point        0.537158   0.629737\n",
      "nfe/point                 25.87062   27.01686\n",
      "nfe/week                 48.162006  42.901836\n",
      "nfex1000                     9.598    642.596\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=48 C=198)  0.083333   0.062500\n",
      "P1(N=63 C=31)   0.063492   0.031746\n",
      "P2(N=60 C=17)   0.066667   0.066667\n",
      "P3(N=47 C=10)   0.063830   0.170213\n",
      "P4(N=71 C=7)    0.000000   0.028169\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.095238   0.079472\n",
      "P1(N=3383 C=31)   0.060006   0.051434\n",
      "P2(N=3284 C=17)   0.067905   0.068210\n",
      "P3(N=3168 C=10)   0.069760   0.132891\n",
      "P4(N=3603 C=7)    0.005828   0.044685\n",
      "info retrieval:   0%|                                                                                                                                               | 11/35470 [20:10<943:48:08, 95.82s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss      0.061124127  0.00073543086\n",
      "postjump_num_loss      0.63555014    0.008041053\n",
      "prejump_diag_loss    6.849258e-05  1.3570902e-06\n",
      "postjump_diag_loss   6.872014e-05  1.3528389e-06\n",
      "num_loss               0.11856673    0.001465993\n",
      "diag_loss           6.8515335e-05  1.3566652e-06\n",
      "ode_loss             6.863383e-05  1.3581298e-06\n",
      "l1_loss                 30487.855      30487.855\n",
      "l2_loss                  2579.755       2579.755\n",
      "dyn_loss             0.0027453573     0.22522128\n",
      "dyn_loss_per_week   1.8549712e-05  1.5036519e-05\n",
      "loss                   0.07490375    0.071323276\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                  0.483333   0.491302\n",
      "recall                    0.558923   0.569676\n",
      "npv                       0.967916   0.969508\n",
      "specificity               0.480603   0.488504\n",
      "precision                 0.037413   0.038243\n",
      "f1-score                  0.070131   0.071675\n",
      "tp                        0.019484   0.019638\n",
      "tn                         0.46385   0.471664\n",
      "fp                        0.501291   0.493864\n",
      "fn                        0.015376   0.014834\n",
      "all_points_count               371      25331\n",
      "integrable_points_count        340      23785\n",
      "predictable_count               19        964\n",
      "odeint weeks/point        0.435294   0.629737\n",
      "nfe/point                23.688236  26.430355\n",
      "nfe/week                  54.41892   41.97049\n",
      "nfex1000                     8.054    628.646\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=62 C=198)  0.064516   0.080645\n",
      "P1(N=63 C=31)   0.000000   0.000000\n",
      "P2(N=84 C=17)   0.035714   0.023810\n",
      "P3(N=62 C=10)   0.080645   0.016129\n",
      "P4(N=79 C=7)    0.000000   0.000000\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.103925   0.092664\n",
      "P1(N=3383 C=31)   0.044339   0.041383\n",
      "P2(N=3284 C=17)   0.042631   0.033800\n",
      "P3(N=3168 C=10)   0.054293   0.094697\n",
      "P4(N=3603 C=7)    0.003886   0.016930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "info retrieval:   0%|                                                                                                                                               | 16/35470 [26:11<605:24:14, 61.47s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss      0.044911113   0.0008288295\n",
      "postjump_num_loss      0.57457197    0.010238781\n",
      "prejump_diag_loss    5.438247e-05  1.3535994e-06\n",
      "postjump_diag_loss     5.4159e-05  1.3507238e-06\n",
      "num_loss                0.0978772   0.0017698247\n",
      "diag_loss           5.4360124e-05  1.3533117e-06\n",
      "ode_loss            5.4457945e-05  1.3550803e-06\n",
      "l1_loss                 29784.697      29784.697\n",
      "l2_loss                 2491.8083      2491.8083\n",
      "dyn_loss              0.002805458      0.1452004\n",
      "dyn_loss_per_week   1.0678741e-05   9.694059e-06\n",
      "loss                  0.065435976      0.0643982\n",
      "INFO:ode:\n",
      "                          Training  Valdation\n",
      "accuracy                    0.4682   0.465236\n",
      "recall                    0.624277   0.611008\n",
      "npv                       0.968817   0.970695\n",
      "specificity               0.462022   0.460032\n",
      "precision                 0.043911   0.038831\n",
      "f1-score                  0.082051   0.073022\n",
      "tp                        0.023768   0.021063\n",
      "tn                        0.444432   0.444174\n",
      "fp                        0.517496   0.521354\n",
      "fn                        0.014305   0.013409\n",
      "all_points_count               518      25331\n",
      "integrable_points_count        468      23785\n",
      "predictable_count               24        964\n",
      "odeint weeks/point        0.561355   0.629737\n",
      "nfe/point                29.435898  26.180618\n",
      "nfe/week                  52.43719  41.573914\n",
      "nfex1000                    13.776    622.706\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=83 C=198)  0.132530   0.108434\n",
      "P1(N=90 C=31)   0.044444   0.033333\n",
      "P2(N=68 C=17)   0.014706   0.014706\n",
      "P3(N=60 C=10)   0.066667   0.116667\n",
      "P4(N=81 C=7)    0.012346   0.037037\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.122265   0.117761\n",
      "P1(N=3383 C=31)   0.035471   0.041383\n",
      "P2(N=3284 C=17)   0.050548   0.027406\n",
      "P3(N=3168 C=10)   0.084912   0.114268\n",
      "P4(N=3603 C=7)    0.023314   0.036914\n",
      "  0%|                                                                                                                                                               | 20/35470 [28:49<622:28:25, 63.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid value encountered in the output of a jit/pmap-ed function. Calling the de-optimized version.\n",
      "Invalid value encountered in the output of a jit/pmap-ed function. Calling the de-optimized version.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:ode:ValueError exception raised: Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 690, in _xla_call_impl\n",
      "    out = compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in transpose(jvp(apply_fn))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 690, in _xla_call_impl\n",
      "    out = compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in transpose(jvp(_odeint_wrapper))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/traitlets/config/application.py\", line 846, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 677, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/base_events.py\", line 596, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/base_events.py\", line 1890, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 457, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 446, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 353, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 648, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 353, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2901, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2947, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3172, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3364, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3444, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_148847/1314418325.py\", line 8, in <module>\n",
      "    res = train.train_ehr(subject_interface=subjects_interface,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 925, in train_ehr\n",
      "    opt_state = update(step, train_batch, opt_state, update_batch_desc)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 882, in update\n",
      "    grads = jax.grad(loss_fn)(params, batch, iteration_text_callback)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 840, in loss_fn\n",
      "    res = ode_model(params,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 614, in __call__\n",
      "    h1, _dyn_loss, _nfe = nn_odeint(h0, delta_weeks,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 489, in <lambda>\n",
      "    nn_odeint = lambda h, t, c, s: self.__odeint(params, h, t, c,\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 346, in __odeint\n",
      "    h_r_nfe = {\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 347, in <dictcomp>\n",
      "    i: self.n_ode(params['ode_dyn'], h[i], t[i], c[i], count_nfe)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 216, in apply_fn\n",
      "    return f.apply(params, None, *args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 127, in apply_fn\n",
      "    out, state = f.apply(params, {}, *args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/transform.py\", line 383, in apply_fn\n",
      "    out = f(*args, **kwargs)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 117, in wrap\n",
      "    return model(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/module.py\", line 428, in wrapped\n",
      "    out = f(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/haiku/_src/module.py\", line 279, in run_interceptors\n",
      "    return bound_method(*args, **kwargs)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/models.py\", line 265, in __call__\n",
      "    h, r = odeint(self.ode_dyn, (h, jnp.zeros(1)), jnp.array([0.0, t]),\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 175, in odeint\n",
      "    return _odeint_wrapper(converted, rtol, atol, mxstep, y0, t, *args, *consts)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 181, in _odeint_wrapper\n",
      "    out = _odeint(func, rtol, atol, mxstep, y0, ts, *args)\n",
      "jax._src.source_info_util.JaxStackTraceBeforeTransformation: FloatingPointError: invalid value (nan) encountered in scan\n",
      "\n",
      "The preceding stack trace is the source of the JAX operation that, once transformed by JAX, triggered the following exception.\n",
      "\n",
      "--------------------\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 925, in train_ehr\n",
      "    opt_state = update(step, train_batch, opt_state, update_batch_desc)\n",
      "  File \"/home/asem/GP/MIMIC-SNONET/mimicnet/train.py\", line 882, in update\n",
      "    grads = jax.grad(loss_fn)(params, batch, iteration_text_callback)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 918, in grad_f\n",
      "    _, g = value_and_grad_f(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 1000, in value_and_grad_f\n",
      "    g = vjp_py(np.ones((), dtype=dtype))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/tree_util.py\", line 326, in <lambda>\n",
      "    func = lambda *args, **kw: original_func(*args, **kw)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/api.py\", line 2219, in _vjp_pullback_wrapper\n",
      "    ans = fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/tree_util.py\", line 326, in <lambda>\n",
      "    func = lambda *args, **kw: original_func(*args, **kw)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 123, in unbound_vjp\n",
      "    arg_cts = backward_pass(jaxpr, reduce_axes, consts, dummy_args, cts)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 222, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 558, in call_transpose\n",
      "    out_flat = primitive.bind(fun, *all_args, **new_params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1632, in bind\n",
      "    return call_bind(self, fun, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1623, in call_bind\n",
      "    outs = primitive.process(top_trace, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1635, in process\n",
      "    return trace.process_call(self, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 627, in process_call\n",
      "    return primitive.impl(f, *tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 706, in _xla_call_impl\n",
      "    _ = clone.call_wrapped(*args)  # probably won't return\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 222, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 558, in call_transpose\n",
      "    out_flat = primitive.bind(fun, *all_args, **new_params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1632, in bind\n",
      "    return call_bind(self, fun, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1623, in call_bind\n",
      "    outs = primitive.process(top_trace, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 1635, in process\n",
      "    return trace.process_call(self, fun, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 627, in process_call\n",
      "    return primitive.impl(f, *tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 706, in _xla_call_impl\n",
      "    _ = clone.call_wrapped(*args)  # probably won't return\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 228, in backward_pass\n",
      "    cts_out = get_primitive_transpose(eqn.primitive)(cts_in, *invals,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/ad.py\", line 690, in _custom_lin_transpose\n",
      "    cts_in = bwd.call_wrapped(*res, *cts_out)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
      "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/ode.py\", line 255, in _odeint_rev\n",
      "    (y_bar, t0_bar, args_bar), rev_ts_bar = lax.scan(\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
      "    return fun(*args, **kwargs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\", line 1357, in scan\n",
      "    out = scan_p.bind(*consts, *in_flat,\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/lax/control_flow.py\", line 1933, in scan_bind\n",
      "    return core.AxisPrimitive.bind(scan_p, *args, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 272, in bind\n",
      "    out = top_trace.process_primitive(self, tracers, params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\", line 624, in process_primitive\n",
      "    return primitive.impl(*tracers, **params)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 418, in apply_primitive\n",
      "    return compiled_fun(*args)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 1101, in _execute_compiled\n",
      "    check_special(name, out_bufs)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 483, in check_special\n",
      "    _check_special(name, buf.xla_shape(), buf)\n",
      "  File \"/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/interpreters/xla.py\", line 489, in _check_special\n",
      "    raise FloatingPointError(f\"invalid value (nan) encountered in {name}\")\n",
      "FloatingPointError: invalid value (nan) encountered in scan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "#with jax.profiler.trace(logs):\n",
    "res = train.train_ehr(subject_interface=subjects_interface,\n",
    "                diag_gram=diag_gram,\n",
    "                proc_gram=proc_gram,\n",
    "                rng=random.Random(42),\n",
    "                model_config=config['model'],\n",
    "                **config['training'],\n",
    "                verbose_debug=False,\n",
    "                shape_debug=False,\n",
    "                nan_debug=False,\n",
    "                memory_profile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-drinking",
   "metadata": {},
   "source": [
    "#### Possible modifications:\n",
    "- Add more layers to the adjustment function\n",
    "- Use days instead of weeks for odeint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
