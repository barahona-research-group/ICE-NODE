{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "photographic-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict \n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "\n",
    "# Global flag to set a specific platform, must be used at startup.\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "jax.config.update(\"jax_debug_infs\", True)\n",
    "\n",
    "jax.config.update('jax_log_compiles', False)\n",
    "jax.config.update('jax_check_tracer_leaks', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "latest-second",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray(499500, dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "a = jnp.array(range(1000)) \n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "later-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'mimicnet.models' from '/home/asem/GP/MIMIC-SNONET/mimicnet/models.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good read: https://iq-inc.com/importerror-attempted-relative-import/\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from mimicnet import concept\n",
    "from mimicnet import jax_interface\n",
    "from mimicnet import dag\n",
    "from mimicnet import glove\n",
    "from mimicnet import gram\n",
    "from mimicnet import train\n",
    "from mimicnet import models\n",
    "\n",
    "importlib.reload(sys.modules['mimicnet.concept'])\n",
    "importlib.reload(sys.modules['mimicnet.dag'])\n",
    "importlib.reload(sys.modules['mimicnet.jax_interface'])\n",
    "importlib.reload(sys.modules['mimicnet.glove'])\n",
    "importlib.reload(sys.modules['mimicnet.gram'])\n",
    "importlib.reload(sys.modules['mimicnet.train'])\n",
    "importlib.reload(sys.modules['mimicnet.models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chemical-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_visit_mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "multi_visit_mimic_dir = '/home/asem/GP/ehr-data/mimic3-multi-visit'\n",
    "transformed_mimic_dir = '/home/asem/GP/ehr-data/mimic3-transforms'\n",
    "mimic_dir = '/home/asem/GP/ehr-data/mimic3-v1.4/physionet.org/files/mimiciii/1.4'\n",
    "# mimic_dir = '/home/asem/GP/MIMIC-SNONET/RAW/mimic-iii-clinical-database-1.4'\n",
    "\n",
    "experiments_dir = '/home/asem/GP/ehr-data/mimic3-snonet-exp'\n",
    "experiment_prefix = 'DEC03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-idaho",
   "metadata": {},
   "source": [
    "### [FORK] Skip the cell below to load the jaxified data from a stored file on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fitting-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_df = pd.read_csv(f'{transformed_mimic_dir}/static_df.csv.gz')\n",
    "# adm_df = pd.read_csv(f'{transformed_mimic_dir}/adm_df.csv.gz')\n",
    "# diag_df = pd.read_csv(f'{transformed_mimic_dir}/diag_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# proc_df = pd.read_csv(f'{transformed_mimic_dir}/proc_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# test_df = pd.read_csv(f'{transformed_mimic_dir}/test_df.csv.gz')\n",
    "\n",
    "\n",
    "# # Cast columns of dates to datetime64\n",
    "\n",
    "# static_df['DOB'] = pd.to_datetime(static_df.DOB, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['ADMITTIME'] = pd.to_datetime(adm_df.ADMITTIME, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['DISCHTIME'] = pd.to_datetime(adm_df.DISCHTIME, infer_datetime_format=True).dt.normalize()\n",
    "# test_df['DATE'] = pd.to_datetime(test_df.DATE, infer_datetime_format=True).dt.normalize()\n",
    "\n",
    "\n",
    "# patients = concept.Subject.to_list(static_df, adm_df, diag_df, proc_df, test_df)\n",
    "\n",
    "# KG = dag.CCSDAG()\n",
    "\n",
    "# subjects_interface = jax_interface.SubjectJAXInterface(patients, set(test_df.ITEMID), KG)\n",
    "# import pickle\n",
    "# with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'wb') as pickleFile:\n",
    "#     pickle.dump(subjects_interface, pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adult-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'rb') as pickleFile:\n",
    "    subjects_interface = pickle.load(pickleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-sweet",
   "metadata": {},
   "source": [
    "## GloVe Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "arbitrary-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "personal-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hollywood-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_args = {\n",
    "    'diag_idx': subjects_interface.diag_multi_ccs_idx,\n",
    "    'proc_idx': subjects_interface.proc_multi_ccs_idx,\n",
    "    'ccs_dag': subjects_interface.dag,\n",
    "    'subjects': subjects_interface.subjects.values(),\n",
    "    'diag_vector_size': 100,\n",
    "    'proc_vector_size': 60,\n",
    "    'iterations': 30,\n",
    "    'window_size_days': 2 * 365\n",
    "}\n",
    "\n",
    "diag_glove_rep, proc_glove_rep = glove.glove_representation(**glove_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "french-birth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#point_indices: 1085\n",
      "#total_points: 129334\n"
     ]
    }
   ],
   "source": [
    "print(f'#point_indices: {len(subjects_interface.nth_points)}')\n",
    "print(f'#total_points: {sum(len(points) for n, points in subjects_interface.nth_points.items())}')\n",
    "\n",
    "#[len(points) for n, points in subjects_interface.nth_points.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-congress",
   "metadata": {},
   "source": [
    "## GRAM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exact-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tensorboard/20211212-080900\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "daily_tracer = \"/tmp/tensorboard/\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "print(daily_tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "unlike-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logs = '/tmp/tensorboard/20210708-182059'\n",
    "#server = jax.profiler.start_server(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "outside-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# config = {\n",
    "#     'gram_config': {\n",
    "#         'diag': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh', #l2, tanh\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': diag_glove_rep\n",
    "#         },\n",
    "#         'proc': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh',\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': proc_glove_rep\n",
    "#         }\n",
    "#     },\n",
    "#     'model': {\n",
    "#         'ode_dyn': 'mlp', # gru, mlp\n",
    "#         'state_size': 50,\n",
    "#         'numeric_hidden_size': 50,\n",
    "#         'bias': True\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'train_validation_split': 0.8,\n",
    "#         'batch_size': 4,\n",
    "#         'epochs': 200,\n",
    "#         'lr': 1e-3,\n",
    "#         'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "#         'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "#         'loss_mixing': {\n",
    "#             'num_alpha': 0.1,\n",
    "#             'diag_alpha': 0.1,\n",
    "#             'ode_alpha': 1e-3,\n",
    "#             'l1_reg': 1e-6,\n",
    "#             'l2_reg': 1e-5,\n",
    "#             'dyn_reg': 1e-5\n",
    "#         },\n",
    "#         'eval_freq': 10,\n",
    "#         'save_freq': 100,\n",
    "#         'save_params_prefix': None\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floating-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "config = {\n",
    "    'gram_config': {\n",
    "        'diag': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "            'attention_method': 'tanh', #l2, tanh\n",
    "            'attention_dim': 150,\n",
    "            'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': diag_glove_rep\n",
    "        },\n",
    "        'proc': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "            'attention_method': 'tanh',\n",
    "            'attention_dim': 100,\n",
    "            'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': proc_glove_rep\n",
    "        }\n",
    "    },\n",
    "    'model': {\n",
    "        'ode_dyn': 'mlp', # gru, mlp, res\n",
    "        'ode_depth': 2,\n",
    "        'state_size': 120,\n",
    "        'numeric_hidden_size': 200,\n",
    "        'init_depth': 2,\n",
    "        'bias': True,\n",
    "        'max_odeint_days': 8 * 7 # two months\n",
    "    },\n",
    "    'training': {\n",
    "        'train_validation_split': 0.8,\n",
    "        'batch_size': 20,\n",
    "        'epochs': 200,\n",
    "        'lr': 1e-3,\n",
    "        'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "        'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "        'loss_mixing': {\n",
    "            'num_alpha': 0.1,\n",
    "            'diag_alpha': 0.1,\n",
    "            'ode_alpha': 1e-6,\n",
    "            'l1_reg': 1e-6,\n",
    "            'l2_reg': 1e-5,\n",
    "            'dyn_reg': 1e3\n",
    "        },\n",
    "        'eval_freq': 5,\n",
    "        'save_freq': 100,\n",
    "        'save_params_prefix': None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "handled-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_gram = gram.DAGGRAM(**config['gram_config']['diag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "framed-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gram = gram.DAGGRAM(**config['gram_config']['proc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-dress",
   "metadata": {},
   "source": [
    "## GRU-ODE-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-corporation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ode:#params: 708684\n",
      "INFO:ode:shape(params): {'diag_gram': ((589, 100), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (150,), 'w': (200, 150)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (150, 1)}),\n",
      "})), 'f_dec': FlatMap({\n",
      "  'f_dec/~/lin_gram': FlatMap({'b': (100,), 'w': (150, 100)}),\n",
      "  'f_dec/~/lin_h_hidden': FlatMap({'b': (50,), 'w': (120, 50)}),\n",
      "  'f_dec/~/lin_num_hidden1': FlatMap({'b': (50,), 'w': (550, 50)}),\n",
      "  'f_dec/~/lin_num_hidden2': FlatMap({'b': (100,), 'w': (50, 100)}),\n",
      "  'f_dec/~/lin_out': FlatMap({'b': (284,), 'w': (100, 284)}),\n",
      "}), 'f_num': FlatMap({\n",
      "  'f_numeric/linear': FlatMap({'b': (200,), 'w': (120, 200)}),\n",
      "  'f_numeric/~/linear': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "  'f_numeric/~/linear_1': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "}), 'f_state_init': FlatMap({\n",
      "  'f_init/~/lin_0': FlatMap({'b': (100,), 'w': (110, 100)}),\n",
      "  'f_init/~/lin_1': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_out': FlatMap({'b': (120,), 'w': (100, 120)}),\n",
      "}), 'gru_bayes': FlatMap({\n",
      "  'gru_bayes/~/gru': FlatMap({'b': (360,), 'w_h': (120, 360), 'w_i': (120, 360)}),\n",
      "  'gru_bayes/~/gru_bayes_prep1': FlatMap({'b': (120,), 'w': (650, 120)}),\n",
      "  'gru_bayes/~/gru_bayes_prep2': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "}), 'ode_dyn': FlatMap({\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_0': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_1': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "}), 'proc_gram': ((345, 60), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (100,), 'w': (120, 100)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (100, 1)}),\n",
      "}))}\n",
      "info retrieval:   0%|                                                                                                                                              | 1/35470 [04:02<2391:49:18, 242.76s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss       0.27145815      0.0223889\n",
      "postjump_num_loss       1.1673303     0.11997444\n",
      "prejump_diag_loss    6.529091e-05  1.3624955e-06\n",
      "postjump_diag_loss   6.608942e-05  1.3677156e-06\n",
      "num_loss               0.36104536    0.032147452\n",
      "diag_loss            6.537076e-05  1.3630174e-06\n",
      "ode_loss             6.573174e-05  1.3951635e-06\n",
      "l1_loss                 31491.037      31491.037\n",
      "l2_loss                 2743.2073      2743.2073\n",
      "dyn_loss             5.895412e-11  2.6247904e-09\n",
      "dyn_loss_per_week   1.9185441e-13   1.752397e-13\n",
      "loss                  0.058988843    0.058924507\n",
      "INFO:ode:\n",
      "                     Training  Valdation\n",
      "accuracy             0.486765   0.478752\n",
      "recall               0.554859    0.60905\n",
      "npv                  0.964268   0.971401\n",
      "specificity          0.484022     0.4741\n",
      "precision             0.04153   0.039706\n",
      "f1-score             0.077276   0.074552\n",
      "tp                   0.021491   0.020995\n",
      "tn                   0.465274   0.457757\n",
      "fp                   0.495993   0.507771\n",
      "fn                   0.017241   0.013477\n",
      "all_points_count          581      25331\n",
      "odeint weeks/point   0.583085   0.629737\n",
      "nfe/point           26.580645  25.902122\n",
      "nfe/week             45.58624  41.131676\n",
      "nfex1000               14.008    616.082\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=66 C=198)  0.090909   0.121212\n",
      "P1(N=67 C=31)   0.074627   0.044776\n",
      "P2(N=75 C=17)   0.040000   0.053333\n",
      "P3(N=79 C=10)   0.063291   0.088608\n",
      "P4(N=98 C=7)    0.112245   0.071429\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3111 C=198)  0.077146   0.084217\n",
      "P1(N=3380 C=31)   0.081361   0.076923\n",
      "P2(N=3284 C=17)   0.067296   0.071255\n",
      "P3(N=3168 C=10)   0.077020   0.093750\n",
      "P4(N=3603 C=7)    0.061615   0.031918\n",
      "info retrieval:   0%|                                                                                                                                                | 6/35470 [08:33<490:43:29, 49.81s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss        0.3506149    0.026515648\n",
      "postjump_num_loss       2.5356317       0.187989\n",
      "prejump_diag_loss    8.622753e-05  1.3426716e-06\n",
      "postjump_diag_loss   8.719017e-05  1.3482321e-06\n",
      "num_loss                0.5691166    0.042662986\n",
      "diag_loss           8.6323795e-05  1.3432275e-06\n",
      "ode_loss            8.6892825e-05  1.3858892e-06\n",
      "l1_loss                  28641.53       28641.53\n",
      "l2_loss                 2445.6743      2445.6743\n",
      "dyn_loss             1.497253e-10  1.0649044e-08\n",
      "dyn_loss_per_week    7.513097e-13  7.1096547e-13\n",
      "loss                  0.053185165     0.05309966\n",
      "INFO:ode:\n",
      "                    Training  Valdation\n",
      "accuracy            0.473998   0.477452\n",
      "recall              0.628099   0.655432\n",
      "npv                 0.973822   0.974551\n",
      "specificity         0.468776   0.471098\n",
      "precision            0.03852    0.04237\n",
      "f1-score            0.072588   0.079594\n",
      "tp                  0.020585   0.022594\n",
      "tn                  0.453413   0.454858\n",
      "fp                  0.513814    0.51067\n",
      "fn                  0.012189   0.011878\n",
      "all_points_count         406      25331\n",
      "odeint weeks/point  0.537158   0.629737\n",
      "nfe/point           28.26415   28.60862\n",
      "nfe/week            52.61792  45.429497\n",
      "nfex1000              10.486    680.456\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=44 C=198)  0.022727   0.000000\n",
      "P1(N=67 C=31)   0.089552   0.089552\n",
      "P2(N=60 C=17)   0.133333   0.083333\n",
      "P3(N=47 C=10)   0.106383   0.170213\n",
      "P4(N=71 C=7)    0.028169   0.014085\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3111 C=198)  0.060109   0.075217\n",
      "P1(N=3380 C=31)   0.101183   0.078402\n",
      "P2(N=3284 C=17)   0.115104   0.101705\n",
      "P3(N=3168 C=10)   0.119003   0.112374\n",
      "P4(N=3603 C=7)    0.075215   0.045518\n",
      "info retrieval:   0%|                                                                                                                                               | 11/35470 [15:49<816:22:14, 82.88s/it]INFO:ode:\n",
      "                         Training     Validation\n",
      "prejump_num_loss        0.4929188     0.05996131\n",
      "postjump_num_loss       1.3140253     0.20106046\n",
      "prejump_diag_loss    6.845129e-05   1.332866e-06\n",
      "postjump_diag_loss   6.865832e-05  1.3432913e-06\n",
      "num_loss               0.57502943     0.07407122\n",
      "diag_loss            6.847199e-05  1.3339084e-06\n",
      "ode_loss            6.9046946e-05  1.4079782e-06\n",
      "l1_loss                 26092.713      26092.713\n",
      "l2_loss                 2176.3625      2176.3625\n",
      "dyn_loss             2.645596e-10  2.3032985e-08\n",
      "dyn_loss_per_week   1.7875649e-12  1.5377584e-12\n",
      "loss                  0.047925383    0.047857746\n",
      "INFO:ode:\n",
      "                     Training  Valdation\n",
      "accuracy             0.484742   0.490662\n",
      "recall               0.653199   0.669656\n",
      "npv                  0.974499   0.976224\n",
      "specificity          0.478657   0.484272\n",
      "precision            0.043294   0.044305\n",
      "f1-score             0.081206   0.083112\n",
      "tp                    0.02277   0.023085\n",
      "tn                   0.461972   0.467578\n",
      "fp                   0.503169    0.49795\n",
      "fn                   0.012089   0.011388\n",
      "all_points_count          371      25331\n",
      "odeint weeks/point   0.435294   0.629737\n",
      "nfe/point           27.341177  29.058903\n",
      "nfe/week             62.81081   46.14453\n",
      "nfex1000                9.296    691.166\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=59 C=198)  0.016949   0.033898\n",
      "P1(N=66 C=31)   0.106061   0.090909\n",
      "P2(N=84 C=17)   0.130952   0.059524\n",
      "P3(N=62 C=10)   0.112903   0.080645\n",
      "P4(N=79 C=7)    0.037975   0.025316\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3111 C=198)  0.059788   0.068467\n",
      "P1(N=3380 C=31)   0.099112   0.088166\n",
      "P2(N=3284 C=17)   0.129111   0.117844\n",
      "P3(N=3168 C=10)   0.102904   0.086174\n",
      "P4(N=3603 C=7)    0.104913   0.086872\n",
      "  0%|                                                                                                                                                               | 15/35470 [18:14<606:42:54, 61.60s/it]"
     ]
    }
   ],
   "source": [
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "#with jax.profiler.trace(logs):\n",
    "res = train.train_ehr(subject_interface=subjects_interface,\n",
    "                diag_gram=diag_gram,\n",
    "                proc_gram=proc_gram,\n",
    "                rng=random.Random(42),\n",
    "                model_config=config['model'],\n",
    "                **config['training'],\n",
    "                verbose_debug=False,\n",
    "                shape_debug=False,\n",
    "                nan_debug=False,\n",
    "                memory_profile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-drinking",
   "metadata": {},
   "source": [
    "#### Possible modifications:\n",
    "- Add more layers to the adjustment function\n",
    "- Use days instead of weeks for odeint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
