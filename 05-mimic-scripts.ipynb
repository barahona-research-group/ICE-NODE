{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from collections import defaultdict \n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "import jax\n",
    "\n",
    "# Global flag to set a specific platform, must be used at startup.\n",
    "jax.config.update('jax_platform_name', 'cpu')\n",
    "jax.config.update(\"jax_debug_nans\", True)\n",
    "jax.config.update(\"jax_debug_infs\", True)\n",
    "\n",
    "jax.config.update('jax_log_compiles', False)\n",
    "jax.config.update('jax_check_tracer_leaks', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-second",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "a = jnp.array(range(1000)) \n",
    "a.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "later-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/experimental/optimizers.py:28: FutureWarning: jax.experimental.optimizers is deprecated, import jax.example_libraries.optimizers instead\n",
      "  warnings.warn('jax.experimental.optimizers is deprecated, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'mimicnet.models' from '/home/asem/GP/MIMIC-SNONET/mimicnet/models.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Good read: https://iq-inc.com/importerror-attempted-relative-import/\n",
    "\n",
    "import sys\n",
    "import importlib\n",
    "from mimicnet import concept\n",
    "from mimicnet import jax_interface\n",
    "from mimicnet import dag\n",
    "from mimicnet import glove\n",
    "from mimicnet import gram\n",
    "from mimicnet import train\n",
    "from mimicnet import models\n",
    "\n",
    "importlib.reload(sys.modules['mimicnet.concept'])\n",
    "importlib.reload(sys.modules['mimicnet.dag'])\n",
    "importlib.reload(sys.modules['mimicnet.jax_interface'])\n",
    "importlib.reload(sys.modules['mimicnet.glove'])\n",
    "importlib.reload(sys.modules['mimicnet.gram'])\n",
    "importlib.reload(sys.modules['mimicnet.train'])\n",
    "importlib.reload(sys.modules['mimicnet.models'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chemical-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi_visit_mimic_dir = '/home/am8520/GP/ehr-data/mimic3-multi-visit'\n",
    "multi_visit_mimic_dir = '/home/asem/GP/ehr-data/mimic3-multi-visit'\n",
    "transformed_mimic_dir = '/home/asem/GP/ehr-data/mimic3-transforms'\n",
    "mimic_dir = '/home/asem/GP/ehr-data/mimic3-v1.4/physionet.org/files/mimiciii/1.4'\n",
    "# mimic_dir = '/home/asem/GP/MIMIC-SNONET/RAW/mimic-iii-clinical-database-1.4'\n",
    "\n",
    "experiments_dir = '/home/asem/GP/ehr-data/mimic3-snonet-exp'\n",
    "experiment_prefix = 'DEC03'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-idaho",
   "metadata": {},
   "source": [
    "### [FORK] Skip the cell below to load the jaxified data from a stored file on disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# static_df = pd.read_csv(f'{transformed_mimic_dir}/static_df.csv.gz')\n",
    "# adm_df = pd.read_csv(f'{transformed_mimic_dir}/adm_df.csv.gz')\n",
    "# diag_df = pd.read_csv(f'{transformed_mimic_dir}/diag_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# proc_df = pd.read_csv(f'{transformed_mimic_dir}/proc_df.csv.gz', dtype={'ICD9_CODE': str})\n",
    "# test_df = pd.read_csv(f'{transformed_mimic_dir}/test_df.csv.gz')\n",
    "\n",
    "\n",
    "# # Cast columns of dates to datetime64\n",
    "\n",
    "# static_df['DOB'] = pd.to_datetime(static_df.DOB, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['ADMITTIME'] = pd.to_datetime(adm_df.ADMITTIME, infer_datetime_format=True).dt.normalize()\n",
    "# adm_df['DISCHTIME'] = pd.to_datetime(adm_df.DISCHTIME, infer_datetime_format=True).dt.normalize()\n",
    "# test_df['DATE'] = pd.to_datetime(test_df.DATE, infer_datetime_format=True).dt.normalize()\n",
    "\n",
    "\n",
    "# patients = concept.Subject.to_list(static_df, adm_df, diag_df, proc_df, test_df)\n",
    "\n",
    "# KG = dag.CCSDAG()\n",
    "\n",
    "# subjects_interface = jax_interface.SubjectJAXInterface(patients, set(test_df.ITEMID), KG)\n",
    "# import pickle\n",
    "# with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'wb') as pickleFile:\n",
    "#     pickle.dump(subjects_interface, pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adult-mistake",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(f'{experiments_dir}/{experiment_prefix}_subjects_interface.pkl', 'rb') as pickleFile:\n",
    "    subjects_interface = pickle.load(pickleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-sweet",
   "metadata": {},
   "source": [
    "## GloVe Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "arbitrary-donna",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "personal-dream",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:test\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "hollywood-nursery",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_args = {\n",
    "    'diag_idx': subjects_interface.diag_multi_ccs_idx,\n",
    "    'proc_idx': subjects_interface.proc_multi_ccs_idx,\n",
    "    'ccs_dag': subjects_interface.dag,\n",
    "    'subjects': subjects_interface.subjects.values(),\n",
    "    'diag_vector_size': 100,\n",
    "    'proc_vector_size': 60,\n",
    "    'iterations': 30,\n",
    "    'window_size_days': 2 * 365\n",
    "}\n",
    "\n",
    "diag_glove_rep, proc_glove_rep = glove.glove_representation(**glove_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "french-birth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#point_indices: 1085\n",
      "#total_points: 129334\n"
     ]
    }
   ],
   "source": [
    "print(f'#point_indices: {len(subjects_interface.nth_points)}')\n",
    "print(f'#total_points: {sum(len(points) for n, points in subjects_interface.nth_points.items())}')\n",
    "\n",
    "#[len(points) for n, points in subjects_interface.nth_points.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-congress",
   "metadata": {},
   "source": [
    "## GRAM objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exact-dover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tensorboard/20211209-210259\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "daily_tracer = \"/tmp/tensorboard/\"+ datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "print(daily_tracer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unlike-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "logs = '/tmp/tensorboard/20210708-182059'\n",
    "#server = jax.profiler.start_server(9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "# config = {\n",
    "#     'gram_config': {\n",
    "#         'diag': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh', #l2, tanh\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': diag_glove_rep\n",
    "#         },\n",
    "#         'proc': {\n",
    "#             'ccs_dag': KG,\n",
    "#             'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "#             'attention_method': 'tanh',\n",
    "#             'attention_dim': 50,\n",
    "#             'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "#             'basic_embeddings': proc_glove_rep\n",
    "#         }\n",
    "#     },\n",
    "#     'model': {\n",
    "#         'ode_dyn': 'mlp', # gru, mlp\n",
    "#         'state_size': 50,\n",
    "#         'numeric_hidden_size': 50,\n",
    "#         'bias': True\n",
    "#     },\n",
    "#     'training': {\n",
    "#         'train_validation_split': 0.8,\n",
    "#         'batch_size': 4,\n",
    "#         'epochs': 200,\n",
    "#         'lr': 1e-3,\n",
    "#         'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "#         'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "#         'loss_mixing': {\n",
    "#             'num_alpha': 0.1,\n",
    "#             'diag_alpha': 0.1,\n",
    "#             'ode_alpha': 1e-3,\n",
    "#             'l1_reg': 1e-6,\n",
    "#             'l2_reg': 1e-5,\n",
    "#             'dyn_reg': 1e-5\n",
    "#         },\n",
    "#         'eval_freq': 10,\n",
    "#         'save_freq': 100,\n",
    "#         'save_params_prefix': None\n",
    "#     }\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "floating-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "       \n",
    "config = {\n",
    "    'gram_config': {\n",
    "        'diag': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.diag_multi_ccs_idx,\n",
    "            'attention_method': 'tanh', #l2, tanh\n",
    "            'attention_dim': 150,\n",
    "            'ancestors_mat': subjects_interface.diag_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': diag_glove_rep\n",
    "        },\n",
    "        'proc': {\n",
    "            'ccs_dag': subjects_interface.dag,\n",
    "            'code2index': subjects_interface.proc_multi_ccs_idx,\n",
    "            'attention_method': 'tanh',\n",
    "            'attention_dim': 100,\n",
    "            'ancestors_mat': subjects_interface.proc_multi_ccs_ancestors_mat,\n",
    "            'basic_embeddings': proc_glove_rep\n",
    "        }\n",
    "    },\n",
    "    'model': {\n",
    "        'ode_dyn': 'mlp', # gru, mlp, res\n",
    "        'ode_depth': 5,\n",
    "        'ode_quad': True,\n",
    "        'state_size': 120,\n",
    "        'numeric_quad': True,\n",
    "        'numeric_hidden_size': 200,\n",
    "        'gru_bayes_quad': True,\n",
    "        'init_depth': 4,\n",
    "        'bias': True\n",
    "    },\n",
    "    'training': {\n",
    "        'train_validation_split': 0.8,\n",
    "        'batch_size': 20,\n",
    "        'epochs': 200,\n",
    "        'lr': 1e-3,\n",
    "        'diag_loss': 'balanced_focal', # balanced_focal, bce\n",
    "        'tay_reg': 3, # Order of regularized derivative of the dynamics function (None for disable).\n",
    "        'loss_mixing': {\n",
    "            'num_alpha': 0.1,\n",
    "            'diag_alpha': 0.1,\n",
    "            'ode_alpha': 1e-6,\n",
    "            'l1_reg': 1e-6,\n",
    "            'l2_reg': 1e-5,\n",
    "            'dyn_reg': 1e3\n",
    "        },\n",
    "        'eval_freq': 5,\n",
    "        'save_freq': 100,\n",
    "        'save_params_prefix': None\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "handled-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_gram = gram.DAGGRAM(**config['gram_config']['diag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "framed-romance",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_gram = gram.DAGGRAM(**config['gram_config']['proc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-dress",
   "metadata": {},
   "source": [
    "## GRU-ODE-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dried-corporation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:ode:#params: 894484\n",
      "INFO:ode:shape(params): {'diag_gram': ((589, 100), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (150,), 'w': (200, 150)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (150, 1)}),\n",
      "})), 'f_dec': FlatMap({\n",
      "  'f_dec/~/lin_gram': FlatMap({'b': (100,), 'w': (150, 100)}),\n",
      "  'f_dec/~/lin_h_hidden': FlatMap({'b': (50,), 'w': (120, 50)}),\n",
      "  'f_dec/~/lin_num_hidden1': FlatMap({'b': (50,), 'w': (550, 50)}),\n",
      "  'f_dec/~/lin_num_hidden2': FlatMap({'b': (100,), 'w': (50, 100)}),\n",
      "  'f_dec/~/lin_out': FlatMap({'b': (284,), 'w': (100, 284)}),\n",
      "}), 'f_num': FlatMap({\n",
      "  'f_numeric/augment/linear': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "  'f_numeric/linear': FlatMap({'b': (200,), 'w': (240, 200)}),\n",
      "  'f_numeric/~/linear': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "  'f_numeric/~/linear_1': FlatMap({'b': (550,), 'w': (200, 550)}),\n",
      "}), 'f_state_init': FlatMap({\n",
      "  'f_init/~/lin_0': FlatMap({'b': (100,), 'w': (110, 100)}),\n",
      "  'f_init/~/lin_1': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_2': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_3': FlatMap({'b': (100,), 'w': (100, 100)}),\n",
      "  'f_init/~/lin_out': FlatMap({'b': (120,), 'w': (100, 120)}),\n",
      "}), 'gru_bayes': FlatMap({\n",
      "  'gru_bayes/input_augment/linear': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "  'gru_bayes/state_augment/linear': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "  'gru_bayes/~/gru': FlatMap({'b': (360,), 'w_h': (120, 360), 'w_i': (120, 360)}),\n",
      "  'gru_bayes/~/gru_bayes_prep1': FlatMap({'b': (120,), 'w': (650, 120)}),\n",
      "  'gru_bayes/~/gru_bayes_prep2': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "}), 'ode_dyn': FlatMap({\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/quad_augment/linear': FlatMap({'b': (120,), 'w': (120, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_0': FlatMap({'b': (120,), 'w': (311, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_1': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_2': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_3': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "  'n_ode/~/ode_dyn_augment/~/ode_dyn/~/lin_4': FlatMap({'b': (120,), 'w': (191, 120)}),\n",
      "}), 'proc_gram': ((345, 60), FlatMap({\n",
      "  'None_DAG_Attention/~/linear': FlatMap({'b': (100,), 'w': (120, 100)}),\n",
      "  'None_DAG_Attention/~/linear_1': FlatMap({'w': (100, 1)}),\n",
      "}))}\n",
      "info retrieval:   0%|                                                                                                                                              | 1/35470 [11:20<6708:27:26, 680.89s/it]INFO:ode:\n",
      "                   Training Validation\n",
      "prejump_num_loss        nan        nan\n",
      "postjump_num_loss       nan        nan\n",
      "prejump_diag_loss       nan        nan\n",
      "postjump_diag_loss      nan        nan\n",
      "num_loss                nan        nan\n",
      "diag_loss               nan        nan\n",
      "ode_loss                nan        nan\n",
      "l1_loss                 nan        nan\n",
      "l1_loss_per_point       nan        nan\n",
      "l2_loss                 nan        nan\n",
      "l2_loss_per_point       nan        nan\n",
      "dyn_loss                nan        nan\n",
      "dyn_loss_per_week       nan        nan\n",
      "loss                    nan        nan\n",
      "INFO:ode:\n",
      "                         Training   Valdation\n",
      "accuracy                 0.962344    0.963007\n",
      "recall                        0.0         0.0\n",
      "npv                      0.962344    0.963007\n",
      "specificity                   1.0         1.0\n",
      "precision                     NaN         NaN\n",
      "f1-score                      0.0         0.0\n",
      "tp                            0.0         0.0\n",
      "tn                       0.962344    0.963007\n",
      "fp                            0.0         0.0\n",
      "fn                       0.037656    0.036993\n",
      "points_count                  581       25331\n",
      "odeint_weeks_per_point     3.3612    3.850815\n",
      "nfe_per_point                 2.0         2.0\n",
      "nfe_per_week            0.5950256  0.51937056\n",
      "nfex1000                    1.162      50.662\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=66 C=198)  0.000000   0.000000\n",
      "P1(N=67 C=31)   0.089552   0.089552\n",
      "P2(N=75 C=17)   0.080000   0.080000\n",
      "P3(N=79 C=10)   0.000000   0.000000\n",
      "P4(N=98 C=7)    0.000000   0.000000\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.031210   0.031210\n",
      "P1(N=3383 C=31)   0.058824   0.058824\n",
      "P2(N=3284 C=17)   0.059074   0.059074\n",
      "P3(N=3168 C=10)   0.000000   0.000000\n",
      "P4(N=3603 C=7)    0.000000   0.000000\n",
      "info retrieval:   0%|                                                                                                                                                | 6/35470 [14:38<769:54:25, 78.15s/it]INFO:ode:\n",
      "                   Training Validation\n",
      "prejump_num_loss        nan        nan\n",
      "postjump_num_loss       nan        nan\n",
      "prejump_diag_loss       nan        nan\n",
      "postjump_diag_loss      nan        nan\n",
      "num_loss                nan        nan\n",
      "diag_loss               nan        nan\n",
      "ode_loss                nan        nan\n",
      "l1_loss                 nan        nan\n",
      "l1_loss_per_point       nan        nan\n",
      "l2_loss                 nan        nan\n",
      "l2_loss_per_point       nan        nan\n",
      "dyn_loss                nan        nan\n",
      "dyn_loss_per_week       nan        nan\n",
      "loss                    nan        nan\n",
      "INFO:ode:\n",
      "                          Training   Valdation\n",
      "accuracy                  0.967174    0.963007\n",
      "recall                         0.0         0.0\n",
      "npv                       0.967174    0.963007\n",
      "specificity                    1.0         1.0\n",
      "precision                      NaN         NaN\n",
      "f1-score                       0.0         0.0\n",
      "tp                             0.0         0.0\n",
      "tn                        0.967174    0.963007\n",
      "fp                             0.0         0.0\n",
      "fn                        0.032826    0.036993\n",
      "points_count                   406       25331\n",
      "odeint_weeks_per_point    5.899015    3.850815\n",
      "nfe_per_point                  2.0         2.0\n",
      "nfe_per_week            0.33903965  0.51937056\n",
      "nfex1000                     0.812      50.662\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=48 C=198)  0.062500   0.062500\n",
      "P1(N=63 C=31)   0.047619   0.047619\n",
      "P2(N=60 C=17)   0.100000   0.100000\n",
      "P3(N=47 C=10)   0.000000   0.000000\n",
      "P4(N=71 C=7)    0.000000   0.000000\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.031210   0.031210\n",
      "P1(N=3383 C=31)   0.058824   0.058824\n",
      "P2(N=3284 C=17)   0.059074   0.059074\n",
      "P3(N=3168 C=10)   0.000000   0.000000\n",
      "P4(N=3603 C=7)    0.000000   0.000000\n",
      "info retrieval:   0%|                                                                                                                                               | 11/35470 [19:53<670:09:24, 68.04s/it]INFO:ode:\n",
      "                   Training Validation\n",
      "prejump_num_loss        nan        nan\n",
      "postjump_num_loss       nan        nan\n",
      "prejump_diag_loss       nan        nan\n",
      "postjump_diag_loss      nan        nan\n",
      "num_loss                nan        nan\n",
      "diag_loss               nan        nan\n",
      "ode_loss                nan        nan\n",
      "l1_loss                 nan        nan\n",
      "l1_loss_per_point       nan        nan\n",
      "l2_loss                 nan        nan\n",
      "l2_loss_per_point       nan        nan\n",
      "dyn_loss                nan        nan\n",
      "dyn_loss_per_week       nan        nan\n",
      "loss                    nan        nan\n",
      "INFO:ode:\n",
      "                          Training   Valdation\n",
      "accuracy                  0.964789    0.963007\n",
      "recall                         0.0         0.0\n",
      "npv                       0.964789    0.963007\n",
      "specificity                    1.0         1.0\n",
      "precision                      NaN         NaN\n",
      "f1-score                       0.0         0.0\n",
      "tp                             0.0         0.0\n",
      "tn                        0.964789    0.963007\n",
      "fp                             0.0         0.0\n",
      "fn                        0.035211    0.036993\n",
      "points_count                   371       25331\n",
      "odeint_weeks_per_point    5.918367    3.850815\n",
      "nfe_per_point                  2.0         2.0\n",
      "nfe_per_week            0.33793104  0.51937056\n",
      "nfex1000                     0.742      50.662\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=62 C=198)  0.016129   0.016129\n",
      "P1(N=63 C=31)   0.031746   0.031746\n",
      "P2(N=84 C=17)   0.083333   0.083333\n",
      "P3(N=62 C=10)   0.000000   0.000000\n",
      "P4(N=79 C=7)    0.000000   0.000000\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.031210   0.031210\n",
      "P1(N=3383 C=31)   0.058824   0.058824\n",
      "P2(N=3284 C=17)   0.059074   0.059074\n",
      "P3(N=3168 C=10)   0.000000   0.000000\n",
      "P4(N=3603 C=7)    0.000000   0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "info retrieval:   0%|                                                                                                                                               | 16/35470 [23:04<369:53:34, 37.56s/it]INFO:ode:\n",
      "                   Training Validation\n",
      "prejump_num_loss        nan        nan\n",
      "postjump_num_loss       nan        nan\n",
      "prejump_diag_loss       nan        nan\n",
      "postjump_diag_loss      nan        nan\n",
      "num_loss                nan        nan\n",
      "diag_loss               nan        nan\n",
      "ode_loss                nan        nan\n",
      "l1_loss                 nan        nan\n",
      "l1_loss_per_point       nan        nan\n",
      "l2_loss                 nan        nan\n",
      "l2_loss_per_point       nan        nan\n",
      "dyn_loss                nan        nan\n",
      "dyn_loss_per_week       nan        nan\n",
      "loss                    nan        nan\n",
      "INFO:ode:\n",
      "                         Training   Valdation\n",
      "accuracy                 0.962637    0.963007\n",
      "recall                        0.0         0.0\n",
      "npv                      0.962637    0.963007\n",
      "specificity                   1.0         1.0\n",
      "precision                     NaN         NaN\n",
      "f1-score                      0.0         0.0\n",
      "tp                            0.0         0.0\n",
      "tn                       0.962637    0.963007\n",
      "fp                            0.0         0.0\n",
      "fn                       0.037363    0.036993\n",
      "points_count                  518       25331\n",
      "odeint_weeks_per_point   4.737452    3.850815\n",
      "nfe_per_point                 2.0         2.0\n",
      "nfe_per_week            0.4221679  0.51937056\n",
      "nfex1000                    1.036      50.662\n",
      "INFO:ode:\n",
      "                Trn(pre)  Trn(post)\n",
      "P0(N=83 C=198)  0.024096   0.024096\n",
      "P1(N=90 C=31)   0.088889   0.088889\n",
      "P2(N=68 C=17)   0.058824   0.058824\n",
      "P3(N=60 C=10)   0.000000   0.000000\n",
      "P4(N=81 C=7)    0.000000   0.000000\n",
      "INFO:ode:\n",
      "                  Val(pre)  Val(post)\n",
      "P0(N=3108 C=198)  0.031210   0.031210\n",
      "P1(N=3383 C=31)   0.058824   0.058824\n",
      "P2(N=3284 C=17)   0.059074   0.059074\n",
      "P3(N=3168 C=10)   0.000000   0.000000\n",
      "P4(N=3603 C=7)    0.000000   0.000000\n",
      "GRAM:   0%|                                                                                                                                                         | 21/35470 [26:04<315:08:34, 32.00s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30794/1314418325.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#with jax.profiler.trace(logs):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m res = train.train_ehr(subject_interface=subjects_interface,\n\u001b[0m\u001b[1;32m      9\u001b[0m                 \u001b[0mdiag_gram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiag_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                 \u001b[0mproc_gram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproc_gram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36mtrain_ehr\u001b[0;34m(subject_interface, diag_gram, proc_gram, rng, model_config, train_validation_split, batch_size, epochs, lr, diag_loss, tay_reg, loss_mixing, eval_freq, save_freq, save_params_prefix, verbose_debug, nan_debug, shape_debug, memory_profile, **init_kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0mres_trn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrn_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mval_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn_detail\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_batch_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m             \u001b[0mres_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36mloss_fn_detail\u001b[0;34m(params, batch, iteration_text_callback)\u001b[0m\n\u001b[1;32m    717\u001b[0m     def loss_fn_detail(params: optimizers.Params, batch: List[int],\n\u001b[1;32m    718\u001b[0m                        iteration_text_callback: Any) -> Dict[str, float]:\n\u001b[0;32m--> 719\u001b[0;31m         res = ode_model(params,\n\u001b[0m\u001b[1;32m    720\u001b[0m                         \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m                         \u001b[0mcount_nfe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, params, subjects_batch, return_path, count_nfe, iteration_text_callback)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0miter_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'point #{n}/{self.subject_interface.n_support[-1]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0miteration_text_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter_prefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mpoints_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnth_points_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpoints_n\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mdiag_emb_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_emb_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__generate_embedding_mats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         nth_points_fn = lambda n: self.__extract_nth_points(\n\u001b[0m\u001b[1;32m    462\u001b[0m             \u001b[0mdiag_emb_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproc_emb_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubjects_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             iteration_text_callback)  # (n)\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36m__extract_nth_points\u001b[0;34m(self, diag_emb_mat, proc_emb_mat, n, subjects_batch, progress_callback)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode_control_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mode_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_ode_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         return {\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode_control_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0mode_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_ode_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         return {\n",
      "\u001b[0;32m~/GP/MIMIC-SNONET/mimicnet/train.py\u001b[0m in \u001b[0;36m_ode_control\u001b[0;34m(subject_id)\u001b[0m\n\u001b[1;32m    314\u001b[0m                 \u001b[0;34m'static'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubject_interface\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubject_static\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubject_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             }\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode_control_passes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mode_control\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_ode_control\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpoints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m   3422\u001b[0m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3423\u001b[0m     \u001b[0marr0_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3424\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marr0_ndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(arrays, axis)\u001b[0m\n\u001b[1;32m   3390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3391\u001b[0m   \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_canonicalize_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3392\u001b[0;31m   \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_promote_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3393\u001b[0m   \u001b[0;31m# lax.concatenate can be slow to compile for wide concatenations, so form a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3394\u001b[0m   \u001b[0;31m# tree of concatenations as a workaround especially for op-by-op mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_promote_dtypes\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mto_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lattice_result_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mto_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_promote_dtypes_inexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    524\u001b[0m     \u001b[0mto_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lattice_result_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0mto_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_promote_dtypes_inexact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moperand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m     return convert_element_type_p.bind(operand, new_dtype=new_dtype,\n\u001b[0m\u001b[1;32m    481\u001b[0m                                        weak_type=new_weak_type)\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mdef_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/mimic3-snonet/lib/python3.9/site-packages/jax/core.py\u001b[0m in \u001b[0;36mfull_lower\u001b[0;34m(val)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Leaked sublevel {t()}. Leaked tracer(s): {leaked_tracers}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from absl import logging\n",
    "logging.set_verbosity(logging.INFO)\n",
    "\n",
    "#with jax.profiler.trace(logs):\n",
    "res = train.train_ehr(subject_interface=subjects_interface,\n",
    "                diag_gram=diag_gram,\n",
    "                proc_gram=proc_gram,\n",
    "                rng=random.Random(42),\n",
    "                model_config=config['model'],\n",
    "                **config['training'],\n",
    "                verbose_debug=False,\n",
    "                shape_debug=False,\n",
    "                nan_debug=False,\n",
    "                memory_profile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-drinking",
   "metadata": {},
   "source": [
    "#### Possible modifications:\n",
    "- Add more layers to the adjustment function\n",
    "- Use days instead of weeks for odeint"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
