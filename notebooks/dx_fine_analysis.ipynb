{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f4d3c",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "<a name=\"outline\"></a>\n",
    "\n",
    "## Setup\n",
    "\n",
    "- [A](#seca) External Imports\n",
    "- [B](#secb) Internal Imports\n",
    "- [C](#secd) Configurations and Paths \n",
    "- [D](#sece) Patient Interface and Train/Val/Test Partitioning\n",
    "\n",
    "\n",
    "## Evaluations\n",
    "\n",
    "- [1](#sec1) Snooping/Selecting Best Models from the Validation Set\n",
    "- [2](#sec2) Top-20 Detection Accuracy on MIMIC-III (Test Set)\n",
    "- [3](#sec3) Top-20 Detection Accuracy on MIMIC-IV (Test Set)\n",
    "- [4](#sec4) Relative AUC Performance on MIMIC-III (Test Set)\n",
    "- [5](#sec5) Relative AUC Performance on MIMIC-IV (Test Set)\n",
    "- [6](#sec6) Relative AUC Performance From MIMIC-III (Training Set) to MIMIC-IV (All)\n",
    "- [7](#sec7) Relative AUC Performance From MIMIC-IV (Training Set) to MIMIC-III (All)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a491c",
   "metadata": {},
   "source": [
    "<a name=\"seca\"></a>\n",
    "\n",
    "### A External Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from upsetplot import from_contents, plot, UpSet, from_indicators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0d568",
   "metadata": {},
   "source": [
    "<a name=\"secb\"></a>\n",
    "\n",
    "### B Internal Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME = os.environ.get('HOME')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import analysis as A\n",
    "import common as C\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9340794",
   "metadata": {},
   "source": [
    "<a name=\"secc\"></a>\n",
    "\n",
    "### C Configurations and Paths [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d78296",
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_dir = {\n",
    "    'M3': f'{HOME}/GP/ehr-data/mimic3-transforms',\n",
    "    'M4': f'{HOME}/GP/ehr-data/mimic4-transforms'\n",
    "}\n",
    "\n",
    "train_dir = {\n",
    "    'GM3': f'{HOME}/GP/ehr-data/icenode-m3-exp/train_config_v0.2.25_G_M3',\n",
    "    'M3': f'{HOME}/GP/ehr-data/icenode-m3-exp/train_config_v0.2.25_M3',\n",
    "    'M4': f'{HOME}/GP/ehr-data/icenode-m4-exp/train_config_v0.2.25_M4',\n",
    "    'GM4': f'{HOME}/GP/ehr-data/icenode-m4-exp/train_config_v0.2.25_G_M4'\n",
    "}\n",
    "\n",
    "model_dir = {\n",
    "    'ICE-NODE': 'icenode_2lr',\n",
    "    'ICE-NODE_UNIFORM': 'icenode_uniform2lr',\n",
    "    'GRU': 'gru',\n",
    "    'RETAIN': 'retain',\n",
    "    'LogReg': 'window_logreg'\n",
    "}\n",
    "\n",
    "\n",
    "clfs = list(model_dir.keys())\n",
    "\n",
    "relative_auc_config = {\n",
    "    'pvalue': 0.01, \n",
    "    'min_auc': 0.9\n",
    "}\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Loma\"#, \"serif\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e347422",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'artefacts'\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d26707",
   "metadata": {},
   "source": [
    "<a name=\"secd\"></a>\n",
    "\n",
    "### D Patient Interface and Train/Val/Test Patitioning [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c24ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_interface = C.create_patient_interface(mimic_dir['M4'])\n",
    "m3_interface = C.create_patient_interface(mimic_dir['M3'])\n",
    "\n",
    "m4_train_ids, m4_valid_ids, m4_test_ids = m4_interface.random_splits(split1=0.7, split2=0.85, random_seed=42)\n",
    "m3_train_ids, m3_valid_ids, m3_test_ids = m3_interface.random_splits(split1=0.7, split2=0.85, random_seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a0902",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_percentiles = m4_interface.dx_flatccs_by_percentiles(20)\n",
    "m3_percentiles = m3_interface.dx_flatccs_by_percentiles(20)\n",
    "\n",
    "m4_train_percentiles = m4_interface.dx_flatccs_by_percentiles(20, m4_train_ids)\n",
    "m3_train_percentiles = m3_interface.dx_flatccs_by_percentiles(20, m3_train_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5de22c",
   "metadata": {},
   "source": [
    "<a name=\"sec1\"></a>\n",
    "\n",
    "## 1 Snooping/Selecting Best Models from the Validation Set [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifiers with Linear Embeddings\n",
    "clfs = (\n",
    "    'ICE-NODE', \n",
    "    'ICE-NODE_UNIFORM',\n",
    "    'GRU',\n",
    "    'RETAIN',\n",
    "    'LogReg'\n",
    ")\n",
    "\n",
    "\n",
    "# Classifiers with GRAM Embeddings\n",
    "clfsG = (\n",
    "    'ICE-NODE', \n",
    "    'ICE-NODE_UNIFORM',\n",
    "    'GRU'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_traces = A.performance_traces(data_tag='M4', \n",
    "                                 clfs=clfs, \n",
    "                                 train_dir=train_dir, \n",
    "                                 model_dir=model_dir)\n",
    "gm4_traces =  A.performance_traces(data_tag='GM4', \n",
    "                                   clfs=clfsG, \n",
    "                                   train_dir=train_dir, \n",
    "                                   model_dir=model_dir)\n",
    "\n",
    "gm3_traces =  A.performance_traces(data_tag='GM3', \n",
    "                                   clfs=clfsG, \n",
    "                                   train_dir=train_dir, \n",
    "                                   model_dir=model_dir)\n",
    "m3_traces = A.performance_traces(data_tag='M3', \n",
    "                                 clfs=clfs, \n",
    "                                 train_dir=train_dir, \n",
    "                                 model_dir=model_dir)\n",
    "\n",
    "plt_ctx = lambda : sns.plotting_context(\"poster\", font_scale=2, rc={\"lines.linewidth\": 2.5,  'grid.linestyle': '--'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a8be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"), plt_ctx():\n",
    "    g = sns.FacetGrid(data=m4_traces, row='clf', col='loss',  height=10, aspect=2, sharey=False, despine=True)\n",
    "    g.map_dataframe(sns.lineplot, 'index', 'value', 'metric', **dict(linewidth=5))\n",
    "    g.set_titles(col_template=\"{col_name}\", fontweight='bold', size=18)\n",
    "    g.add_legend()\n",
    "\n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{output_dir}/M4_performance_trace.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff4a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"), plt_ctx():\n",
    "    g = sns.FacetGrid(data=m3_traces, row='clf', col='loss',  height=10, aspect=2, sharey=False, despine=True)\n",
    "    g.map_dataframe(sns.lineplot, 'index', 'value', 'metric', **dict(linewidth=5))\n",
    "    g.set_titles(col_template=\"{col_name}\", fontweight='bold', size=18)\n",
    "    g.add_legend()\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{output_dir}/M3_performance_trace.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3481cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"), plt_ctx():\n",
    "    g = sns.FacetGrid(data=gm3_traces, row='clf', col='loss',  height=10, aspect=2, sharey=False, despine=True)\n",
    "    g.map_dataframe(sns.lineplot, 'index', 'value', 'metric', **dict(linewidth=5))\n",
    "    g.set_titles(col_template=\"{col_name}\", fontweight='bold', size=18)\n",
    "    g.add_legend()\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{output_dir}/GM3_performance_trace.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f23042",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"whitegrid\"), plt_ctx():\n",
    "    g = sns.FacetGrid(data=gm4_traces, row='clf', col='loss',  height=10, aspect=2, sharey=False, despine=True)\n",
    "    g.map_dataframe(sns.lineplot, 'index', 'value', 'metric', **dict(linewidth=5))\n",
    "    g.set_titles(col_template=\"{col_name}\", fontweight='bold', size=18)\n",
    "    g.add_legend()\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{output_dir}/GM4_performance_trace.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('> Models trained on MIMIC-III')\n",
    "m3_uAUC = A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M3', \n",
    "                               criterion='MICRO-AUC',  comp=max)\n",
    "display(m3_uAUC['summary'])\n",
    "\n",
    "print('> Models trained on MIMIC-IV')\n",
    "m4_uAUC = A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M4', \n",
    "                               criterion='MICRO-AUC',  comp=max)\n",
    "display(m4_uAUC['summary'])\n",
    "\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-III')\n",
    "gm3_uAUC = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM3',  \n",
    "                                criterion='MICRO-AUC', comp=max)\n",
    "display(gm3_uAUC['summary'])\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-IV')\n",
    "gm4_uAUC = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM4', \n",
    "                                criterion='MICRO-AUC', comp=max)\n",
    "display(gm4_uAUC['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126699ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('> Models trained on MIMIC-III')\n",
    "m3_loss =  A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M3', \n",
    "                                criterion='loss', comp=min)\n",
    "display(m3_loss['summary'])\n",
    "\n",
    "print('> Models trained on MIMIC-IV')\n",
    "m4_loss = A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M4',\n",
    "                             criterion='loss',  comp=min)\n",
    "display(m4_loss['summary'])\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-III')\n",
    "gm3_loss = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM3',\n",
    "                                criterion='loss', comp=min)\n",
    "display(gm3_loss['summary'])\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-IV')\n",
    "gm4_loss = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM4',\n",
    "                                criterion='loss', comp=min)\n",
    "display(gm4_loss['summary'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c03ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_acc(row):\n",
    "    return 1 / (1 / row.loc[list(f'ACC-P{i}' for i in range(5))]).sum()\n",
    "\n",
    "print('> Models trained on MIMIC-III')\n",
    "m3_comb = A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M3', \n",
    "                             criterion=combine_acc, comp=max)\n",
    "display(m3_comb['summary'])\n",
    "\n",
    "\n",
    "print('> Models trained on MIMIC-IV')\n",
    "m4_comb = A.get_trained_models(clfs=clfs, train_dir=train_dir, model_dir=model_dir, data_tag='M4', \n",
    "                             criterion=combine_acc, comp=max)\n",
    "display(m4_comb['summary'])\n",
    "\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-III')\n",
    "gm3_comb = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM3', \n",
    "                              criterion=combine_acc, comp=max)\n",
    "display(gm3_comb['summary'])\n",
    "\n",
    "\n",
    "print('> Models (GRAM) trained on MIMIC-IV')\n",
    "gm4_comb = A.get_trained_models(clfs=clfsG, train_dir=train_dir, model_dir=model_dir, data_tag='GM4', \n",
    "                               criterion=combine_acc, comp=max)\n",
    "display(gm4_comb['summary'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad6ecc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m3_models_uAUC = C.get_models(clfs, m3_uAUC[\"config\"], m3_uAUC[\"params\"], m3_interface)\n",
    "gm3_models_uAUC = C.get_models(clfsG, gm3_uAUC[\"config\"], gm3_uAUC[\"params\"], m3_interface)\n",
    "\n",
    "m4_models_uAUC = C.get_models(clfs, m4_uAUC[\"config\"], m4_uAUC[\"params\"], m4_interface)\n",
    "gm4_models_uAUC = C.get_models(clfsG, gm4_uAUC[\"config\"], gm4_uAUC[\"params\"], m4_interface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18973f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_models_loss = C.get_models(clfs, m3_loss[\"config\"], m3_loss[\"params\"], m3_interface)\n",
    "gm3_models_loss = C.get_models(clfsG, gm3_loss[\"config\"], gm3_loss[\"params\"], m3_interface)\n",
    "\n",
    "m4_models_loss = C.get_models(clfs, m4_loss[\"config\"], m4_loss[\"params\"], m4_interface)\n",
    "gm4_models_loss = C.get_models(clfsG, gm4_loss[\"config\"], gm4_loss[\"params\"], m4_interface)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_models_comb = C.get_models(clfs, m3_comb[\"config\"], m3_comb[\"params\"], m3_interface)\n",
    "gm3_models_comb = C.get_models(clfsG, gm3_comb[\"config\"], gm3_comb[\"params\"], m3_interface)\n",
    "\n",
    "m4_models_comb = C.get_models(clfs, m4_comb[\"config\"], m4_comb[\"params\"], m4_interface)\n",
    "gm4_models_comb = C.get_models(clfsG, gm4_comb[\"config\"], gm4_comb[\"params\"], m4_interface)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671801dd",
   "metadata": {},
   "source": [
    "### Snooping on MIMIC-III Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2308e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_val_res_uAUC = {clf: C.eval_(model, m3_valid_ids) for clf, model in m3_models_uAUC.items()} \n",
    "m3_val_res_comb = {clf: C.eval_(model, m3_valid_ids) for clf, model in m3_models_comb.items()} \n",
    "m3_val_res_loss = {clf: C.eval_(model, m3_valid_ids) for clf, model in m3_models_loss.items()} \n",
    "\n",
    "m3_val_res_all = {\n",
    "    **{f'{clf}_uAUC': res for clf, res in m3_val_res_uAUC.items()},\n",
    "    **{f'{clf}_comb': res for clf, res in m3_val_res_comb.items()},\n",
    "    **{f'{clf}_loss': res for clf, res in m3_val_res_loss.items()}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324a57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_val_auctests_all = A.codes_auc_pairwise_tests(m3_val_res_all, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_clfs = tuple(sorted(m3_val_res_all.keys()))\n",
    "content_set, indicator_df, data, common_codes, dichotomous_codes = A.relative_performance_upset(m3_val_auctests_all, selected_clfs, \n",
    "                                                                                              **relative_auc_config)\n",
    "upset_format = from_indicators(indicator_df, data=data)\n",
    "\n",
    "upset_object.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abefc5e",
   "metadata": {},
   "source": [
    "### Snooping on MIMIC-IV Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_val_res_uAUC = {clf: C.eval_(model, m4_valid_ids) for clf, model in m4_models_uAUC.items()} \n",
    "m4_val_res_comb = {clf: C.eval_(model, m4_valid_ids) for clf, model in m4_models_comb.items()} \n",
    "m4_val_res_loss = {clf: C.eval_(model, m4_valid_ids) for clf, model in m4_models_loss.items()} \n",
    "\n",
    "m4_val_res_all = {\n",
    "    **{f'{clf}_uAUC': res for clf, res in m4_val_res_uAUC.items()},\n",
    "    **{f'{clf}_comb': res for clf, res in m4_val_res_comb.items()},\n",
    "    **{f'{clf}_loss': res for clf, res in m4_val_res_loss.items()}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefe722",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_val_auctests_all = A.codes_auc_pairwise_tests(m4_val_res_all, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03eb1074",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_clfs = tuple(sorted(m4_val_res_all.keys()))\n",
    "content_set, indicator_df, data, common_codes, dichotomous_codes = A.relative_performance_upset(m4_val_auctests_all,\n",
    "                                                                                              selected_clfs, \n",
    "                                                                                              **relative_auc_config)\n",
    "upset_format = from_indicators(indicator_df, data=data)\n",
    "upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "\n",
    "upset_object.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58168a0c",
   "metadata": {},
   "source": [
    "### Snooping Conclusion\n",
    "\n",
    "In the cells above, we evaluate the model competency by the number of codes\n",
    "predicted competently compared to the other models.\n",
    "It is realized that for `GRU`, `RETAIN`, and `ICENODE_UNIFORM`, the competency is maximized by picking the\n",
    "model with minimum validation loss throughout the training iterations.\n",
    "However, `ICENODE` competency is maximized by picking the model with maximum average validation AUC throughout the training iterations. Therefore, subsequent evaluations will consider only the most competent models on the validation set, as we select in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eda8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_config = {}\n",
    "m4_params = {}\n",
    "\n",
    "m3_config = {}\n",
    "m3_params = {}\n",
    "\n",
    "gm4_config = {}\n",
    "gm4_params = {}\n",
    "\n",
    "gm3_config = {}\n",
    "gm3_params = {}\n",
    "\n",
    "selection_dicts = (m4_config, m4_params, m4_eval, \n",
    "                   m3_config, m3_params, m3_eval, \n",
    "                   gm4_config, gm4_params, gm4_eval,\n",
    "                   gm3_config, gm3_params, gm3_eval)\n",
    "\n",
    "uAUC_dicts = (m4_config_uAUC, m4_params_uAUC, m4_df_uAUC,\n",
    "              m3_config_uAUC, m3_params_uAUC, m3_df_uAUC,\n",
    "              m4_config_uAUCG, m4_params_uAUCG, m4_df_uAUCG,\n",
    "              m3_config_uAUCG, m3_params_uAUCG, m3_df_uAUCG)\n",
    "\n",
    "comb_dicts = (m4_config_comb, m4_params_comb, m4_df_comb,\n",
    "              m3_config_comb, m3_params_comb, m3_df_comb,\n",
    "              m4_config_combG, m4_params_combG, m4_df_combG,\n",
    "              m3_config_combG, m3_params_combG, m3_df_combG)\n",
    "\n",
    "\n",
    "loss_dicts = (m4_config_loss, m4_params_loss, m4_df_loss,\n",
    "              m3_config_loss, m3_params_loss, m3_df_loss,\n",
    "              m4_config_lossG, m4_params_lossG, m4_df_lossG,\n",
    "              m3_config_lossG, m3_params_lossG, m3_df_lossG)\n",
    "\n",
    "for clf in ('GRU', 'RETAIN', 'ICE-NODE', 'ICE-NODE_UNIFORM'):\n",
    "#     best_dicts = maxauc_dicts\n",
    "#     if clf == 'ICE-NODE':\n",
    "\n",
    "#     else:\n",
    "#     best_dicts = minloss_dicts\n",
    "        \n",
    "    for dict_a, dict_b in zip(selection_dicts, uAUC_dicts):\n",
    "        if clf in dict_b:\n",
    "            dict_a[clf] = dict_b[clf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19fd24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_predictor(clf, source_tag, target_tag):\n",
    "    if '/G' in clf:\n",
    "        clf = clf.replace('/G', '')\n",
    "        _params = {'M3': gm3_params[clf], 'M4': gm4_params[clf]}\n",
    "        _config = {'M3': gm3_config[clf], 'M4': gm4_config[clf]}\n",
    "    else:\n",
    "        _params = {'M3': m3_params[clf], 'M4': m4_params[clf]}\n",
    "        _config = {'M3': m3_config[clf], 'M4': m4_config[clf]}\n",
    "    _interface = {'M3': m3_interface, 'M4': m4_interface}\n",
    "\n",
    "    return A.get_model(clf=clf, \n",
    "                       config=_config[source_tag], \n",
    "                       params=_params[source_tag],\n",
    "                       interface = _interface[target_tag])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6f05b4",
   "metadata": {},
   "source": [
    "<a name=\"sec2\"></a>\n",
    "\n",
    "## 2 Top-20 Detection Accuracy on MIMIC-III (Test Set) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def styled_df(df):  \n",
    "    import numpy as np\n",
    "    pd.set_option('precision', 3)\n",
    "    def highlight_max(s, props=''):\n",
    "        return np.where(s == np.nanmax(s.values), props, '')\n",
    "    \n",
    "    s_df = df.style\n",
    "    s_df = s_df.apply(highlight_max, props='bfseries: ;color:white;background-color:darkblue', axis=0)\n",
    "    texttt = [{'selector': 'th', 'props': 'font-family: monospace;'}]\n",
    "\n",
    "    latex_str = s_df.to_latex(convert_css=True)\n",
    "    for clf in df.index.tolist():\n",
    "        latex_str = latex_str.replace(clf, f'\\\\texttt{{{clf}}}', 1)\n",
    "    latex_str = latex_str.replace('_', '\\\\_')\n",
    "    return s_df, latex_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41226b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241eae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best models results from max_auc and min_loss snapshots on the validation data.\n",
    "\n",
    "\n",
    "\n",
    "df_acc20_dict = {\n",
    "    **{clf: m3_eval[clf] for clf in ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')},\n",
    "    **{f'{clf}/G': gm3_eval[clf] for clf in ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU')},\n",
    "}\n",
    "\n",
    "df_acc20 = test_eval_table(df_acc20_dict, list(f'ACC-P{i}' for i in range(5)))\n",
    "df_acc20 = df_acc20.apply(lambda x: round(x, 3))\n",
    "df_acc20.to_csv(f'acc20_mimic3.csv')\n",
    "\n",
    "s_df, ltx_s = styled_df(df_acc20)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f1d11a",
   "metadata": {},
   "source": [
    "<a name=\"sec3\"></a>\n",
    "\n",
    "## 3 Top-20 Detection Accuracy on MIMIC-IV (Test Set) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327f332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick the best models results from max_auc and min_loss snapshots on the validation data.\n",
    "df_acc20 = {\n",
    "    clf: m4_eval[clf] for clf in ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "}\n",
    "\n",
    "df_acc20 = test_eval_table(df_acc20, list(f'ACC-P{i}' for i in range(5)))\n",
    "df_acc20 = df_acc20.apply(lambda x: round(x, 3))\n",
    "df_acc20.to_csv(f'acc20_mimic4.csv')\n",
    "\n",
    "s_df, ltx_s = styled_df(df_acc20)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6323308",
   "metadata": {},
   "source": [
    "<a name=\"sec4\"></a>\n",
    "\n",
    "## 4 Relative AUC Performance on MIMIC-III (Test Set) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "           'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "m3_predictors = {clf: cross_predictor(clf, 'M3', 'M3') for clf in m3_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5b1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m3 = {clf: eval2_(model, m3_test_ids) for clf, model in m3_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f74ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m3 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m3.items()}, fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = [col for col in auctests_m3.columns if col[:2] == 'P0']\n",
    "auctests_m3.loc[:, test_cols].isnull().max(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee80b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "upset_clfs = ['ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN']#, 'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G']\n",
    "upsetcontents_m3, upsetindicator_m3, data_m3,  _, compete_codesm3 = relative_performance_upset(auctests_m3, \n",
    "                                                                                               upset_clfs, \n",
    "                                                                                               m3_interface,\n",
    "                                                                                               m3_train_ids,\n",
    "                                                                                               **relative_auc_config)\n",
    "\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\", font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m3, data=data_m3)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(max_subset_size=1,\n",
    "                               facecolor=\"red\",\n",
    "                               edgecolor=\"red\", linewidth=3)\n",
    "\n",
    "#     upset_object.add_catplot(value='Avg. AUC', kind=\"strip\")\n",
    "#     upset_object.add_catplot(value='#codes (train)', kind=\"strip\")\n",
    "    g = upset_object.plot()\n",
    "#     g['extra1'].set_yscale('log')\n",
    "\n",
    "    current_figure = plt.gcf()\n",
    "    w, h = 3.5, 3\n",
    "    wi, hi = current_figure.get_size_inches()\n",
    "    current_figure.set_size_inches(hi*(w/h), hi)\n",
    "    current_figure.savefig(f\"upset_M3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bc591",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m3_k5, _ = evaluation_table(test_res_m3, m3_train_percentiles, top_k=5)\n",
    "results_m3_k10, _ = evaluation_table(test_res_m3, m3_train_percentiles, top_k=10)\n",
    "results_m3_k15, _ = evaluation_table(test_res_m3, m3_train_percentiles, top_k=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_acc5 = results_m3_k5.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc5 = df_acc5.apply(lambda x: round(x, 3))\n",
    "df_acc5.to_csv(f'acc5_mimic3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc5)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "\n",
    "df_acc10 = results_m3_k10.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc10 = df_acc10.apply(lambda x: round(x, 3))\n",
    "df_acc10.to_csv(f'acc10_mimic3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc10)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "\n",
    "df_acc15 = results_m3_k15.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc15 = df_acc15.apply(lambda x: round(x, 3))\n",
    "df_acc15.to_csv(f'acc15_mimic3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc15)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_tests_df = auctests_m3[auctests_m3.CODE_INDEX.isin(upsetindicator_m3[upsetindicator_m3.sum(axis=1)<7].index)]\n",
    "competing_tests_df.loc[:, [col for col in competing_tests_df.columns if col[:2]=='P0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc5a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m3.iloc[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cf5a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid_tests = auctests_m3.loc[:, test_cols].isnull().max(axis=1) > 0\n",
    "# auctests_m3[invalid_tests].transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0ab6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ['ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN']#, 'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G']\n",
    "\n",
    "ax = selected_auc_barplot(upset_clfs, competing_tests_df,  horizontal=True)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(-0.02, 1), ncol=2)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "\n",
    "current_figure = plt.gcf()\n",
    "w, h = 4, 4\n",
    "wi, hi = current_figure.get_size_inches()\n",
    "current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "current_figure.savefig(\"icenode_m3.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d43833",
   "metadata": {},
   "source": [
    "<a name=\"sec5\"></a>\n",
    "\n",
    "## 5 Relative AUC Performance on MIMIC-IV (Test Set) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76a1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relauc_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "# m4_predictors = {clf: cross_predictor(clf, 'M4', 'M4') for clf in relauc_clfs}\n",
    "\n",
    "m4_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "                'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "m4_predictors = {clf: cross_predictor(clf, 'M4', 'M4') for clf in m4_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede2567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m4 = {clf: eval2_(model, m4_test_ids) for clf, model in m4_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e98c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m4 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m4.items()}, fast=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a28ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "# upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "#                'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "\n",
    "upsetcontents_m4, upsetindicator_m4, data_m4,  _, compete_codesm4 = relative_performance_upset(auctests_m4, \n",
    "                                                                                               upset_clfs, \n",
    "                                                                                               m4_interface, \n",
    "                                                                                               m4_train_ids,\n",
    "                                                                                               **relative_auc_config)\n",
    "\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\",  font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m4, data=data_m4)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(present=['ICE-NODE'], absent=('ICE-NODE_UNIFORM', 'GRU', 'RETAIN'),\n",
    "                               edgecolor=\"red\", linewidth=3, facecolor=\"red\")\n",
    "#     upset_object.add_catplot(value='#codes (train)', kind=\"strip\")\n",
    "\n",
    "    g = upset_object.plot()\n",
    "#     g['extra1'].set_yscale('log')\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    w, h = 5, 3\n",
    "    wi, hi = current_figure.get_size_inches()\n",
    "    current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "    current_figure.savefig(f\"upset_M4.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec332ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4_k5, _ = evaluation_table(test_res_m4, m4_train_percentiles, top_k=5)\n",
    "results_m4_k10, _ = evaluation_table(test_res_m4, m4_train_percentiles, top_k=10)\n",
    "results_m4_k15, _ = evaluation_table(test_res_m4, m4_train_percentiles, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8714f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_acc5 = results_m4_k5.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc5 = df_acc5.apply(lambda x: round(x, 3))\n",
    "df_acc5.to_csv(f'acc5_mimic4.csv')\n",
    "s_df, ltx_s = styled_df(df_acc5)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "\n",
    "df_acc10 = results_m4_k10.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc10 = df_acc10.apply(lambda x: round(x, 3))\n",
    "df_acc10.to_csv(f'acc10_mimic4.csv')\n",
    "s_df, ltx_s = styled_df(df_acc10)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "\n",
    "df_acc15 = results_m4_k15.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc15 = df_acc15.apply(lambda x: round(x, 3))\n",
    "df_acc15.to_csv(f'acc15_mimic4.csv')\n",
    "s_df, ltx_s = styled_df(df_acc15)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3f0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4_excl = upsetcontents_m4['ICE-NODE'] - set.union(*list(upsetcontents_m4[clf] for clf in ('RETAIN', 'GRU', 'ICE-NODE_UNIFORM')))\n",
    "icenode_m4_excl = compete_codesm4[compete_codesm4['CODE_INDEX'].isin(icenode_m4_excl)]\n",
    "icenode_m4_excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16faeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# icenode_ratain_gru_m4 = upsetcontents_m4['ICE-NODE']\n",
    "# icenode_ratain_gru_m4 = compete_codesm4[compete_codesm4['CODE_INDEX'].isin(icenode_ratain_gru_m4)]\n",
    "# icenode_ratain_gru_m4.sort_values('AUC(ICE-NODE)', ascending=False)[['CODE_INDEX', 'N_POSITIVE_CODES', 'DESC', 'AUC(ICE-NODE)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22935ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "w, h = 4, 3\n",
    "ax = selected_auc_barplot(upset_clfs, icenode_m4_excl, horizontal=True)\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(-0.02, 1), ncol=2)\n",
    "current_figure = plt.gcf()\n",
    "w, h = 4, 4\n",
    "wi, hi = current_figure.get_size_inches()\n",
    "current_figure.set_size_inches(hi*(w/h), hi)\n",
    "\n",
    "current_figure.savefig(\"icenode_m4.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a7e699",
   "metadata": {},
   "source": [
    "<a name=\"sec7\"></a>\n",
    "\n",
    "## 7 Relative AUC Performance From MIMIC-IV (Training Set) to MIMIC-III (All) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad1247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_clfs =  ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "                'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "\n",
    "# clfs_ordered = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "m3_subjects = list(m3_interface.subjects.keys())\n",
    "m4m3_predictors = {clf: cross_predictor(clf, 'M4', 'M3') for clf in m4m3_clfs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2555b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_m4m3 = {clf: eval2_(model, m3_subjects) for clf, model in m4m3_predictors.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06aac33",
   "metadata": {},
   "outputs": [],
   "source": [
    "auctests_m4m3 = codes_auc_pairwise_tests({k: v['diag_detectability'] for k, v in test_res_m4m3.items()}, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3244ca3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN')\n",
    "\n",
    "# upset_clfs = ('ICE-NODE', 'ICE-NODE_UNIFORM', 'GRU', 'RETAIN',\n",
    "#                 'ICE-NODE/G', 'ICE-NODE_UNIFORM/G', 'GRU/G')\n",
    "\n",
    "upsetcontents_m4m3, upsetindicator_m4m3, data_m4m3,  _, compete_codesm4m3 = relative_performance_upset(auctests_m4m3, \n",
    "                                                                                                       upset_clfs, \n",
    "                                                                                                       m4_interface[clfs[0]],\n",
    "                                                                                                       m4_train_ids,\n",
    "                                                                                                       **relative_auc_config)\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\", font_scale=1.5, rc={\"font.family\": \"Loma\", \n",
    "                                                                        'axes.labelsize': 'medium',\n",
    "                                                                       'ytick.labelsize': 'medium'})\n",
    "with sns.axes_style(\"darkgrid\"), upset_ctx():\n",
    "    upset_format = from_indicators(upsetindicator_m4m3, data=data_m4m3)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    upset_object.style_subsets(present='ICE-NODE', absent=['ICE-NODE_UNIFORM', 'GRU', 'RETAIN'],\n",
    "                              edgecolor=\"red\", facecolor=\"red\")\n",
    "    # upset_object.add_catplot(value='Avg. AUC', kind=\"strip\")\n",
    "#     upset_object.add_catplot(value='#codes (train)', kind=\"strip\")\n",
    "    g = upset_object.plot()\n",
    "#     g['extra1'].set_yscale('log')\n",
    "\n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"upset_M4M3.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8862950",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_m4m3_k5, _ = evaluation_table(test_res_m4m3, m4_train_percentiles, top_k=5)\n",
    "results_m4m3_k10, _ = evaluation_table(test_res_m4m3, m4_train_percentiles, top_k=10)\n",
    "results_m4m3_k15, _ = evaluation_table(test_res_m4m3, m4_train_percentiles, top_k=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4a9042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc5 = results_m4m3_k5.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc5 = df_acc5.apply(lambda x: round(x, 3))\n",
    "df_acc5.to_csv(f'acc5_m4m3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc5)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "df_acc10 = results_m4m3_k10.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc10 = df_acc10.apply(lambda x: round(x, 3))\n",
    "df_acc10.to_csv(f'acc10_m4m3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc10)\n",
    "display(s_df)\n",
    "print(ltx_s)\n",
    "\n",
    "df_acc15 = results_m4m3_k15.loc[list(f'ACC-P{i}' for i in range(5)), :].transpose()\n",
    "df_acc15 = df_acc15.apply(lambda x: round(x, 3))\n",
    "df_acc15.to_csv(f'acc15_m4m3.csv')\n",
    "s_df, ltx_s = styled_df(df_acc15)\n",
    "display(s_df)\n",
    "print(ltx_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c06568",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4m3_excl = upsetcontents_m4m3['ICE-NODE'] - set.union(*list(upsetcontents_m4m3[clf] for clf in ('RETAIN', 'GRU', 'ICE-NODE_UNIFORM')))\n",
    "icenode_m4m3_excl = compete_codesm4m3[compete_codesm4m3['CODE_INDEX'].isin(icenode_m4m3_excl)]\n",
    "icenode_m4m3_excl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f942b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = selected_auc_barplot(upset_clfs, icenode_m4m3_excl, horizontal=True)\n",
    "\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "# ax.legend(fontsize=22, title_fontsize=32,\n",
    "#           bbox_to_anchor=(0.02, 1), ncol=2)\n",
    "plt.xticks(fontsize=30)\n",
    "plt.yticks(fontsize=30)\n",
    "ax.legend(fontsize=22, title_fontsize=32,\n",
    "          bbox_to_anchor=(1, 1.17), ncol=2)\n",
    "\n",
    "current_figure = plt.gcf()\n",
    "current_figure.savefig(\"icenode_m4m3.pdf\", bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86634c4c",
   "metadata": {},
   "source": [
    "## Trajectories for Patients with CCS codes best predicted with ICENODE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfc4c29",
   "metadata": {},
   "source": [
    "### Analyse AUC for Each Admission in the Test Partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df33d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def admissions_auc_scores(model, test_ids):\n",
    "    model, state = model\n",
    "    return model.admissions_auc_scores(state, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7affbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatccs_idx2code = {idx: code for code, idx in m4_interface[clfs[0]].diag_flatccs_idx.items()}\n",
    "flatccs_code2idx = m4_interface[clfs[0]].diag_flatccs_idx\n",
    "idx2desc = lambda idx: m4_interface[clfs[0]].dag.diag_flatccs_desc[flatccs_idx2code[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1cbeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode_visit_auc_df = admissions_auc_scores(m4_predictors['ICE-NODE'], m4_test_ids)\n",
    "m4_icenode_visit_auc_df['N_VISITS'] = m4_icenode_visit_auc_df['SUBJECT_ID'].apply(lambda i: (m4_icenode_visit_auc_df['SUBJECT_ID'] == i).sum())\n",
    "m4_visit_auc_subject = m4_icenode_visit_auc_df.groupby('SUBJECT_ID').agg({'AUC': 'mean', 'N_VISITS': 'max', 'N_CODES': ['min', 'max', 'mean', 'median'], 'INTERVALS': ['mean', 'max', 'min'], 'R/T': ['min', 'max', 'mean'] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_icenode_visit_auc_df = admissions_auc_scores(m4m3_predictors['ICE-NODE'], m3_interface[clfs[0]].subjects.keys())\n",
    "m4m3_icenode_visit_auc_df['N_VISITS'] = m4m3_icenode_visit_auc_df['SUBJECT_ID'].apply(lambda i: (m4m3_icenode_visit_auc_df['SUBJECT_ID'] == i).sum())\n",
    "m4m3_visit_auc_subject = m4m3_icenode_visit_auc_df.groupby('SUBJECT_ID').agg({'AUC': 'mean', 'N_VISITS': 'max', 'N_CODES': ['min', 'max', 'mean', 'median'], 'INTERVALS': ['mean', 'max', 'min'], 'R/T': ['min', 'max', 'mean'] })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ed05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_best_visit_auc_subjects =  m4_visit_auc_subject[(m4_visit_auc_subject.N_VISITS['max'] > 2) & (m4_visit_auc_subject.INTERVALS['max'] < 150)]\n",
    "m4m3_best_visit_auc_subjects =  m4m3_visit_auc_subject[(m4m3_visit_auc_subject.N_VISITS['max'] > 1) & (m4m3_visit_auc_subject.INTERVALS['max'] < 150)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429952cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m4_best_visit_auc_subjects), len(m4m3_best_visit_auc_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfcd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_ccs_history = {i: m4_interface[clfs[0]].diag_flatccs_history(i) for i in m4_best_visit_auc_subjects.index}\n",
    "m4m3_ccs_history = {i: m3_interface[clfs[0]].diag_flatccs_history(i) for i in m4m3_best_visit_auc_subjects.index}\n",
    "\n",
    "m4_ccs_idx_frequency = m4_interface[clfs[0]].diag_flatccs_frequency(list(m4_best_visit_auc_subjects.index))\n",
    "m3_ccs_idx_frequency = m3_interface[clfs[0]].diag_flatccs_frequency(list(m4m3_best_visit_auc_subjects.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e6927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_history_all_ccs_codes = set(map(flatccs_code2idx.get, set.union(*[set(h.keys()) for h in m4_ccs_history.values()])))\n",
    "m3_history_all_ccs_codes = set(map(flatccs_code2idx.get, set.union(*[set(h.keys()) for h in m4m3_ccs_history.values()])))\n",
    "m4_history_all_ccs_codes = {idx for idx in m4_history_all_ccs_codes if m4_ccs_idx_frequency[idx] < 10}\n",
    "m3_history_all_ccs_codes = {idx for idx in m3_history_all_ccs_codes if m3_ccs_idx_frequency[idx] < 10}\n",
    "\n",
    "len(m4_history_all_ccs_codes), len(m3_history_all_ccs_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "icenode_m4_competent = upsetcontents_m4['ICE-NODE'] \n",
    "icenode_m4_competent = auctests_m4[auctests_m4['CODE_INDEX'].isin(icenode_m4_competent)]\n",
    "icenode_m4_competent = icenode_m4_competent[['N_POSITIVE_CODES', 'AUC(ICE-NODE)', 'DESC']].sort_values('N_POSITIVE_CODES',ascending=False)\n",
    "# icenode_m4_competent.head(50)\n",
    "trajectory_ccs_codes_level2 = [\n",
    "    173, 168, 169, 156, 165, 216, 171, 100, 167\n",
    "]\n",
    "icenode_m4_competent[icenode_m4_competent.index.isin(trajectory_ccs_codes_level2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory_ccs_codes_level1 = [\n",
    "    64, #renal fail \n",
    "    6, # pulm heart dx\n",
    "    236, # ear dx \n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6524fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_ccs_history_level1 = {i: history for i, history in m4_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level1)) & set(history.keys())) > 0}\n",
    "m4m3_ccs_history_level1 = {i: history for i, history in m4m3_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level1)) & set(history.keys())) > 0}\n",
    "\n",
    "m4_ccs_history_level2 = {i: history for i, history in m4_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level2)) & set(history.keys())) > 0}\n",
    "m4m3_ccs_history_level2 = {i: history for i, history in m4m3_ccs_history.items() \n",
    "                         if len(set(map(flatccs_idx2code.get, trajectory_ccs_codes_level2)) & set(history.keys())) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fdc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(m4_ccs_history_level1), len(m4m3_ccs_history_level1), len(m4_ccs_history_level2), len(m4m3_ccs_history_level2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b952bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_cases = set(m4_ccs_history_level1.keys()) | set(m4_ccs_history_level2.keys())\n",
    "m4m3_cases = set(m4m3_ccs_history_level1.keys()) | set(m4m3_ccs_history_level2.keys())\n",
    "len(m4_cases), len(m4m3_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35ce59",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode, m4_icenode_state = m4_predictors['ICE-NODE']\n",
    "m4_trajectory = m4_icenode.sample_trajectory(m4_icenode_state, m4_cases, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfc4ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4m3_icenode, m4m3_icenode_state = m4m3_predictors['ICE-NODE']\n",
    "m4m3_trajectory = m4m3_icenode.sample_trajectory(m4m3_icenode_state, m4m3_cases, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eef088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b96e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m4_selected_subjects = [\n",
    "#     13798593, #acute-renal\n",
    "#     13965528, #acute-renal\n",
    "#     11907876, #pulmonary heart dx\n",
    "#     13557547, #ear dx\n",
    "#     10139504, #acute renal fail\n",
    "#     12367864, #pulomonary-heart dx\n",
    "# ]\n",
    "\n",
    "# m4_selected_trajectory = {i: m4_trajectory[i] for i in m4_selected_subjects}\n",
    "\n",
    "# m3_selected_subjects = [\n",
    "#     50093 #pulmonary-heart dx\n",
    "# ]\n",
    "\n",
    "# m3_selected_trajectory = {i: m4m3_trajectory[i] for i in m3_selected_subjects}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95b021c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "trajectory_ccs_codes_level1 = [\n",
    "    64, #renal fail \n",
    "    6, # pulm heart dx\n",
    "    236, # ear dx \n",
    "    # Others\n",
    "    100, # Brnch/lng ca\n",
    "    168, # Kidney/rnl ca\n",
    "    194, # Immunity dx\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "# icenode_m4_competent.head(50)\n",
    "trajectory_ccs_codes_level2 = [\n",
    "    173, 168, 169, 156, 165, 216, 171, 100, 167\n",
    "]\n",
    "\n",
    "\n",
    "ccs_color = {\n",
    "    6: 'blue',\n",
    "    64: 'purple',\n",
    "    236: 'orange',\n",
    "    # Others\n",
    "    100: 'salmon', # Brnch/lng ca\n",
    "    168: 'navy', # Kidney/rnl ca\n",
    "    194: 'pink', # Immunity dx\n",
    "    **{idx: \"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n",
    "                   for idx in trajectory_ccs_codes_level2}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b013311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "interface = m4_interface[clfs[0]]\n",
    "trajectories = m4_trajectory\n",
    "save_dir = \"m4_trajectories_level2\"\n",
    "ccs_indexes = trajectory_ccs_codes_level2# + trajectory_ccs_codes_level2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(interface.dag.diag_flatccs_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcce07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "plt.rcParams['figure.figsize']=(10,10)\n",
    "\n",
    "def plot_codes(codes_dict):\n",
    "    for ccs_idx in codes_dict:\n",
    "        ccs_desc = idx2desc(ccs_idx)\n",
    "        time, traj_vals = zip(*codes_dict[ccs_idx])\n",
    "        plt.scatter(time,  traj_vals, s=100,  marker='^', \n",
    "                    color=ccs_color[ccs_idx], linewidths=2,\n",
    "                    label=f'code: {ccs_desc if len(ccs_desc) < 15 else ccs_desc[:15]+\"..\"}')\n",
    "        \n",
    "def plot_admission_lines(adms):\n",
    "    adms, dischs = zip(*adms)\n",
    "    for i, (adm_ti, disch_ti) in enumerate(zip(adms, dischs)):\n",
    "        plt.axvline(x=adm_ti, color='green', linestyle='-.', label='admission' if i == 0 else None)\n",
    "        plt.axvline(x=disch_ti, color='red', linestyle='--', label='discharge' if i == 0 else None)\n",
    "        plt.fill_between([adm_ti, disch_ti], [1.0, 1.0], alpha=0.1, color='green')\n",
    "        \n",
    "        \n",
    "\n",
    "def plot_risk_traj(trajs):\n",
    "    for ccs_idx in trajs: \n",
    "        ccs_desc = idx2desc(ccs_idx)\n",
    "        time, traj_vals = zip(*trajs[ccs_idx])\n",
    "        time = np.concatenate(time)\n",
    "        traj_vals = np.concatenate(traj_vals)\n",
    "        \n",
    "        plt.plot(time, traj_vals,  color=ccs_color[ccs_idx], \n",
    "                 marker='o', markersize=2, linewidth=1,\n",
    "                 label=f'risk: {ccs_desc if len(ccs_desc) < 15 else ccs_desc[:15]+\"..\"}')\n",
    "    \n",
    "for i, traj in list(trajectories.items()):\n",
    "    plt.figure(i)\n",
    "    \n",
    "    adm_times = interface.adm_times(i)\n",
    "    \n",
    "    plot_admission_lines(adm_times)\n",
    "    \n",
    "    history = interface.diag_flatccs_history(i)\n",
    "    \n",
    "    t = traj['t']\n",
    "    d = traj['d']\n",
    "    \n",
    "\n",
    "    plt_codes = defaultdict(list)\n",
    "    plt_trajs = defaultdict(list)\n",
    "    max_min = (-np.inf, np.inf)\n",
    "    for code in history:\n",
    "        ccs_idx = flatccs_code2idx[code]\n",
    "        code = flatccs_idx2code[ccs_idx]\n",
    "        \n",
    "        if ccs_idx not in ccs_indexes:\n",
    "            continue\n",
    "\n",
    "        code_history = history[code]\n",
    "        code_history_adm, code_history_disch = zip(*code_history)\n",
    "\n",
    "        if code_history_adm[0] == adm_times[0][0]:\n",
    "            plt_codes[ccs_idx].append((adm_times[0][1], d[0][0, ccs_idx]))\n",
    "            \n",
    "        for ti, di, (adm_time_i, disch_time_i) in zip(t, d, adm_times[1:]):\n",
    "            max_min = max(max_min[0], di[:, ccs_idx].max()), min(max_min[1], di[:, ccs_idx].min())\n",
    "            plt_trajs[ccs_idx].append((ti, di[:, ccs_idx]))\n",
    "\n",
    "            \n",
    "            if disch_time_i in code_history_disch:\n",
    "                plt_codes[ccs_idx].append((disch_time_i, di[-1, ccs_idx]))\n",
    "            \n",
    "\n",
    "    if len(plt_codes) == 0:\n",
    "        continue\n",
    "\n",
    "    plot_codes(plt_codes)       \n",
    "    plot_risk_traj(plt_trajs)\n",
    "\n",
    "            \n",
    "    # Make the major grid\n",
    "    plt.grid(which='major', linestyle=':', color='gray', linewidth='1')\n",
    "    # Turn on the minor ticks on\n",
    "    plt.minorticks_on()\n",
    "    # Make the minor grid\n",
    "    plt.grid(which='minor', linestyle=':', color='black', linewidth='0.5')\n",
    "    \n",
    "    plt.ylim(math.floor(max_min[1]/0.05)*0.05, \n",
    "             math.ceil(max_min[0]/0.05)*0.05)\n",
    "    \n",
    "    ystart, yend = plt.gca().get_ylim()\n",
    "    plt.gca().yaxis.set_ticks(np.arange(ystart, yend+0.01, 0.05))\n",
    "\n",
    "    plt.ylabel('Predicted Risk ($\\widehat{v}(t)$)', fontsize=26)\n",
    "    plt.yticks(fontsize=24)\n",
    "    plt.xlabel('Days Since First Admission ($t$)', fontsize=26)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.title(f'Disease Risk Trajectory for Subject ID: {i}', fontsize=28)\n",
    "    plt.legend(fontsize=22, title_fontsize=32,\n",
    "          loc='upper right', bbox_to_anchor=(1.5, 0.5), ncol=1)\n",
    "    \n",
    "    current_figure = plt.gcf()\n",
    "    current_figure.savefig(f\"{save_dir}/trajectory_{i}.pdf\", bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959861b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
