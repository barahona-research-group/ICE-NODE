{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f4d3c",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "<a name=\"outline\"></a>\n",
    "\n",
    "## Setup\n",
    "\n",
    "- [A](#seca) External Imports\n",
    "- [B](#secb) Internal Imports\n",
    "- [C](#secc) Configurations and Paths \n",
    "- [D](#secd) Patient Interface and Train/Val/Test Partitioning\n",
    "- [E](#sece) Setup Metrics\n",
    "\n",
    "\n",
    "## 1. [Load Models: Uninitialised](#models)\n",
    "## 2. [Snapshot Selection](#snapshot)\n",
    "## 3. [Evaluations: Predictive Performance on CPRD](#eval)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a491c",
   "metadata": {},
   "source": [
    "<a name=\"seca\"></a>\n",
    "\n",
    "### A External Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfc614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# Install upsetplot\n",
    "# !pip install UpSetPlot==0.8.0\n",
    "from upsetplot import from_contents, plot, UpSet, from_indicators\n",
    "import jax\n",
    "\n",
    "jax.config.update('jax_platform_name', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0d568",
   "metadata": {},
   "source": [
    "<a name=\"secb\"></a>\n",
    "\n",
    "### B Internal Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "from lib import utils as U\n",
    "from lib.ehr.dataset import load_dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9340794",
   "metadata": {},
   "source": [
    "<a name=\"secc\"></a>\n",
    "\n",
    "### C Configurations and Paths [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e935c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_dir = 'cprd_artefacts/train'\n",
    "output_dir = 'cprd_analysis_artefacts'\n",
    "\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e347422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the folder of the dataset to `DATA_FILE`.\n",
    "HOME = os.environ.get('HOME')\n",
    "DATA_FILE = f'{HOME}/GP/ehr-data/cprd-data/DUMMY_DATA.csv'\n",
    "SOURCE_DIR = os.path.abspath(\"..\")\n",
    "\n",
    "with U.modified_environ(DATA_FILE=DATA_FILE):\n",
    "    cprd_dataset = load_dataset('CPRD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed738552",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_auc_config = {\n",
    "    'pvalue': 0.01, \n",
    "    'min_auc': 0.9\n",
    "}\n",
    "top_k_list=[1, 2, 3, 5, 7, 10, 15, 20]\n",
    "percentile_range=20 \n",
    "n_percentiles=int(100/percentile_range)\n",
    "\n",
    "\n",
    "import matplotlib.font_manager as font_manager\n",
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "plt.rcParams.update({'font.family': 'sans-serif',\n",
    "                     'font.sans-serif': 'Helvetica',\n",
    "                     'font.weight':  'normal'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d435df11",
   "metadata": {},
   "source": [
    "<a name=\"secd\"></a>\n",
    "\n",
    "### D Patient Interface and Train/Val/Test Patitioning [^](#outline)\n",
    "\n",
    "**Configurations should be matching the training notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649755fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ehr.coding_scheme import DxLTC212FlatCodes, DxLTC9809FlatMedcodes, EthCPRD5, EthCPRD16\n",
    "from lib.ehr import OutcomeExtractor, SurvivalOutcomeExtractor\n",
    "from lib.ehr import Subject_JAX\n",
    "from lib.ehr import StaticInfoFlags\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "code_scheme = {\n",
    "    'dx': DxLTC9809FlatMedcodes(), # other options \n",
    "    'outcome': SurvivalOutcomeExtractor('dx_cprd_ltc9809'),\n",
    "    # Comment above^, and uncomment below, to consider only the first occurrence of codes per subject.\n",
    "    # 'outcome': SurvivalOutcomeExtractor('dx_cprd_ltc9809'),\n",
    "    'eth': EthCPRD5()\n",
    "}\n",
    "\n",
    "\n",
    "static_info_flags = StaticInfoFlags(\n",
    " gender=True,\n",
    " age=True,\n",
    " idx_deprivation=True,\n",
    " ethnicity=EthCPRD5(), # <- include it by the category of interest, not just 'True'.\n",
    ")\n",
    "\n",
    "cprd_interface = Subject_JAX.from_dataset(cprd_dataset, code_scheme=code_scheme, static_info_flags=static_info_flags)\n",
    "cprd_splits = cprd_interface.random_splits(split1=0.7, split2=0.85, random_seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f08145",
   "metadata": {},
   "source": [
    "<a name=\"sece\"></a>\n",
    "\n",
    "### E Setup Metrics [^](#outline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddadc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.metric import (CodeAUC, UntilFirstCodeAUC, AdmissionAUC, CodeGroupTopAlarmAccuracy, LossMetric, MetricsCollection)\n",
    "# pecentile_range=20 will partition the codes into five gruops, where each group contains \n",
    "# codes that overall constitutes 20% of the codes in all visits of specified 'subjects' list.\n",
    "code_freq_partitions = cprd_interface.outcome_by_percentiles(percentile_range=20, subjects=cprd_splits[0])\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate for different k values\n",
    "top_k_list = [3, 5, 10, 15, 20]\n",
    "\n",
    "metrics = {'code_auc': CodeAUC(cprd_interface),\n",
    "           'code_first_auc': UntilFirstCodeAUC(cprd_interface),\n",
    "           'admission_auc': AdmissionAUC(cprd_interface),\n",
    "           'loss': LossMetric(cprd_interface),\n",
    "           'code_group_acc': CodeGroupTopAlarmAccuracy(cprd_interface, top_k_list=top_k_list, code_groups=code_freq_partitions)}\n",
    "\n",
    "metric_extractor = {\n",
    "    'code_auc': metrics['code_auc'].aggregate_extractor({'field': 'auc', 'aggregate': 'mean'}),\n",
    "    'code_first_auc': metrics['code_first_auc'].aggregate_extractor({'field': 'auc', 'aggregate': 'mean'}),\n",
    "    'admission_auc': metrics['admission_auc'].aggregate_extractor({'field': 'auc', 'aggregate': 'mean'}),\n",
    "    'loss': metrics['loss'].value_extractor({'field': 'focal_softmax'}),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5de22c",
   "metadata": {},
   "source": [
    "<a name=\"models\"></a>\n",
    "\n",
    "## 1. Loading Models (Uninitialised) [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600cfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ml import ICENODE, ICENODE_UNIFORM, GRU, RETAIN, WindowLogReg\n",
    "from lib.vis import models_from_configs, performance_traces, probe_model_snapshots\n",
    "\n",
    "model_cls = {\n",
    "    'ICE-NODE': ICENODE,\n",
    "    'ICE-NODE_UNIFORM': ICENODE_UNIFORM,\n",
    "    'GRU': GRU,\n",
    "    'RETAIN': RETAIN,\n",
    "    'LogReg': WindowLogReg\n",
    "}       \n",
    "cprd_models = models_from_configs(training_dir, model_cls, cprd_interface, cprd_splits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51366766",
   "metadata": {},
   "source": [
    "<a name=\"snapshot\"></a>\n",
    "\n",
    "\n",
    "## 2. Snapshot Selection [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35cd234",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = probe_model_snapshots(train_dir=training_dir, metric_extractor=metric_extractor, \n",
    "                               selection_metric='admission_auc_val', models=cprd_models)\n",
    "display(result)\n",
    "# Now cprd_models have the selected snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6323308",
   "metadata": {},
   "source": [
    "<a name=\"eval\"></a>\n",
    "\n",
    "## 3. Predictive Performance on CPRD [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7196d5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cprd_test_res = {model_key: model(cprd_interface, cprd_splits[2], dict(eval_only=True))['predictions'] \n",
    "               for model_key, model in cprd_models.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f74ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.metric import DeLongTest\n",
    "from lib.vis import auc_upset\n",
    "\n",
    "delong_metric = DeLongTest(cprd_interface)\n",
    "cprd_auctests = delong_metric.to_df(cprd_test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535f46c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keys = list(cprd_test_res.keys())\n",
    "indicator_df, (nodiff_set, diff_set) = auc_upset(delong_metric, cprd_auctests, model_keys, \n",
    "                                                 p_value=0.05, min_auc=0.7)\n",
    "\n",
    "upset_ctx = lambda : sns.plotting_context(\"paper\", font_scale=1.5, \n",
    "                                          rc={\"font.family\": \"sans-serif\", \n",
    "                                          'axes.labelsize': 'medium',\n",
    "                                          'ytick.labelsize': 'medium'})\n",
    "\n",
    "with sns.axes_style(\"darkgrid\"): #, upset_ctx():\n",
    "    upset_format = from_indicators(indicator_df)\n",
    "    upset_object = UpSet(upset_format, subset_size='count', show_counts=True)\n",
    "    \n",
    "    g = upset_object.plot()\n",
    "        \n",
    "    current_figure = plt.gcf()\n",
    "    w, h = 2.5, 3\n",
    "    wi, hi = current_figure.get_size_inches()\n",
    "    current_figure.set_size_inches(hi*(w/h), hi)\n",
    "    current_figure.savefig(f\"{output_dir}/cprd_auc_upset.pdf\", bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de1bc591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:568: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  group_alarm_acc[k] = group_tp.sum() / group_true.sum()\n"
     ]
    }
   ],
   "source": [
    "from lib.vis import top_k_tables\n",
    "group_acc_metric = metrics['code_group_acc']\n",
    "top_k_results = {k: group_acc_metric.to_df(k, res) for k, res in cprd_test_res.items()}\n",
    "top_k_dfs = top_k_tables(group_acc_metric, top_k_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ed7f64d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC-P0-k5</th>\n",
       "      <th>ACC-P1-k5</th>\n",
       "      <th>ACC-P2-k5</th>\n",
       "      <th>ACC-P3-k5</th>\n",
       "      <th>ACC-P4-k5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GRU</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICE-NODE</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICE-NODE_UNIFORM</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogReg</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RETAIN</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ACC-P0-k5  ACC-P1-k5  ACC-P2-k5  ACC-P3-k5  ACC-P4-k5\n",
       "GRU                     0.0        NaN        NaN        NaN        NaN\n",
       "ICE-NODE                0.0        NaN        NaN        NaN        NaN\n",
       "ICE-NODE_UNIFORM        0.0        NaN        NaN        NaN        NaN\n",
       "LogReg                  0.0        NaN        NaN        NaN        NaN\n",
       "RETAIN                  0.0        NaN        NaN        NaN        NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k_dfs[5]['raw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db683a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
