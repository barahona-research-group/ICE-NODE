{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f53f4d3c",
   "metadata": {},
   "source": [
    "# Table of Content\n",
    "\n",
    "<a name=\"outline\"></a>\n",
    "\n",
    "## Setup\n",
    "\n",
    "- [A](#seca) External Imports\n",
    "- [B](#secb) Internal Imports\n",
    "- [C](#secc) Configurations and Paths \n",
    "- [D](#secd) JAX Interface\n",
    "- [E](#sece) General Utility Functions\n",
    "\n",
    "\n",
    "## Training\n",
    "\n",
    "- [1](#sec1) Training ICE-NODE and The Baselines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a491c",
   "metadata": {},
   "source": [
    "<a name=\"seca\"></a>\n",
    "\n",
    "### A External Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cfc614e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import jax\n",
    "jax.config.update('jax_platform_name', 'gpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f0d568",
   "metadata": {},
   "source": [
    "<a name=\"secb\"></a>\n",
    "\n",
    "### B Internal Imports [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894a3743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from lib import utils as U\n",
    "from lib.ehr.dataset import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c176dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the folder of the dataset to `DATA_FILE`.\n",
    "\n",
    "HOME = os.environ.get('HOME')\n",
    "DATA_DIR = f'{HOME}/GP/ehr-data'\n",
    "SOURCE_DIR = os.path.abspath(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9340794",
   "metadata": {},
   "source": [
    "<a name=\"secd\"></a>\n",
    "\n",
    "### C Configurations and Paths [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca7906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1898f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = 'mimic_artefacts_surv'\n",
    "Path(output_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86e81c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:\n",
      "                Unrecognised <class 'lib.ehr.coding_scheme.DxICD9'> codes (38)\n",
      "                to be removed: ['041.49', '282.40', '282.46', '284.11', '284.12', '284.19', '294.20', '294.21', '348.82', '365.70', '425.11', '425.18', '444.09', '512.83', '512.84', '512.89', '516.31', '516.34', '516.36', '518.51', '518.52', '518.53', '573.5', '596.89', '719.70', '747.32', '793.11', '793.19', '795.51', '997.49', '998.01', '998.09', '999.32', '999.33', 'V12.55', 'V13.89', 'V54.82', 'V88.21']\n",
      "WARNING:absl:\n",
      "                Unrecognised <class 'lib.ehr.coding_scheme.PrICD9'> codes (7)\n",
      "                to be removed: ['02.21', '17.55', '17.56', '35.05', '36.01', '36.02', '36.05']\n"
     ]
    }
   ],
   "source": [
    "with U.modified_environ(DATA_DIR=DATA_DIR):\n",
    "    m3_dataset = load_dataset('M3')\n",
    "#     m4_dataset = load_dataset('M4')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8d78296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lib.ml import ICENODE, ICENODE_UNIFORM, GRU, RETAIN, WindowLogReg, NJODE\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\"\"\"\n",
    "predefined hyperparams re: each model.\n",
    "\"\"\"\n",
    "\n",
    "model_cls = {\n",
    "    'ICE-NODE': ICENODE,\n",
    "    'ICE-NODE_UNIFORM': ICENODE_UNIFORM,\n",
    "    'GRU': GRU,\n",
    "    'RETAIN': RETAIN,\n",
    "    'LogReg': WindowLogReg,\n",
    "    'NJODE': NJODE\n",
    "}\n",
    "\n",
    "model_config = {\n",
    "    'ICE-NODE': f'{SOURCE_DIR}/expt_configs/icenode.json' ,\n",
    "    'ICE-NODE_UNIFORM': f'{SOURCE_DIR}/expt_configs/icenode.json' ,\n",
    "    'GRU': f'{SOURCE_DIR}/expt_configs/gru.json' ,\n",
    "    'RETAIN': f'{SOURCE_DIR}/expt_configs/retain.json',\n",
    "    'LogReg': f'{SOURCE_DIR}/expt_configs/window_logreg.json',\n",
    "    'NJODE': f'{SOURCE_DIR}/expt_configs/njode.json'\n",
    "}\n",
    "\n",
    "model_config = {clf: U.load_config(file) for clf, file in model_config.items()}\n",
    "\n",
    "clfs = [\n",
    "    'ICE-NODE', \n",
    "    'ICE-NODE_UNIFORM', \n",
    "    'GRU', 'RETAIN', 'LogReg', 'NJODE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecf14e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# icenode_variants = []\n",
    "\n",
    "# timescale = {'Ts7': 7.0, 'Ts30': 30.0}\n",
    "# embeddings_size = {'E200': 200, 'E250': 250, 'E300': 300}\n",
    "# tayreg = {'Ty0': 0, 'Ty3': 3}\n",
    "# for ts_key, ts_val in timescale.items():\n",
    "#     for e_key, e_val in embeddings_size.items():\n",
    "#         for tay_key, tay_val in tayreg.items():\n",
    "#             model_name = f'ICE-NODE-{\"\".join((ts_key, e_key, tay_key))}'\n",
    "#             icenode_variants.append(model_name)\n",
    "            \n",
    "#             config = U.load_config(f'{SOURCE_DIR}/expt_configs/icenode.json')\n",
    "#             config['emb']['dx']['embeddings_size'] = e_val\n",
    "#             config['model']['timescale'] = ts_val\n",
    "#             config['training']['tay_reg'] = tay_val\n",
    "#             model_config[model_name] = config\n",
    "#             model_cls[model_name] = ICENODE\n",
    "# clfs.extend(icenode_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ccb6be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3_train_output_dir = {clf: f'{output_dir}/m3_train/{clf}' for clf in clfs}\n",
    "m4_train_output_dir = {clf: f'{output_dir}/m4_train/{clf}' for clf in clfs}\n",
    "\n",
    "[Path(d).mkdir(parents=True, exist_ok=True) for d in m3_train_output_dir.values()]\n",
    "[Path(d).mkdir(parents=True, exist_ok=True) for d in m4_train_output_dir.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "394a3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ml import ConfigDiskWriter, MinibatchLogger, EvaluationDiskWriter, ParamsDiskWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fa1032",
   "metadata": {},
   "source": [
    "The reporter objects are called inside training iterations\n",
    "Each has its own functionality:\n",
    "1. **ConfigDiskWriter**: writes the experiment config file as JSON in the same training directory\n",
    "2. **MinibatchLogger**: writes to the console the training progress details.\n",
    "3. **EvaluationDiskWriter**: writes the evaluation as csv tables in the same training directory for each step of the 100.\n",
    "4. **ParamsDiskWriter**: writes the model parameters snapshot at each step out of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "701e3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_reporters = lambda output_dir, config: [ConfigDiskWriter(output_dir=output_dir, config=config),\n",
    "                                             MinibatchLogger(config),\n",
    "                                             EvaluationDiskWriter(output_dir=output_dir),\n",
    "                                             ParamsDiskWriter(output_dir=output_dir)]\n",
    "\n",
    "m3_reporters = {model: make_reporters(m3_train_output_dir[model], model_config[model]) for model in clfs}\n",
    "# m4_reporters = {model: make_reporters(m4_train_output_dir[model], model_config[model]) for model in clfs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d26707",
   "metadata": {},
   "source": [
    "<a name=\"sece\"></a>\n",
    "\n",
    "### D JAX Interface [^](#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2384d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from lib.ehr.coding_scheme import DxCCS, DxFlatCCS, DxICD9, DxICD10\n",
    "from lib.ehr import Subject_JAX\n",
    "from lib.ehr import StaticInfoFlags\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1208aa8d",
   "metadata": {},
   "source": [
    "The dictionary `code_scheme` in the next cell specifies the code spaces of:\n",
    "- 'dx': diagnostic input (input features) codes. Possible arguments:  `DxCCS()`, `DxFlatCCS()`, `DxICD9()`, `DxICD10()`.\n",
    "- 'outcome': diagnostic outcome (target to be predicted) codes. Possible arguments: \n",
    "    - `OutcomeExtractor('<outcome_label>')`  for prediction of all `<outcome_label>` codes or \n",
    "    - `FirstOccurrenceOutcomeExtractor('<outcome_label>')` for prediction of `<outcome_label>` for the first occurrence per patient).\n",
    "    - `'<outcome_label>'` specifies a subset of dx-codes defined by JSON files in `lib/ehr/resources/outcome_filters`, where each of the labels below links to the following JSON file:\n",
    "        - `'dx_flatccs_mlhc_groups'`:  `'dx_flatccs_mlhc_groups.json'`,\n",
    "        - `'dx_flatccs_filter_v1'`: `'dx_flatccs_v1.json'`,\n",
    "        - `'dx_icd9_filter_v1'`: `'dx_icd9_v1.json'`,\n",
    "        - `'dx_icd9_filter_v2_groups'`: `'dx_icd9_v2_groups.json'`,\n",
    "        - `'dx_icd9_filter_v3_groups'`: `'dx_icd9_v3_groups.json'`\n",
    "    \n",
    "\n",
    "**Note**: OutcomeExtractor can be configured through a JSON file to focus only a subset of the diagnostic codes. For example,\n",
    "you can focus the prediction objective on a small subset of interest (e.g. to predict only pulmonary-heart \n",
    "diseases codes, etc.).\n",
    "OutcomeExtractor can also be replaced by FirstOccurrenceOutcomeExtractor to enforce the prediction \n",
    "objective to predict only the first occurrence of each code for one patient, and subsequent\n",
    "redundant occurences will be avoided and not incorporated in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76078abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ehr import OutcomeExtractor, SurvivalOutcomeExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ccd6b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_scheme = {\n",
    "    'dx': DxCCS(), # other options \n",
    "    'outcome': SurvivalOutcomeExtractor('dx_flatccs_filter_v1')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44b5d7",
   "metadata": {},
   "source": [
    "### Adding Demographic Information in Training\n",
    "\n",
    "What do you need to include as control features? **Uncomment each line to consider the corresponding static information.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02e43e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Source discrepancy\n",
      "WARNING:absl:M: dx_icd9->dx_ccs \n",
      "\n",
      "                            S - M_domain (2497, p=0.14371223021582732):\n",
      "                            ['001', '002', '003', '003.2', '004']...\n",
      "\n",
      "                            M_domain - S (0, p=0.0):\n",
      "                            []...\n",
      "\n",
      "                            M_domain (14878):\n",
      "                            ['001.0', '001.1', '001.9', '002.0', '002.1']...\n",
      "\n",
      "                            S (17375): ['001', '001.0', '001.1', '001.9', '002']...\n",
      "WARNING:absl:Source discrepancy\n",
      "WARNING:absl:M: dx_icd9->dx_flatccs \n",
      "\n",
      "                            S - M_domain (2497, p=0.14371223021582732):\n",
      "                            ['001', '002', '003', '003.2', '004']...\n",
      "\n",
      "                            M_domain - S (0, p=0.0):\n",
      "                            []...\n",
      "\n",
      "                            M_domain (14878):\n",
      "                            ['001.0', '001.1', '001.9', '002.0', '002.1']...\n",
      "\n",
      "                            S (17375): ['001', '001.0', '001.1', '001.9', '002']...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "static_info_flags = StaticInfoFlags(gender=True, age=True)\n",
    "\n",
    "m3_interface = Subject_JAX.from_dataset(m3_dataset, \n",
    "                                        code_scheme=code_scheme, \n",
    "                                        static_info_flags=static_info_flags,\n",
    "                                       data_max_size_gb=1)\n",
    "# m4_interface = Subject_JAX.from_dataset(m4_dataset, \n",
    "#                                         code_scheme=code_scheme, \n",
    "#                                         static_info_flags=static_info_flags,\n",
    "#                                        data_max_size_gb=1)\n",
    "\n",
    "m3_splits = m3_interface.random_splits(split1=0.7, split2=0.85, random_seed=42)\n",
    "# m4_splits = m4_interface.random_splits(split1=0.7, split2=0.85, random_seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28b7c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import jax.random as jrandom\n",
    "import lib.ml as ml\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "key = jrandom.PRNGKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3156b8",
   "metadata": {},
   "source": [
    "In the next cell we load a dictionary for each model specifiying the experiment configuration per model.\n",
    "The classname of the trainer used is also specified in the experiment configs.\n",
    "For example, this is the configuration file of ICE-NODE experiment.\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"emb\": {\n",
    "        \"dx\": {\n",
    "           \"decoder_n_layers\": 2,\n",
    "           \"classname\":  \"MatrixEmbeddings\",      \n",
    "           \"embeddings_size\": 300\n",
    "        }\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"ode_dyn_label\": \"mlp3\",\n",
    "        \"ode_init_var\": 1e-7,\n",
    "        \"state_size\": 30,\n",
    "        \"timescale\": 30\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"batch_size\": 256,\n",
    "        \"decay_rate\": [0.25, 0.33],\n",
    "        \"lr\": [7e-5,  1e-3],\n",
    "        \"epochs\": 60,\n",
    "        \"reg_hyperparams\": {\n",
    "            \"L_dyn\": 1000.0,\n",
    "            \"L_l1\": 0,\n",
    "            \"L_l2\": 0\n",
    "        },\n",
    "        \"opt\": \"adam\",\n",
    "        \"classname\": \"ODETrainer2LR\" <---- \"classname, so this class should be available through ml package.\"\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Since we have a string of the classname, one way to get `ml.ODETrainer2LR` is `getattr(ml, 'ODETrainer2LR')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "542d1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_models = {clf: model_cls[clf].from_config(model_config[clf],\n",
    "                                              m3_interface,\n",
    "                                              m3_splits[0],\n",
    "                                              key) for clf in clfs}\n",
    "# m4_models = {clf: model_cls[clf].from_config(model_config[clf],\n",
    "#                                               m4_interface,\n",
    "#                                               m4_splits[0],\n",
    "#                                               key) for clf in clfs}\n",
    "\n",
    "\n",
    "\n",
    "trainers_cls = {clf: getattr(ml, model_config[clf][\"training\"][\"classname\"]) for clf in clfs}\n",
    "trainers = {clf: trainers_cls[clf](**model_config[clf][\"training\"]) for clf in clfs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c1b824",
   "metadata": {},
   "source": [
    "## Metrics of Interest Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4df755f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.metric import (CodeAUC, UntilFirstCodeAUC, AdmissionAUC, CodeGroupTopAlarmAccuracy, LossMetric, MetricsCollection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7f67e",
   "metadata": {},
   "source": [
    "## Evaluation Metrics per Model\n",
    "\n",
    "1. *CodeAUC*: evaluates the prediction AUC per code (aggregating over all subject visits, for all subjects)\n",
    "2. *UntilFirstCodeAUC*: same as *CodeAUC*, but evaluates the prediction AUC until the first occurrence for each subject, once the code occured, all the subsequent visits are ignored for that code. If the code does not show in a particular subject, all the subject visits are ignored.\n",
    "3. *AdmissionAUC*: evaluates the prediction AUC per visit (i.e. probability of assigning higher risk values for present codes than the absent ones).\n",
    "4. *CodeGroupTopAlarmAccuracy*: partition codes into groups according the code frequency (from the most frequent to the least), and for each visit picks the top `k` risks, and the metric evaluates the accuracy of the top `k` riskiest codes by the model for being indeed present.\n",
    "5. *LossMetric*: records the loss values for different loss variants, which doesn't necessarily include the actual loss function that was used in the training.\n",
    "6. *MetricsCollection*: Groups multiple metrics to be considered at once."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3968aa",
   "metadata": {},
   "source": [
    "**Note:** you will get different results when calling the method `outcome_by_percentiles` by changing the 'outcome' enty of the `ode_scheme` dictionary as following:\n",
    "- OutcomeExtractor: the counting will consider the code and its redundant occurrence for each subject, then aggregated over all subjects \n",
    "- FirstOccurrenceOutcomeExtractor: the counting will consider the first occurrence only for each subject, then aggregated over all subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a37fd74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pecentile_range=20 will partition the codes into five gruops, where each group contains \n",
    "# codes that overall constitutes 20% of the codes in all visits of specified 'subjects' list.\n",
    "m3_code_freq_partitions = m3_interface.outcome_by_percentiles(percentile_range=20, subjects=m3_splits[0])\n",
    "# m4_code_freq_partitions = m4_interface.outcome_by_percentiles(percentile_range=20, subjects=m4_splits[0])\n",
    "\n",
    "# Evaluate for different k values\n",
    "top_k_list = [3, 5, 10, 15, 20]\n",
    "\n",
    "m3_metrics = [CodeAUC(m3_interface),\n",
    "              UntilFirstCodeAUC(m3_interface),\n",
    "              AdmissionAUC(m3_interface),\n",
    "              LossMetric(m3_interface),\n",
    "              CodeGroupTopAlarmAccuracy(m3_interface, top_k_list=top_k_list, code_groups=m3_code_freq_partitions)]\n",
    "# m4_metrics = [CodeAUC(m4_interface),\n",
    "#               UntilFirstCodeAUC(m4_interface),\n",
    "#               AdmissionAUC(m4_interface),\n",
    "#               LossMetric(m4_interface),\n",
    "#               CodeGroupTopAlarmAccuracy(m4_interface, top_k_list=top_k_list, code_groups=m4_code_freq_partitions)]\n",
    "\n",
    "m3_metrics = MetricsCollection(m3_metrics)\n",
    "# m4_metrics = MetricsCollection(m4_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f87624",
   "metadata": {},
   "source": [
    "<a name=\"sec1\"></a>\n",
    "\n",
    "### 1 Training ICE-NODE and The Baselines (#outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffcc11e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.ml import MetricsHistory\n",
    "\n",
    "def m3_train(clf):\n",
    "    output_dir = m3_train_output_dir[clf]\n",
    "    config = model_config[clf]\n",
    "    model = m3_models[clf]\n",
    "    trainer = trainers[clf]\n",
    "    reporters = [EvaluationDiskWriter(output_dir), # <- responsible for writing evaluation tables on disk at the given path\n",
    "                 ParamsDiskWriter(output_dir), # <- responsible for writing model parameters snapshot after each iteration.\n",
    "                 ConfigDiskWriter(output_dir, config), # writes the config file as JSON\n",
    "                ]\n",
    "    \n",
    "    history = MetricsHistory(m3_metrics) # <- empty history\n",
    "    \n",
    "    return trainer(model, m3_interface, m3_splits, history=history, reporters=reporters, prng_seed=42)\n",
    "\n",
    "# def m4_train(clf):\n",
    "#     output_dir = m4_train_output_dir[clf]\n",
    "#     config = model_config[clf]\n",
    "#     model = m4_models[clf]\n",
    "#     trainer = trainers[clf]\n",
    "#     reporters = [EvaluationDiskWriter(output_dir), # <- responsible for writing evaluation tables on disk at the given path\n",
    "#                  ParamsDiskWriter(output_dir), # <- responsible for writing model parameters snapshot after each iteration.\n",
    "#                  ConfigDiskWriter(output_dir, config), # writes the config file as JSON\n",
    "#                 ]\n",
    "    \n",
    "#     history = MetricsHistory(m4_metrics) # <- empty history\n",
    "    \n",
    "#     return trainer(model, m4_interface, m4_splits, history=history, reporters=reporters, prng_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0416a9",
   "metadata": {},
   "source": [
    "#### NJODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cedb0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7193/7193 [10:11:46<00:00,  5.10s/it]\n"
     ]
    }
   ],
   "source": [
    "m3_njode_results = m3_train('NJODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958d7262",
   "metadata": {},
   "source": [
    "#### ICE-NODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abbed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for icenode_variant in icenode_variants:\n",
    "#     print(icenode_variant)\n",
    "#     m3_train(icenode_variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80826221",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 4794/4795 [4:21:41<00:02,  2.72s/it]"
     ]
    }
   ],
   "source": [
    "m3_icenode_results = m3_train('ICE-NODE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode_results = m4_train('ICE-NODE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a21bb",
   "metadata": {},
   "source": [
    "#### ICE-NODE_UNIFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9694c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_icenode_uniform_results = m3_train('ICE-NODE_UNIFORM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_icenode_uniform_results = m4_train('ICE-NODE_UNIFORM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083317e8",
   "metadata": {},
   "source": [
    "#### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49726833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                               | 0/23018 [00:00<?, ?it/s]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 11%|████████████▋                                                                                                     | 2557/23018 [41:32<4:45:38,  1.19it/s]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 12%|█████████████▊                                                                                                    | 2789/23018 [45:16<5:49:32,  1.04s/it]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 21%|███████████████████████▊                                                                                        | 4882/23018 [1:18:21<4:29:35,  1.12it/s]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 31%|███████████████████████████████████                                                                             | 7207/23018 [1:55:11<3:57:28,  1.11it/s]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 64%|██████████████████████████████████████████████████████████████████████▋                                        | 14647/23018 [3:53:10<2:15:27,  1.03it/s]/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: Mean of empty slice\n",
      "  row.append(agg_f(field_vals))\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.8/site-packages/numpy/lib/nanfunctions.py:1218: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "/home/asem/GP/ICE-NODE/notebooks/../lib/metric/stat.py:254: RuntimeWarning: All-NaN slice encountered\n",
      "  row.append(agg_f(field_vals))\n",
      " 70%|█████████████████████████████████████████████████████████████████████████████▍                                 | 16052/23018 [4:15:52<2:03:42,  1.07s/it]"
     ]
    }
   ],
   "source": [
    "m3_gru_results = m3_train('GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72be64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_gru_results = m4_train('GRU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad24c2",
   "metadata": {},
   "source": [
    "#### RETAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2182d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_retain_results = m3_train('RETAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0b60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_retain_results = m4_train('RETAIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda3b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m3_logreg_results = m3_train('LogReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcce213",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4_logreg_results = m4_train('LogReg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f0659c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
