{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3113eb1e",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import sqlalchemy\n",
    "\n",
    "RESULTS_DIR = \"aki_evals\"\n",
    "\n",
    "db_name = [f\"{RESULTS_DIR}/seg_evals.sqlite\",\n",
    "           f\"{RESULTS_DIR}/bin_evals.sqlite\"]\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4aff410b",
   "metadata": {},
   "source": [
    "\n",
    "def model_name(exp):\n",
    "    if 'inicenodelite_' in exp:\n",
    "        return 'eICE-NODE'\n",
    "    if 'gruodebayes' in exp:\n",
    "        return 'GRU-ODE-Bayes'\n",
    "    if 'ingru' in exp:\n",
    "        return 'GRU'\n",
    "    if 'inkoopman' in exp:\n",
    "        return 'Koopman'\n",
    "    if 'inicenodeliteicnn' in exp:\n",
    "        return 'ODE-ICNN'\n",
    "    assert False\n",
    "    \n",
    "def loss_name(exp):\n",
    "    if 'mse' in exp:\n",
    "        return 'mse'\n",
    "    if 'bce' in exp:\n",
    "        return 'bce'\n",
    "    assert False\n",
    "\n",
    "def predictor_name(exp):    \n",
    "    if exp.startswith('mlp'):\n",
    "        return 'mlp'\n",
    "    if exp.startswith('monotonic'):\n",
    "        return f'monotonic'\n",
    "    assert False\n",
    "\n",
    "def batch_size(exp):\n",
    "    if 'B2' in exp:\n",
    "        return 2\n",
    "    else:\n",
    "        return 64\n",
    "    assert False\n",
    "\n",
    "def icenode_dyn(exp):\n",
    "    if 'inicenodelite_gru_' in exp:\n",
    "        return 'gru'\n",
    "    if 'inicenodelite' in exp:\n",
    "        return 'mlp'\n",
    "    else:\n",
    "        return 'NA'\n",
    "        \n",
    "\n",
    "\n",
    "def sql2dataframe(db):\n",
    "    engine = sqlalchemy.create_engine(\"sqlite:///%s\" % db, execution_options={\"sqlite_raw_colnames\": True},\n",
    "                                     connect_args={'timeout': 5})\n",
    "    \n",
    "    df = {name: pd.read_sql_table(name, engine) for name in \n",
    "          ('evaluation_runs', 'evaluation_status', 'experiments', 'metrics', 'results')}\n",
    "    df['results']\n",
    "    \n",
    "    metrics = df['metrics'].rename(columns={'name': 'metric', 'id': 'metric_id'})\n",
    "    eval_runs = df['evaluation_runs'].rename(columns={'id': 'evaluation_id'})\n",
    "    experiments = df['experiments'].rename(columns={'name': 'experiment', 'id': 'experiment_id'})\n",
    "    eval_status = df['evaluation_status'].rename(columns={'id': 'status_id', 'name': 'status'})\n",
    "    \n",
    "    res = pd.merge(df['results'], metrics, left_on='metric_id', right_on='metric_id', how='left')\n",
    "    res = pd.merge(res, eval_runs, left_on='evaluation_id', right_on='evaluation_id', how='left')\n",
    "    res = pd.merge(res, experiments, left_on='experiment_id', right_on='experiment_id', how='left')\n",
    "    res = pd.merge(res, eval_status, left_on='status_id', right_on='status_id', how='left')\n",
    "    res['step'] = res.snapshot.str.extract('(\\d+)').astype(int)\n",
    "\n",
    "    res = res.sort_values(['experiment_id', 'step'])\n",
    "    res['last_max'] = float('nan')\n",
    "    res['last_min'] = float('nan')\n",
    "    res['is_max'] = False\n",
    "    res['is_min'] = False\n",
    "    res['max'] = float('nan')\n",
    "    res['min'] = float('nan')\n",
    "    \n",
    "    for exp, exp_df in res.groupby('experiment_id'):\n",
    "        for metric, metric_df in exp_df.groupby('metric'):\n",
    "            index = metric_df.index\n",
    "            res.loc[index, 'last_max'] = metric_df['value'].cummax()\n",
    "            res.loc[index, 'last_min'] = metric_df['value'].cummin()\n",
    "            res.loc[index, 'is_max'] = metric_df['value'] == res.loc[index, 'last_max']\n",
    "            res.loc[index, 'is_min'] = metric_df['value'] == res.loc[index, 'last_min']\n",
    "            res.loc[index, 'max'] = metric_df['value'].max()\n",
    "            res.loc[index, 'min'] = metric_df['value'].min()\n",
    "            \n",
    "    \n",
    "    res = res[[col for col in res.columns if 'id' not in col]]\n",
    "\n",
    "    res['model'] = res.experiment.map(model_name)\n",
    "    res['loss'] = res.experiment.map(loss_name)\n",
    "    res['predictor'] = res.experiment.map(predictor_name)\n",
    "    res['batch_size'] = res.experiment.map(batch_size)\n",
    "    res['icenode_dyn'] = res.experiment.map(icenode_dyn)\n",
    "    \n",
    "    return res\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "26d2c43e-ac6a-4b73-9f48-504c4c78525e",
   "metadata": {},
   "source": [
    "results = pd.concat([sql2dataframe(db) for db in db_name])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "569c97e7-209c-4592-82c2-e1eb4494a46e",
   "metadata": {},
   "source": [
    "experiments = pd.DataFrame(results.experiment.unique(), columns=['label'])\n",
    "experiments['model'] = experiments.label.map(model_name)\n",
    "experiments['loss'] = experiments.label.map(loss_name)\n",
    "experiments['predictor'] = experiments.label.map(predictor_name)\n",
    "experiments['batch_size'] = experiments.label.map(batch_size)\n",
    "experiments['icenode_dyn'] =  experiments.label.map(icenode_dyn)\n",
    "experiments = experiments.set_index(['model', 'icenode_dyn', 'loss', 'predictor', 'batch_size']).sort_index()\n",
    "experiments.index.is_unique"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ac4c6b3e-8191-4b4a-9f34-a4c5f80a3305",
   "metadata": {},
   "source": [
    "# results.metric.unique()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8de2f1ef",
   "metadata": {},
   "source": [
    "results.set_index(['model', 'icenode_dyn', 'loss', 'predictor', 'batch_size']).sort_index().index.is_unique"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "05cdb113-7228-4a2d-b4b8-a00d428e5288",
   "metadata": {},
   "source": [
    "results.batch_size.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "19ffb2a2",
   "metadata": {},
   "source": [
    "# METRIC = 'LossMetric.lead_mse'\n",
    "METRIC = [\n",
    "    'LeadingAKIPredictionAccuracy.AUC_first_pre_emergence_6.0-48.0',\n",
    "    'LeadingAKIPredictionAccuracy.AUC_pre_emergence_6.0-48.0',\n",
    "    'LeadingAKIPredictionAccuracy.AUC_first_pre_emergence_36.0-48.0',\n",
    "    'LeadingAKIPredictionAccuracy.AUC_pre_emergence_36.0-48.0'\n",
    "]\n",
    "\n",
    "MODEL = [\n",
    "    'eICE-NODE', \n",
    "    'GRU-ODE-Bayes', \n",
    "    'GRU'\n",
    "]\n",
    "PREDICTOR = [\n",
    "    'mlp', \n",
    "    'monotonic'\n",
    "]\n",
    "ICENODE_DYN = [\n",
    "    'mlp', \n",
    "    'gru', \n",
    "    'NA'\n",
    "]\n",
    "LOSS = [\n",
    "    'mse', \n",
    "    'bce'\n",
    "]\n",
    "BATCH_SIZE = [\n",
    "    64,\n",
    "    2\n",
    "]\n",
    "res_metric = results\n",
    "res_metric = res_metric[res_metric['model'].isin(MODEL)]\n",
    "res_metric = res_metric[res_metric['predictor'].isin(PREDICTOR)]\n",
    "res_metric = res_metric[res_metric['loss'].isin(LOSS)]\n",
    "res_metric = res_metric[res_metric['metric'].isin(METRIC)]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cb67e8-4e62-45eb-afb0-75fd465aa238",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a6d39616",
   "metadata": {},
   "source": [
    "res_metric.groupby(['experiment', 'metric'])[['value']].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb59770",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "\n",
    "from bokeh.plotting import figure, show, curdoc\n",
    "from bokeh.io import output_notebook, export_svgs\n",
    "output_notebook()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28518066",
   "metadata": {},
   "source": [
    "from bokeh.palettes import  mpl, small_palettes, viridis,inferno, cividis, YlOrRd4, Spectral"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2aaa8dc4",
   "metadata": {},
   "source": [
    "res_metric.experiment.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b56480f8",
   "metadata": {},
   "source": [
    "p = figure(y_axis_label=METRIC, x_axis_label=\"Training Step\")\n",
    "\n",
    "colors = palette = Spectral[res_metric.experiment.nunique() + 3]\n",
    "res_metric = res_metric.sort_values('step')\n",
    "for i, (exp, df) in enumerate(res_metric.groupby('experiment')):\n",
    "    color = colors[i + 3]\n",
    "    model_label = df['model'].iloc[0]\n",
    "    loss_label = df['loss'].iloc[0]\n",
    "    modularity = df['state_modularity'].iloc[0]\n",
    "    predictor_label = df['predictor'].iloc[0]\n",
    "    \n",
    "    label = f'{\" \".join((modularity, model_label))} ({loss_label}) ({predictor_label})'\n",
    "    \n",
    "    p.line(x='step', y='last_max', color=color,\n",
    "           line_width=4, legend_label=label, source=df)\n",
    "    p.scatter(x='step', y='value', color=color,\n",
    "           line_width=2, legend_label=label, source=df[df['is_max']])\n",
    "    \n",
    "p.legend.location = \"bottom_right\"\n",
    "p.yaxis.axis_label = 'Prediction AUC 48-hours in-advance'\n",
    "p.legend.label_text_font_size = '16pt'\n",
    "\n",
    "curdoc().theme = 'caliber'\n",
    "p.xaxis.axis_label_text_font_size = \"20pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"20pt\"\n",
    "p.xaxis.major_label_text_font_size = '20px'\n",
    "p.yaxis.major_label_text_font_size = '20px'\n",
    "\n",
    "show(p)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41c390d8",
   "metadata": {},
   "source": [
    "p.output_backend = \"svg\"\n",
    "export_svgs(p, filename=\"aki_prediction.svg\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3f431",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
