{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.base_models import ICNNObsDecoder\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa92a456-7044-4d3a-bfbb-a9fcbe3079fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "X_california = X_california[:3000]\n",
    "y_california = y_california[:3000]\n",
    "X_diabetes = X_diabetes[:3000]\n",
    "y_diabetes = y_diabetes[:3000]\n",
    "\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)\n",
    "X_miss_diabetes, y_miss_diabetes = add_missing_values(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edced3f-c431-48ee-af88-8d274a3fd49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 8), (442, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_miss_california.shape, X_miss_diabetes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef1ac49-9b42-4a3a-8f56-86c9b38de838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_imputer(imputer, X_missing, X_full):\n",
    "    M_missing = np.where(np.isnan(X_missing), False, True)\n",
    "    \n",
    "    X_full_hat = imputer.fit_transform(X_missing)\n",
    "\n",
    "    SE = (X_full - X_full_hat)**2\n",
    "\n",
    "    return np.nanmean(SE, where=~M_missing)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_labels = []\n",
    "california_scores = []\n",
    "diabetes_scores = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723b52a-fe2c-4a06-910f-78f303c6bc7a",
   "metadata": {},
   "source": [
    "### Replace missing values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b3644c-f152-4498-b299-9b259e312eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer =  SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0)\n",
    "california_scores.append(get_scores_for_imputer(zero_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(zero_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"Zero imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e42b0-2fa8-4431-b0e6-3bc9dbd66978",
   "metadata": {},
   "source": [
    "### kNN-imputation of the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33724792-aef3-4d3d-8e00-d776ce02b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer =  KNNImputer(missing_values=np.nan)\n",
    "california_scores.append(get_scores_for_imputer(knn_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(knn_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"KNN Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35f1b2-557d-4574-bc02-c855ca6aec6c",
   "metadata": {},
   "source": [
    "### Impute missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0edbe2b-a013-41de-bc77-f14217b3b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer =  SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0)\n",
    "california_scores.append(get_scores_for_imputer(mean_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(mean_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"Mean Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5fb4b-724a-4834-a7b9-5dfcf1e260d4",
   "metadata": {},
   "source": [
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378b1eb6-7862-4ea4-80aa-6dcbe9d9ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "california_scores.append(get_scores_for_imputer(iter_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(iter_imputer,  X_miss_diabetes, X_diabetes))\n",
    "\n",
    "x_labels.append(\"Iterative Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7cb6791-6e53-4973-998b-9b6aabb37391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = pd.DataFrame({'Diabetes': diabetes_scores, 'California': california_scores, 'Method': x_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76292158-a5ba-4dc9-aff8-5621df418bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>California</th>\n",
       "      <th>Method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002004</td>\n",
       "      <td>261858.315676</td>\n",
       "      <td>Zero imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001222</td>\n",
       "      <td>87331.981458</td>\n",
       "      <td>KNN Imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002029</td>\n",
       "      <td>84315.718870</td>\n",
       "      <td>Mean Imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002180</td>\n",
       "      <td>198526.965016</td>\n",
       "      <td>Iterative Imputation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes     California                Method\n",
       "0  0.002004  261858.315676       Zero imputation\n",
       "1  0.001222   87331.981458        KNN Imputation\n",
       "2  0.002029   84315.718870       Mean Imputation\n",
       "3  0.002180  198526.965016  Iterative Imputation"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b5fc4-7103-4100-84fd-d689ada680b0",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 16:19:15.115100: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "claifornia_imputer = ICNNObsDecoder(observables_size=X_miss_california.shape[1], state_size=0,  hidden_size_multiplier=3, depth=4, key=jrandom.PRNGKey(0))\n",
    "diabetes_imputer = ICNNObsDecoder(observables_size=X_miss_diabetes.shape[1], state_size=0,  hidden_size_multiplier=3, depth=4, key=jrandom.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10e8590f-0cb5-4878-984c-b467b3d7c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(X, X_hat, M, axis=None):\n",
    "    return jnp.mean((X - X_hat)**2, where=M, axis=axis)\n",
    "\n",
    "@eqx.filter_jit\n",
    "def loss(model, batch_X, batch_M, batch_M_art):\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    X_imp, aux = eqx.filter_vmap(model.partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    return mse(batch_X, X_imp, (~batch_M_art) & batch_M), aux\n",
    "\n",
    "@eqx.filter_jit\n",
    "def mean_imputer_loss(batch_X, batch_M, batch_M_art):\n",
    "    return mse(batch_X, jnp.nanmean(batch_X), (~batch_M_art) & batch_M)\n",
    "\n",
    "    \n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def loss_grad(model, batch_X, batch_M, batch_M_art):\n",
    "    return loss(model, batch_X, batch_M, batch_M_art)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, optim, opt_state, batch_X, batch_M, batch_M_art):\n",
    "    (loss, aux), grads = loss_grad(model, batch_X, batch_M, batch_M_art)\n",
    "    updates, opt_state = optim.update(grads, opt_state, params=model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return (loss, aux), model, opt_state\n",
    "\n",
    "def dataloader(arrays, batch_size, *, key):\n",
    "    dataset_size = arrays[0].shape[0]\n",
    "    indices = jnp.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = jrandom.permutation(key, indices)\n",
    "        (key,) = jrandom.split(key, 1)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end < dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield tuple(array[batch_perm] for array in arrays)\n",
    "            start = end\n",
    "            end = start + batch_size\n",
    "\n",
    "\n",
    "def train_imputer(model, X_missing, X_full, lr=1e-3, steps=1000, train_batch_size=8, test_batch_size=8, eval_frequency = 10):\n",
    "    optim = optax.adadelta(lr)\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "    split=0.7\n",
    "    key = jrandom.PRNGKey(0)\n",
    "    mask = jnp.array(np.where(np.isnan(X_missing), False, True))\n",
    "    X_missing = jnp.nan_to_num(X_missing, 0.0)\n",
    "    train_idx, test_idx = jnp.split(jrandom.permutation(key, len(X_missing)), [int(split * len(X_missing))])\n",
    "    data_train = (X_missing[train_idx], mask[train_idx])\n",
    "    data_test = (X_missing[test_idx], mask[test_idx])\n",
    "\n",
    "    train_batches = dataloader(data_train, train_batch_size, key=key)\n",
    "    test_batches = iter(dataloader(data_test, train_batch_size, key=key))\n",
    "    \n",
    "\n",
    "    progress = tqdm(range(steps))\n",
    "    train_history = defaultdict(list)\n",
    "    test_history = defaultdict(list)\n",
    "    \n",
    "    for step, batch_train in zip(progress, train_batches):\n",
    "        start = time.time()\n",
    "        batch_X, batch_M = batch_train\n",
    "        batch_M_art = batch_M & jrandom.bernoulli(key, p=0.8, shape=batch_M.shape)\n",
    "        \n",
    "        (key, ) = jrandom.split(key, 1)\n",
    "        (train_loss, train_aux), model, opt_state = make_step(model, optim, opt_state, batch_X, batch_M, batch_M_art)\n",
    "        train_mloss =  mean_imputer_loss(batch_X, batch_M, batch_M_art)\n",
    "        train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "        train_history['mloss'].append(train_mloss)\n",
    "        train_history['loss'].append(train_loss)\n",
    "        train_history['n_opt_steps'].append(train_nsteps)\n",
    "        \n",
    "        end = time.time()\n",
    "        if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "            batch_test = next(test_batches)\n",
    "            test_batch_X, test_batch_M = batch_train\n",
    "            test_batch_M_art = test_batch_M & jrandom.bernoulli(key, p=0.8, shape=test_batch_M.shape)\n",
    "            test_loss, aux = loss(model, test_batch_X, test_batch_M, test_batch_M_art)\n",
    "            test_mloss = mean_imputer_loss(test_batch_X, test_batch_M, test_batch_M_art)\n",
    "            nsteps = int(sum(aux.n_steps) / len(aux.n_steps))\n",
    "            test_history['mloss'].append(test_mloss)\n",
    "            test_history['loss'].append(test_loss)\n",
    "            test_history['n_opt_steps'].append(nsteps)\n",
    "            \n",
    "        progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-M-L: {train_mloss: .3f}, Tst N-steps: {train_nsteps}, \" \n",
    "                                 f\"Tst-L: {test_loss:.3f}, Tst-M-L: {test_mloss:.3f}, Tst N-steps: {nsteps}, Computation time: {end - start:.2f}, \")\n",
    "    return train_history, test_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0da92e8-d693-4cb7-b31e-bfcd368dd429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0025343894958496094,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 36,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f593247bf5c343e6b98e8177aa31e793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0025467872619628906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 36,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f254b444e474c6ea5e7dcab0236174b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cal_train_history, cal_test_history = train_imputer(claifornia_imputer, X_missing=X_miss_california, X_full=X_california, \n",
    "                                                    lr=1e-3, steps=1000, train_batch_size=8, test_batch_size=8, eval_frequency = 10)\n",
    "diab_train_history, diab_test_history = train_imputer(diabetes_imputer, X_missing=X_miss_diabetes, X_full=X_diabetes, \n",
    "                                                      lr=1e-3, steps=1000, train_batch_size=8, test_batch_size=8, eval_frequency = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78844f69-101e-4089-8bc6-bdd36b99c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_train_res = pd.DataFrame(cal_train_history)\n",
    "diab_train_res = pd.DataFrame(diab_train_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6b7bd88-323c-4716-959a-7d2423c7fc85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.319"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cal_train_res.mloss > cal_train_res.loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "abfdce98-4b4b-45b5-8ab0-996b19ecc925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mloss</th>\n",
       "      <th>loss</th>\n",
       "      <th>n_opt_steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0033216879335892487</td>\n",
       "      <td>0.0032859004240497645</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0021130209601621275</td>\n",
       "      <td>0.0021338346719317097</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0035260805797846673</td>\n",
       "      <td>0.0038464151040079994</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0017791617517213833</td>\n",
       "      <td>0.0019324880604001157</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003719065863328398</td>\n",
       "      <td>0.003724907321025007</td>\n",
       "      <td>768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0021521392310232443</td>\n",
       "      <td>0.0024381389776902958</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0017614536126886252</td>\n",
       "      <td>0.0017016980460527699</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.000873853949298992</td>\n",
       "      <td>0.0008924362071787255</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.001252240018715222</td>\n",
       "      <td>0.0011685380600661257</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0016806558285468894</td>\n",
       "      <td>0.00199741201859913</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     mloss                   loss  n_opt_steps\n",
       "0    0.0033216879335892487  0.0032859004240497645         1024\n",
       "1    0.0021130209601621275  0.0021338346719317097         1024\n",
       "2    0.0035260805797846673  0.0038464151040079994         1024\n",
       "3    0.0017791617517213833  0.0019324880604001157         1024\n",
       "4     0.003719065863328398   0.003724907321025007          768\n",
       "..                     ...                    ...          ...\n",
       "995  0.0021521392310232443  0.0024381389776902958         1024\n",
       "996  0.0017614536126886252  0.0017016980460527699         1024\n",
       "997   0.000873853949298992  0.0008924362071787255         1024\n",
       "998   0.001252240018715222  0.0011685380600661257         1024\n",
       "999  0.0016806558285468894    0.00199741201859913         1024\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diab_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bb36-09e3-4433-aeeb-2006c325d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
