{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import sklearn.neural_network as sknn\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.base_models import ICNNObsDecoder\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa92a456-7044-4d3a-bfbb-a9fcbe3079fc",
   "metadata": {},
   "source": [
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "X_california = X_california[:5000]\n",
    "y_california = y_california[:5000]\n",
    "X_diabetes = X_diabetes[:5000]\n",
    "y_diabetes = y_diabetes[:5000]\n",
    "\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)\n",
    "X_miss_diabetes, y_miss_diabetes = add_missing_values(X_diabetes, y_diabetes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edced3f-c431-48ee-af88-8d274a3fd49f",
   "metadata": {},
   "source": [
    "X_miss_california.shape, X_miss_diabetes.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {},
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c064fd5-4daa-4c35-9760-0af20b291884",
   "metadata": {},
   "source": [
    "from typing import Literal, Callable, Tuple\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import equinox as eqx\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def r_squared(y, y_hat):\n",
    "    y = y.squeeze()\n",
    "    y_hat = y_hat.squeeze()\n",
    "    \n",
    "    y_bar = y.mean()\n",
    "    ss_tot = ((y-y_bar)**2).sum()\n",
    "    ss_res = ((y-y_hat)**2).sum()\n",
    "    return 1 - (ss_res/ss_tot)\n",
    "\n",
    "\n",
    "class MLPRegressor(eqx.Module):\n",
    "    mlp: eqx.nn.MLP\n",
    "    optimiser: optax.GradientTransformation = eqx.static_field()\n",
    "    lr: float = eqx.static_field()\n",
    "    alpha: float = eqx.static_field()\n",
    "    loss_fn: Callable[[jnp.ndarray], jnp.ndarray] = eqx.static_field()\n",
    "    batch_size: int = eqx.static_field()\n",
    "    max_iters: int = eqx.static_field()\n",
    "    seed: int = eqx.static_field()\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, depth: int,\n",
    "                 activation: Literal['relu', 'tanh', 'sigmoid', 'elu', 'softplus', 'leaky_relu'], batch_size: int,\n",
    "                 lr: float = 1e-3, alpha: float = 1e-5, loss_fn: Literal['mse', 'mae'] = 'mse',\n",
    "                 max_iters: int = 100,\n",
    "                 optax_optimiser = optax.adam,\n",
    "                 seed: int = 0):\n",
    "        super().__init__()\n",
    "        if activation == 'relu':\n",
    "            activation_f = jnn.relu\n",
    "        elif activation == 'tanh':\n",
    "            activation_f = jnn.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            activation_f = jnn.sigmoid\n",
    "        elif activation == 'softplus':\n",
    "            activation_f = jnn.softplus\n",
    "        elif activation == 'elu':\n",
    "            activation_f = jnn.elu\n",
    "        elif activation == 'leaky_relu':\n",
    "            activation_f = lambda x: jnn.leaky_relu(x, negative_slope=0.01)\n",
    "        else:\n",
    "            activation_f = lambda x: x\n",
    "\n",
    "        if loss_fn == 'mse':\n",
    "            self.loss_fn = jnp.square\n",
    "        elif loss_fn == 'mae':\n",
    "            self.loss_fn = jnp.abs\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown loss function {loss_fn}\")\n",
    "\n",
    "        self.mlp = eqx.nn.MLP(input_size, output_size, hidden_size, depth, activation=activation_f,\n",
    "                              key=jr.PRNGKey(seed),\n",
    "                              use_bias=True, use_final_bias=True)\n",
    "        self.optimiser = optax_optimiser(lr)\n",
    "        self.lr = lr\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iters = max_iters\n",
    "        self.seed = seed\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def loss(self, batch_X: jnp.ndarray, batch_y: jnp.ndarray) -> jnp.ndarray:\n",
    "        y_hat = eqx.filter_vmap(self.predict)(batch_X)\n",
    "        return jnp.mean(self.loss_fn(y_hat.flatten() - batch_y.flatten()))\n",
    "\n",
    "    @property\n",
    "    def weights_list(self):\n",
    "        return list(l.weight for l in self.mlp.layers)\n",
    "\n",
    "    @eqx.filter_value_and_grad\n",
    "    def loss_grad(self, batch_X: jnp.ndarray, batch_y: jnp.ndarray):\n",
    "        L = self.loss(batch_X, batch_y)\n",
    "        if self.alpha > 0:\n",
    "            L += self.alpha * sum(jnp.sum(jnp.square(w)) for w in self.weights_list) / (2 * len(batch_X))\n",
    "        return L\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(self, opt_state, batch_X: jnp.ndarray, batch_y: jnp.ndarray) -> Tuple[\n",
    "        jnp.ndarray, \"MLPRegressor\", optax.OptState]:\n",
    "        loss, grads = self.loss_grad(batch_X, batch_y)\n",
    "        updates, opt_state = self.optimiser.update(grads, opt_state,\n",
    "                                                   params=eqx.filter(self, eqx.is_inexact_array),\n",
    "                                                   value=loss, grad=grads, \n",
    "                                                   value_fn=lambda m: eqx.combine(m, self).loss(batch_X, batch_y))\n",
    "        return loss, eqx.apply_updates(self, updates), opt_state\n",
    "\n",
    "    @staticmethod\n",
    "    def dataloader(arrays, batch_size, *, key):\n",
    "        dataset_size = arrays[0].shape[0]\n",
    "        indices = jnp.arange(dataset_size)\n",
    "        while True:\n",
    "            perm = jr.permutation(key, indices)\n",
    "            (key, _) = jr.split(key, 2)\n",
    "            start = 0\n",
    "            end = batch_size\n",
    "            while end < dataset_size:\n",
    "                batch_perm = perm[start:end]\n",
    "                yield tuple(array[batch_perm] for array in arrays)\n",
    "                start = end\n",
    "                end = start + batch_size\n",
    "\n",
    "    def fit(self, X: jnp.ndarray, y: jnp.ndarray):\n",
    "        model = self\n",
    "        opt_state = self.optimiser.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "        train_batches = self.dataloader((X, y), self.batch_size, key=jr.PRNGKey(self.seed))\n",
    "        progress = tqdm(range(self.max_iters), leave=False)\n",
    "        for step, (batch_X, batch_y) in zip(progress, train_batches):\n",
    "            loss, model, opt_state = model.make_step(opt_state, batch_X, batch_y)\n",
    "            r2 = r_squared(batch_y, model.predict(batch_X))\n",
    "            progress.set_description(f\"Loss: {loss:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def predict(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        return eqx.filter_vmap(self.mlp)(X)\n",
    "\n",
    "\n",
    "class MLPRegressorICNN(MLPRegressor):\n",
    "    imputer: ICNNObsDecoder\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, depth: int,\n",
    "                 activation: Literal['relu', 'tanh', 'sigmoid'], batch_size: int,\n",
    "                 imputer_hidden_size_multiplier: int = 3, imputer_depth: int = 5,\n",
    "                 lr: float = 1e-3, alpha: float = 1e-5, loss_fn: Literal['mse', 'mae'] = 'mse',\n",
    "                 max_iters: int = 100,\n",
    "                 optax_optimiser = optax.adam,\n",
    "                 icnn_optax_optimiser_name = 'adam',\n",
    "                 seed: int = 0):\n",
    "        super().__init__(input_size, output_size, hidden_size, depth, activation, batch_size, lr, alpha, loss_fn,\n",
    "                         max_iters, optax_optimiser, seed)\n",
    "        self.imputer = ICNNObsDecoder(observables_size=input_size, state_size=0,\n",
    "                                      hidden_size_multiplier=imputer_hidden_size_multiplier,\n",
    "                                      depth=imputer_depth, \n",
    "                                      optax_optimiser_name=icnn_optax_optimiser_name,\n",
    "                                      key=jr.PRNGKey(seed))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def impute(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        M = jnp.where(jnp.isnan(X), False, True)\n",
    "        X = jnp.nan_to_num(X)\n",
    "        X, aux = eqx.filter_vmap(self.imputer.partial_input_optimise)(X, M)\n",
    "        return X\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def predict(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        X = self.impute(X)\n",
    "        return eqx.filter_vmap(self.mlp)(X)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef1ac49-9b42-4a3a-8f56-86c9b38de838",
   "metadata": {},
   "source": [
    "\n",
    "def get_mlp_regressor(X, opt=optax.adam):\n",
    "    return MLPRegressor(input_size=X.shape[1],\n",
    "                        output_size=1, hidden_size=X.shape[1]*5,\n",
    "                        optax_optimiser=opt,\n",
    "                        alpha=0., depth=2, activation='leaky_relu', batch_size=32, max_iters=1500, lr=1e-3)\n",
    "\n",
    "\n",
    "def get_sklearn_mlp_regressor(X):\n",
    "    return sknn.MLPRegressor(hidden_layer_sizes=(X.shape[1]*5, )*2,\n",
    "                             solver='lbfgs',\n",
    "                             alpha=0., activation='relu', batch_size=32, max_iter=1500, learning_rate_init=1e-3)\n",
    "\n",
    "def get_mlp_icnn_regressor(X, icnn_optax_optimiser_name, opt=optax.adam):\n",
    "    return MLPRegressorICNN(input_size=X.shape[1],\n",
    "                            output_size=1, hidden_size=X.shape[1]*5,                       \n",
    "                            optax_optimiser=opt,\n",
    "                            icnn_optax_optimiser_name=icnn_optax_optimiser_name,\n",
    "                            alpha=0., depth=2, activation='leaky_relu', batch_size=32, max_iters=1500, lr=1e-3)\n",
    "\n",
    "\n",
    "def get_rf_regressor(X = None):\n",
    "    return RandomForestRegressor(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "def get_impute_regress_scores(model, X_missing_train, y_train, X_missing_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_missing_train)\n",
    "    X_missing_train = scaler.transform(X_missing_train)\n",
    "    X_missing_test = scaler.transform(X_missing_test)\n",
    "    if isinstance(model, tuple):\n",
    "        model, imputer = model\n",
    "        imputer = imputer.fit(X_missing_train)\n",
    "        X_missing_train = imputer.transform(X_missing_train)\n",
    "        X_missing_test = imputer.transform(X_missing_test)\n",
    "        model = model.fit(X_missing_train, y_train)\n",
    "        ret_model = (model, imputer)\n",
    "    else:\n",
    "        model = model.fit(X_missing_train, y_train)\n",
    "        ret_model = model\n",
    "\n",
    "    return ({'MSE': np.mean(np.square(model.predict(X_missing_train).flatten() - y_train.flatten())), \n",
    "             'R2': r_squared(y_train, model.predict(X_missing_train))},\n",
    "            {'MSE': np.mean(np.square(model.predict(X_missing_test).flatten() - y_test.flatten())), \n",
    "             'R2': r_squared(y_test, model.predict(X_missing_test))}), ret_model\n",
    "\n",
    "def get_imput_regress_scores_cv(model, X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "    train_mse, train_r2 = [], []\n",
    "    test_mse, test_r2 = [], []\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        (train_scores, test_scores), model = get_impute_regress_scores(model, X_train, y_train, X_test, y_test)\n",
    "        train_mse.append(train_scores['MSE'])\n",
    "        train_r2.append(train_scores['R2'])\n",
    "        test_mse.append(test_scores['MSE'])\n",
    "        test_r2.append(test_scores['R2'])\n",
    "    \n",
    "\n",
    "    return pd.DataFrame({'split': ['TRAIN'] * k +  ['TEST'] * k,\n",
    "                        'MSE': train_mse + test_mse,\n",
    "                        'R2':  train_r2 + test_r2,\n",
    "                        'Fold': list(range(k)) * 2})\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bb36cd0-60a4-441a-8bb1-e37455e8e7a4",
   "metadata": {},
   "source": [
    "optax_optimisers = {\n",
    "    'adam': optax.adam,\n",
    "    'polyak_sgd': optax.polyak_sgd,\n",
    "    'novograd': optax.novograd,\n",
    "    'lamb': optax.lamb,\n",
    "    'yogi': optax.yogi,\n",
    "}\n",
    "\n",
    "\n",
    "imputers =  {\n",
    "    'zero_imputer': SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94997861-64c6-4e54-a990-ca514f9c3b9d",
   "metadata": {},
   "source": [
    "dfs = []"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09f0e17-afbd-4c73-be91-79f27222975f",
   "metadata": {},
   "source": [
    "for (ds_name, (X, y)) in zip(['California',\n",
    "                             'Diabetes'\n",
    "                             ],  [(X_miss_california, y_miss_california), \n",
    "                                  (X_miss_diabetes, y_miss_diabetes)\n",
    "                                 ]):\n",
    "\n",
    "    for imputer_name, imputer in imputers.items():\n",
    "        for model_name, model in [('SKL_MLP', get_sklearn_mlp_regressor(X)), ('SKL_RF', get_rf_regressor())]:\n",
    "            res = get_imput_regress_scores_cv((model,imputer), X, y)\n",
    "            res['Dataset'] = ds_name\n",
    "            res['Imputer'] = imputer_name\n",
    "            res['Model'] = model_name\n",
    "            dfs.append(res)\n",
    "\n",
    "        for opt_name, optimizer in optax_optimisers.items():\n",
    "            model_name = 'JAX_MLP'\n",
    "            model = get_mlp_regressor(X, opt=optimizer)\n",
    "            res = get_imput_regress_scores_cv((model,imputer), X, y)\n",
    "            res['Dataset'] = ds_name\n",
    "            res['Imputer'] = imputer_name\n",
    "            res['Model'] = model_name\n",
    "            res['Optimizer'] = opt_name\n",
    "            dfs.append(res)\n",
    "\n",
    "pd.concat(dfs).to_csv('feedforward_imputations.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639280b1-42de-4d83-a8a7-03a5ad35bcfb",
   "metadata": {},
   "source": [
    "for (ds_name, (X, y)) in zip(['California',\n",
    "                             'Diabetes'\n",
    "                             ],  [(X_miss_california, y_miss_california), \n",
    "                                  (X_miss_diabetes, y_miss_diabetes)\n",
    "                                 ]):\n",
    "    for opt_name, optimizer in optax_optimisers.items():\n",
    "        model_name = 'JAX_MLP_ICNN'\n",
    "        for icnn_opt_name in ['adam', 'polyak_sgd', 'lamb', 'yogi']:\n",
    "            model = get_mlp_icnn_regressor(X, opt=optimizer, icnn_optax_optimiser_name=icnn_opt_name)\n",
    "            resicnn = get_imput_regress_scores_cv(model, X, y)\n",
    "            resicnn['Dataset'] = ds_name\n",
    "            resicnn['Model'] = model_name\n",
    "            resicnn['Optimizer'] = opt_name\n",
    "            resicnn['ICNN-Opt'] = icnn_opt_name\n",
    "            dfs.append(resicnn)\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc85ea8-77b8-4ab0-828f-b8769fe2a114",
   "metadata": {},
   "source": [
    "print('x')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1abaa-b24f-4857-bbd8-1c4f6e40750f",
   "metadata": {},
   "source": [
    "print('x')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488c5175-b63a-4829-9f59-17b194f1b552",
   "metadata": {},
   "source": [
    "results = pd.concat(dfs)\n",
    "results_train = results[results.split == 'TRAIN']\n",
    "results_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6104220-bf57-4b12-8af4-9cc74ccd1684",
   "metadata": {},
   "source": [
    "results['Method'] = results['Model'] + '-' + results['Imputer']\n",
    "results[(results.Dataset == 'California') & (results.split == 'TEST')]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f06521-855a-46a9-b1a9-f7ab83779d00",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.barplot(results[(results.Dataset == 'Diabetes') & (results.split == 'TEST')], \n",
    "            x=\"MSE\", y=\"Method\", errorbar=\"sd\"\n",
    "           )\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "source": [
    "claifornia_imputer = ICNNObsDecoder(observables_size=X_miss_california.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))\n",
    "diabetes_imputer = ICNNObsDecoder(observables_size=X_miss_diabetes.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22286c09-b6d5-48a2-ab66-4266844e9efc",
   "metadata": {},
   "source": [
    "california_scores.append(get_scores_for_icnn_imputer(claifornia_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_icnn_imputer(diabetes_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"ICNN Imputation\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc80f18-e2c3-45ec-bd7c-9e029de6c792",
   "metadata": {},
   "source": [
    "california_scores, california_scores_per_feature = zip(*california_scores)\n",
    "diabetes_scores, diabetes_scores_per_feature = zip(*diabetes_scores)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03300-e9ab-4b03-9f0b-44c02d584322",
   "metadata": {},
   "source": [
    "results = pd.DataFrame({'Diabetes': diabetes_scores, #'California': california_scores, \n",
    "                        'Method': x_labels})\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b34c3-e1ef-4a75-919c-b3f3d244fe6e",
   "metadata": {},
   "source": [
    "cal_features = [f'feature_{i}' for i in range(len(california_scores_per_feature[0]))]\n",
    "diab_features = [f'feature_{i}' for i in range(len(diabetes_scores_per_feature[0]))]\n",
    "cal_features_res = pd.DataFrame(dict(zip(x_labels, california_scores_per_feature)), index=cal_features)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296101c7-22f2-439d-910d-ea3aa3998f98",
   "metadata": {},
   "source": [
    "cal_features_res"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d00a2-4dec-4fd2-9fb3-52a1b6ba9089",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
