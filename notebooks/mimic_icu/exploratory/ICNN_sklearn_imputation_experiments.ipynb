{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.base_models import ICNNObsDecoder\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa92a456-7044-4d3a-bfbb-a9fcbe3079fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "X_california = X_california[:3000]\n",
    "y_california = y_california[:3000]\n",
    "X_diabetes = X_diabetes[:3000]\n",
    "y_diabetes = y_diabetes[:3000]\n",
    "\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)\n",
    "X_miss_diabetes, y_miss_diabetes = add_missing_values(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edced3f-c431-48ee-af88-8d274a3fd49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 8), (442, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_miss_california.shape, X_miss_diabetes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# To use the experimental IterativeImputer, we need to explicitly ask for it:\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ef1ac49-9b42-4a3a-8f56-86c9b38de838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_imputer(imputer, X_missing, X_full):\n",
    "    M_missing = np.where(np.isnan(X_missing), False, True)\n",
    "    \n",
    "    X_full_hat = imputer.fit_transform(X_missing)\n",
    "\n",
    "    SE = (X_full - X_full_hat)**2\n",
    "\n",
    "    return np.nanmean(SE, where=~M_missing),  np.nanmean(SE, where=~M_missing, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_labels = []\n",
    "california_scores = []\n",
    "diabetes_scores = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b723b52a-fe2c-4a06-910f-78f303c6bc7a",
   "metadata": {},
   "source": [
    "### Replace missing values by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b3644c-f152-4498-b299-9b259e312eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_imputer =  SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0)\n",
    "california_scores.append(get_scores_for_imputer(zero_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(zero_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"Zero imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558e42b0-2fa8-4431-b0e6-3bc9dbd66978",
   "metadata": {},
   "source": [
    "### kNN-imputation of the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33724792-aef3-4d3d-8e00-d776ce02b58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputer =  KNNImputer(missing_values=np.nan)\n",
    "california_scores.append(get_scores_for_imputer(knn_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(knn_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"KNN Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b35f1b2-557d-4574-bc02-c855ca6aec6c",
   "metadata": {},
   "source": [
    "### Impute missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0edbe2b-a013-41de-bc77-f14217b3b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputer =  SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0)\n",
    "california_scores.append(get_scores_for_imputer(mean_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(mean_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"Mean Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e5fb4b-724a-4834-a7b9-5dfcf1e260d4",
   "metadata": {},
   "source": [
    "### Iterative Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "378b1eb6-7862-4ea4-80aa-6dcbe9d9ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputer = IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "california_scores.append(get_scores_for_imputer(iter_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_imputer(iter_imputer,  X_miss_diabetes, X_diabetes))\n",
    "\n",
    "x_labels.append(\"Iterative Imputation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b5fc4-7103-4100-84fd-d689ada680b0",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 20:44:39.721573: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "claifornia_imputer = ICNNObsDecoder(observables_size=X_miss_california.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))\n",
    "diabetes_imputer = ICNNObsDecoder(observables_size=X_miss_diabetes.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10e8590f-0cb5-4878-984c-b467b3d7c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(X, X_hat, M, axis=None):\n",
    "    return jnp.mean(jnp.square(X - X_hat), where=M, axis=axis)\n",
    "\n",
    "@eqx.filter_jit\n",
    "def loss(model, batch_X, batch_M, batch_M_art):\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    X_imp, aux = eqx.filter_vmap(model.partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    return mse(batch_X, X_imp, (~batch_M_art) & batch_M), aux\n",
    "\n",
    "@eqx.filter_jit\n",
    "def mean_imputer_loss(batch_X, batch_M, batch_M_art):\n",
    "    return mse(batch_X, jnp.nanmean(batch_X), (~batch_M_art) & batch_M)\n",
    "\n",
    "    \n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def loss_grad(model, batch_X, batch_M, batch_M_art):\n",
    "    return loss(model, batch_X, batch_M, batch_M_art)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model, optim, opt_state, batch_X, batch_M, batch_M_art):\n",
    "    (loss, aux), grads = loss_grad(model, batch_X, batch_M, batch_M_art)\n",
    "    updates, opt_state = optim.update(grads, opt_state, params=model)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return (loss, aux), model, opt_state\n",
    "\n",
    "def dataloader(arrays, batch_size, *, key):\n",
    "    dataset_size = arrays[0].shape[0]\n",
    "    indices = jnp.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = jrandom.permutation(key, indices)\n",
    "        (key,) = jrandom.split(key, 1)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end < dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield tuple(array[batch_perm] for array in arrays)\n",
    "            start = end\n",
    "            end = start + batch_size\n",
    "\n",
    "\n",
    "def train_imputer(model, X_missing, lr=1e-3, steps=1000, train_batch_size=8, test_batch_size=8, eval_frequency = 10):\n",
    "    optim = optax.adam(lr)\n",
    "    opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "    split=0.7\n",
    "    key = jrandom.PRNGKey(0)\n",
    "    mask = jnp.array(np.where(np.isnan(X_missing), False, True))\n",
    "    X_missing = jnp.nan_to_num(X_missing, 0.0)\n",
    "    train_idx, test_idx = jnp.split(jrandom.permutation(key, len(X_missing)), [int(split * len(X_missing))])\n",
    "    data_train = (X_missing[train_idx], mask[train_idx])\n",
    "    data_test = (X_missing[test_idx], mask[test_idx])\n",
    "\n",
    "    train_batches = dataloader(data_train, train_batch_size, key=key)\n",
    "    test_batches = iter(dataloader(data_test, train_batch_size, key=key))\n",
    "    \n",
    "\n",
    "    progress = tqdm(range(steps))\n",
    "    train_history = defaultdict(list)\n",
    "    test_history = defaultdict(list)\n",
    "    \n",
    "    for step, batch_train in zip(progress, train_batches):\n",
    "        start = time.time()\n",
    "        batch_X, batch_M = batch_train\n",
    "        batch_M_art = batch_M & jrandom.bernoulli(key, p=0.8, shape=batch_M.shape)\n",
    "        \n",
    "        (key, ) = jrandom.split(key, 1)\n",
    "        (train_loss, train_aux), model, opt_state = make_step(model, optim, opt_state, batch_X, batch_M, batch_M_art)\n",
    "        train_mloss =  mean_imputer_loss(batch_X, batch_M, batch_M_art)\n",
    "        train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "        train_history['mloss'].append(train_mloss)\n",
    "        train_history['loss'].append(train_loss)\n",
    "        train_history['n_opt_steps'].append(train_nsteps)\n",
    "        \n",
    "        end = time.time()\n",
    "        if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "            batch_test = next(test_batches)\n",
    "            test_batch_X, test_batch_M = batch_train\n",
    "            test_batch_M_art = test_batch_M & jrandom.bernoulli(key, p=0.8, shape=test_batch_M.shape)\n",
    "            test_loss, aux = loss(model, test_batch_X, test_batch_M, test_batch_M_art)\n",
    "            test_mloss = mean_imputer_loss(test_batch_X, test_batch_M, test_batch_M_art)\n",
    "            nsteps = int(sum(aux.n_steps) / len(aux.n_steps))\n",
    "            test_history['mloss'].append(test_mloss)\n",
    "            test_history['loss'].append(test_loss)\n",
    "            test_history['n_opt_steps'].append(nsteps)\n",
    "            \n",
    "        progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-M-L: {train_mloss: .3f}, Tst N-steps: {train_nsteps}, \" \n",
    "                                 f\"Tst-L: {test_loss:.3f}, Tst-M-L: {test_mloss:.3f}, Tst N-steps: {nsteps}, Computation time: {end - start:.2f}, \")\n",
    "    return model, train_history, test_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0da92e8-d693-4cb7-b31e-bfcd368dd429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002896547317504883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1500,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676943e5bb754017a80bb2129dfc47a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "jax.pure_callback failed\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/callback.py\", line 77, in pure_callback_impl\n",
      "    return callback(*args)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/callback.py\", line 65, in __call__\n",
      "    return tree_util.tree_leaves(self.callback_func(*args, **kwargs))\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/equinox/_errors.py\", line 70, in raises\n",
      "    raise EqxRuntimeError(msgs[_index.item()])\n",
      "equinox._errors.EqxRuntimeError: The linear solver returned non-finite (NaN or inf) output. This usually means that the\n",
      "operator was not well-posed, and that the solver does not support this.\n",
      "\n",
      "If you are trying solve a linear least-squares problem then you should pass\n",
      "`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\n",
      "assumes that the operator is square and nonsingular.\n",
      "\n",
      "If you *were* expecting this solver to work with this operator, then it may be because:\n",
      "\n",
      "(a) the operator is singular, and your code has a bug; or\n",
      "\n",
      "(b) the operator was nearly singular (i.e. it had a high condition number:\n",
      "    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n",
      "    numerical instability issues; or\n",
      "\n",
      "(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n",
      "    that is does not actually satisfy.\n",
      "E0625 20:44:57.534742  159026 pjrt_stream_executor_client.cc:2809] Execution of replica 0 failed: INTERNAL: CustomCall failed: CpuCallback error: Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/asyncio/events.py\", line 84, in _run\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "  File \"/tmp/ipykernel_159026/536613702.py\", line 1, in <module>\n",
      "  File \"/tmp/ipykernel_159026/948891182.py\", line 70, in train_imputer\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/equinox/_jit.py\", line 206, in __call__\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/equinox/_module.py\", line 1053, in __call__\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/equinox/_jit.py\", line 200, in _call\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/traceback_util.py\", line 179, in reraise_with_filtered_traceback\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/pjit.py\", line 298, in cache_miss\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/pjit.py\", line 176, in _python_pjit_helper\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/core.py\", line 2788, in bind\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/core.py\", line 425, in bind_with_trace\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/core.py\", line 913, in process_primitive\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1488, in _pjit_call_impl\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1471, in call_impl_cache_miss\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/pjit.py\", line 1427, in _pjit_call_impl_python\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/profiler.py\", line 335, in wrapper\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/interpreters/pxla.py\", line 1205, in __call__\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/interpreters/mlir.py\", line 2466, in _wrapped_callback\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/callback.py\", line 219, in _callback\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/callback.py\", line 80, in pure_callback_impl\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/jax/_src/callback.py\", line 65, in __call__\n",
      "  File \"/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/equinox/_errors.py\", line 70, in raises\n",
      "EqxRuntimeError: The linear solver returned non-finite (NaN or inf) output. This usually means that the\n",
      "operator was not well-posed, and that the solver does not support this.\n",
      "\n",
      "If you are trying solve a linear least-squares problem then you should pass\n",
      "`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\n",
      "assumes that the operator is square and nonsingular.\n",
      "\n",
      "If you *were* expecting this solver to work with this operator, then it may be because:\n",
      "\n",
      "(a) the operator is singular, and your code has a bug; or\n",
      "\n",
      "(b) the operator was nearly singular (i.e. it had a high condition number:\n",
      "    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n",
      "    numerical instability issues; or\n",
      "\n",
      "(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n",
      "    that is does not actually satisfy.\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "The linear solver returned non-finite (NaN or inf) output. This usually means that the\noperator was not well-posed, and that the solver does not support this.\n\nIf you are trying solve a linear least-squares problem then you should pass\n`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\nassumes that the operator is square and nonsingular.\n\nIf you *were* expecting this solver to work with this operator, then it may be because:\n\n(a) the operator is singular, and your code has a bug; or\n\n(b) the operator was nearly singular (i.e. it had a high condition number:\n    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n    numerical instability issues; or\n\n(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n    that is does not actually satisfy.\n-------\nThis error occurred during the runtime of your JAX program. Setting the environment\nvariable `EQX_ON_ERROR=breakpoint` is usually the most useful way to debug such errors.\n(This can be navigated using most of the usual commands for the Python debugger:\n`u` and `d` to move through stack frames, the name of a variable to print its value,\netc.) See also `https://docs.kidger.site/equinox/api/errors/#equinox.error_if` for more\ninformation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m claifornia_imputer, cal_train_history, cal_test_history \u001b[38;5;241m=\u001b[39m train_imputer(claifornia_imputer, X_missing\u001b[38;5;241m=\u001b[39mX_miss_california, \n\u001b[1;32m      2\u001b[0m                                                     lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, test_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, eval_frequency \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m diabetes_imputer, diab_train_history, diab_test_history \u001b[38;5;241m=\u001b[39m train_imputer(diabetes_imputer, X_missing\u001b[38;5;241m=\u001b[39mX_miss_diabetes,\n\u001b[1;32m      4\u001b[0m                                                       lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1500\u001b[39m, train_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, test_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, eval_frequency \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 70\u001b[0m, in \u001b[0;36mtrain_imputer\u001b[0;34m(model, X_missing, lr, steps, train_batch_size, test_batch_size, eval_frequency)\u001b[0m\n\u001b[1;32m     67\u001b[0m batch_M_art \u001b[38;5;241m=\u001b[39m batch_M \u001b[38;5;241m&\u001b[39m jrandom\u001b[38;5;241m.\u001b[39mbernoulli(key, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, shape\u001b[38;5;241m=\u001b[39mbatch_M\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     69\u001b[0m (key, ) \u001b[38;5;241m=\u001b[39m jrandom\u001b[38;5;241m.\u001b[39msplit(key, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m (train_loss, train_aux), model, opt_state \u001b[38;5;241m=\u001b[39m make_step(model, optim, opt_state, batch_X, batch_M, batch_M_art)\n\u001b[1;32m     71\u001b[0m train_mloss \u001b[38;5;241m=\u001b[39m  mean_imputer_loss(batch_X, batch_M, batch_M_art)\n\u001b[1;32m     72\u001b[0m train_nsteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28msum\u001b[39m(train_aux\u001b[38;5;241m.\u001b[39mn_steps) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_aux\u001b[38;5;241m.\u001b[39mn_steps))\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: The linear solver returned non-finite (NaN or inf) output. This usually means that the\noperator was not well-posed, and that the solver does not support this.\n\nIf you are trying solve a linear least-squares problem then you should pass\n`solver=AutoLinearSolver(well_posed=False)`. By default `lineax.linear_solve`\nassumes that the operator is square and nonsingular.\n\nIf you *were* expecting this solver to work with this operator, then it may be because:\n\n(a) the operator is singular, and your code has a bug; or\n\n(b) the operator was nearly singular (i.e. it had a high condition number:\n    `jnp.linalg.cond(operator.as_matrix())` is large), and the solver suffered from\n    numerical instability issues; or\n\n(c) the operator is declared to exhibit a certain property (e.g. positive definiteness)\n    that is does not actually satisfy.\n-------\nThis error occurred during the runtime of your JAX program. Setting the environment\nvariable `EQX_ON_ERROR=breakpoint` is usually the most useful way to debug such errors.\n(This can be navigated using most of the usual commands for the Python debugger:\n`u` and `d` to move through stack frames, the name of a variable to print its value,\netc.) See also `https://docs.kidger.site/equinox/api/errors/#equinox.error_if` for more\ninformation.\n"
     ]
    }
   ],
   "source": [
    "claifornia_imputer, cal_train_history, cal_test_history = train_imputer(claifornia_imputer, X_missing=X_miss_california, \n",
    "                                                    lr=5e-4, steps=1500, train_batch_size=64, test_batch_size=64, eval_frequency = 10)\n",
    "diabetes_imputer, diab_train_history, diab_test_history = train_imputer(diabetes_imputer, X_missing=X_miss_diabetes,\n",
    "                                                      lr=5e-4, steps=1500, train_batch_size=8, test_batch_size=8, eval_frequency = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78844f69-101e-4089-8bc6-bdd36b99c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_train_res = pd.DataFrame(cal_train_history)\n",
    "diab_train_res = pd.DataFrame(diab_train_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7bd88-323c-4716-959a-7d2423c7fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "(cal_train_res.mloss > cal_train_res.loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38a15de-54fd-4a99-a135-bb112f83dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "(diab_train_res.mloss > diab_train_res.loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdce98-4b4b-45b5-8ab0-996b19ecc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "diab_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bb36-09e3-4433-aeeb-2006c325d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_icnn_imputer(imputer, X_missing, X_full):\n",
    "    M_missing = jnp.array(np.where(np.isnan(X_missing), False, True))\n",
    "    X_missing = jnp.nan_to_num(X_missing)\n",
    "    X_full_hat, aux = eqx.filter_vmap(imputer.partial_input_optimise)(X_missing, M_missing)\n",
    "    SE = (X_full - X_full_hat)**2\n",
    "    return np.nanmean(SE, where=~M_missing), np.nanmean(SE, where=~M_missing, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22286c09-b6d5-48a2-ab66-4266844e9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_scores.append(get_scores_for_icnn_imputer(claifornia_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_icnn_imputer(diabetes_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"ICNN Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc80f18-e2c3-45ec-bd7c-9e029de6c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_scores, california_scores_per_feature = zip(*california_scores)\n",
    "diabetes_scores, diabetes_scores_per_feature = zip(*diabetes_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03300-e9ab-4b03-9f0b-44c02d584322",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Diabetes': diabetes_scores, #'California': california_scores, \n",
    "                        'Method': x_labels})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b34c3-e1ef-4a75-919c-b3f3d244fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_features = [f'feature_{i}' for i in range(len(california_scores_per_feature[0]))]\n",
    "diab_features = [f'feature_{i}' for i in range(len(diabetes_scores_per_feature[0]))]\n",
    "cal_features_res = pd.DataFrame(dict(zip(x_labels, california_scores_per_feature)), index=cal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296101c7-22f2-439d-910d-ea3aa3998f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_features_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d00a2-4dec-4fd2-9fb3-52a1b6ba9089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
