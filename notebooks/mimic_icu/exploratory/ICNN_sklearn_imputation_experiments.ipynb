{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "import sklearn.neural_network as sknn\n",
    "from sklearn.datasets import fetch_california_housing, load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.base_models import ICNNObsDecoder\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa92a456-7044-4d3a-bfbb-a9fcbe3079fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rng = np.random.RandomState(42)\n",
    "\n",
    "X_diabetes, y_diabetes = load_diabetes(return_X_y=True)\n",
    "X_california, y_california = fetch_california_housing(return_X_y=True)\n",
    "X_california = X_california[:5000]\n",
    "y_california = y_california[:5000]\n",
    "X_diabetes = X_diabetes[:5000]\n",
    "y_diabetes = y_diabetes[:5000]\n",
    "\n",
    "\n",
    "def add_missing_values(X_full, y_full):\n",
    "    n_samples, n_features = X_full.shape\n",
    "\n",
    "    # Add missing values in 75% of the lines\n",
    "    missing_rate = 0.75\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "\n",
    "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
    "    missing_samples[:n_missing_samples] = True\n",
    "\n",
    "    rng.shuffle(missing_samples)\n",
    "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
    "    X_missing = X_full.copy()\n",
    "    X_missing[missing_samples, missing_features] = np.nan\n",
    "    y_missing = y_full.copy()\n",
    "\n",
    "    return X_missing, y_missing\n",
    "\n",
    "\n",
    "X_miss_california, y_miss_california = add_missing_values(X_california, y_california)\n",
    "X_miss_diabetes, y_miss_diabetes = add_missing_values(X_diabetes, y_diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0edced3f-c431-48ee-af88-8d274a3fd49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 8), (442, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_miss_california.shape, X_miss_diabetes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c064fd5-4daa-4c35-9760-0af20b291884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Callable, Tuple\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import equinox as eqx\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr\n",
    "import optax\n",
    "\n",
    "class MLPRegressor(eqx.Module):\n",
    "    mlp: eqx.nn.MLP\n",
    "    optimiser: optax.GradientTransformation = eqx.static_field()\n",
    "    lr: float = eqx.static_field()\n",
    "    alpha: float = eqx.static_field()\n",
    "    loss_fn: Callable[[jnp.ndarray], jnp.ndarray] = eqx.static_field()\n",
    "    batch_size: int = eqx.static_field()\n",
    "    max_iters: int = eqx.static_field()\n",
    "    seed: int = eqx.static_field()\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, depth: int,\n",
    "                 activation: Literal['relu', 'tanh', 'sigmoid', 'elu', 'softplus', 'leaky_relu'], batch_size: int,\n",
    "                 lr: float = 1e-3, alpha: float = 1e-5, loss_fn: Literal['mse', 'mae'] = 'mse',\n",
    "                 max_iters: int = 100,\n",
    "                 seed: int = 0):\n",
    "        super().__init__()\n",
    "        if activation == 'relu':\n",
    "            activation_f = jnn.relu\n",
    "        elif activation == 'tanh':\n",
    "            activation_f = jnn.tanh\n",
    "        elif activation == 'sigmoid':\n",
    "            activation_f = jnn.sigmoid\n",
    "        elif activation == 'softplus':\n",
    "            activation_f = jnn.softplus\n",
    "        elif activation == 'elu':\n",
    "            activation_f = jnn.elu\n",
    "        elif activation == 'leaky_relu':\n",
    "            activation_f = lambda x: jnn.leaky_relu(x, negative_slope=0.01)\n",
    "        else:\n",
    "            activation_f = lambda x: x\n",
    "\n",
    "        if loss_fn == 'mse':\n",
    "            self.loss_fn = jnp.square\n",
    "        elif loss_fn == 'mae':\n",
    "            self.loss_fn = jnp.abs\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown loss function {loss_fn}\")\n",
    "\n",
    "        self.mlp = eqx.nn.MLP(input_size, output_size, hidden_size, depth, activation=activation_f,\n",
    "                              key=jr.PRNGKey(seed),\n",
    "                              use_bias=True, use_final_bias=True)\n",
    "        self.optimiser = optax.adam(lr)\n",
    "        self.lr = lr\n",
    "        self.alpha = alpha\n",
    "        self.batch_size = batch_size\n",
    "        self.max_iters = max_iters\n",
    "        self.seed = seed\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def loss(self, batch_X: jnp.ndarray, batch_y: jnp.ndarray) -> jnp.ndarray:\n",
    "        y_hat = eqx.filter_vmap(self.predict)(batch_X)\n",
    "        return jnp.mean(self.loss_fn(y_hat - batch_y))\n",
    "\n",
    "    @property\n",
    "    def weights_list(self):\n",
    "        return list(l.weight for l in self.mlp.layers)\n",
    "\n",
    "    @eqx.filter_value_and_grad\n",
    "    def loss_grad(self, batch_X: jnp.ndarray, batch_y: jnp.ndarray):\n",
    "        L = self.loss(batch_X, batch_y)\n",
    "        if self.alpha > 0:\n",
    "            L += self.alpha * sum(jnp.sum(jnp.square(w)) for w in self.weights_list) / (2 * len(batch_X))\n",
    "        return L\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def make_step(self, opt_state, batch_X: jnp.ndarray, batch_y: jnp.ndarray) -> Tuple[\n",
    "        jnp.ndarray, \"MLPRegressor\", optax.OptState]:\n",
    "        loss, grads = self.loss_grad(batch_X, batch_y)\n",
    "        updates, opt_state = self.optimiser.update(grads, opt_state,\n",
    "                                                   params=eqx.filter(self, eqx.is_inexact_array),\n",
    "                                                   value=loss, grad=grads, \n",
    "                                                   value_fn=lambda m: eqx.combine(m, self).loss(batch_X, batch_y))\n",
    "        return loss, eqx.apply_updates(self, updates), opt_state\n",
    "\n",
    "    @staticmethod\n",
    "    def dataloader(arrays, batch_size, *, key):\n",
    "        dataset_size = arrays[0].shape[0]\n",
    "        indices = jnp.arange(dataset_size)\n",
    "        while True:\n",
    "            perm = jr.permutation(key, indices)\n",
    "            (key,) = jr.split(key, 1)\n",
    "            start = 0\n",
    "            end = batch_size\n",
    "            while end < dataset_size:\n",
    "                batch_perm = perm[start:end]\n",
    "                yield tuple(array[batch_perm] for array in arrays)\n",
    "                start = end\n",
    "                end = start + batch_size\n",
    "\n",
    "    def fit(self, X: jnp.ndarray, y: jnp.ndarray):\n",
    "        model = self\n",
    "        opt_state = self.optimiser.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "        train_batches = self.dataloader((X, y), self.batch_size, key=jr.PRNGKey(self.seed))\n",
    "        progress = tqdm(range(self.max_iters), leave=False)\n",
    "        for step, (batch_X, batch_y) in zip(progress, train_batches):\n",
    "            loss, model, opt_state = model.make_step(opt_state, batch_X, batch_y)\n",
    "            progress.set_description(f\"Loss: {loss:.4f}\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def predict(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        return eqx.filter_vmap(self.mlp)(X)\n",
    "\n",
    "\n",
    "class MLPRegressorICNN(MLPRegressor):\n",
    "    imputer: ICNNObsDecoder\n",
    "\n",
    "    def __init__(self, input_size: int, output_size: int, hidden_size: int, depth: int,\n",
    "                 activation: Literal['relu', 'tanh', 'sigmoid'], batch_size: int,\n",
    "                 imputer_hidden_size_multiplier: int = 3, imputer_depth: int = 5,\n",
    "                 lr: float = 1e-3, alpha: float = 1e-5, loss_fn: Literal['mse', 'mae'] = 'mse',\n",
    "                 max_iters: int = 100,\n",
    "                 seed: int = 0):\n",
    "        super().__init__(input_size, output_size, hidden_size, depth, activation, batch_size, lr, alpha, loss_fn,\n",
    "                         max_iters, seed)\n",
    "        self.imputer = ICNNObsDecoder(observables_size=input_size, state_size=0,\n",
    "                                      hidden_size_multiplier=imputer_hidden_size_multiplier,\n",
    "                                      depth=imputer_depth, key=jr.PRNGKey(seed))\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def impute(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        M = jnp.where(jnp.isnan(X), False, True)\n",
    "        X = jnp.nan_to_num(X)\n",
    "        X, aux = eqx.filter_vmap(self.imputer.partial_input_optimise)(X, M)\n",
    "        return X\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def predict(self, X: jnp.ndarray):\n",
    "        if jnp.ndim(X) == 1:\n",
    "            X = X[None, :]\n",
    "        X = self.impute(X)\n",
    "        return eqx.filter_vmap(self.mlp)(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef1ac49-9b42-4a3a-8f56-86c9b38de838",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_mlp_regressor(X):\n",
    "    return MLPRegressor(input_size=X.shape[1],\n",
    "                        output_size=1, hidden_size=X.shape[1]*4,\n",
    "                        alpha=0., depth=2, activation='leaky_relu', batch_size=32, max_iters=10000, lr=5e-4)\n",
    "\n",
    "\n",
    "def get_sklearn_mlp_regressor(X):\n",
    "    return sknn.MLPRegressor(hidden_layer_sizes=(X.shape[1]*4, )*2,\n",
    "                             solver='lbfgs',\n",
    "                             alpha=0., activation='relu', batch_size=32, max_iter=10000, learning_rate_init=1e-3)\n",
    "\n",
    "def get_mlp_icnn_regressor(X):\n",
    "    return MLPRegressorICNN(input_size=X.shape[1],\n",
    "                            output_size=1, hidden_size=X.shape[1]*4,\n",
    "                            alpha=0., depth=2, activation='leaky_relu', batch_size=32, max_iters=10000, lr=5e-4)\n",
    "\n",
    "\n",
    "def get_rf_regressor(X = None):\n",
    "    return RandomForestRegressor(random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "def get_impute_regress_scores(model, X_missing_train, y_train, X_missing_test, y_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler = scaler.fit(X_missing_train)\n",
    "    X_missing_train = scaler.transform(X_missing_train)\n",
    "    X_missing_test = scaler.transform(X_missing_test)\n",
    "    if isinstance(model, tuple):\n",
    "        model, imputer = model\n",
    "        imputer = imputer.fit(X_missing_train)\n",
    "        X_full_hat_train = imputer.transform(X_missing_train)\n",
    "        X_full_hat_test = imputer.transform(X_missing_test)\n",
    "        model = model.fit(X_full_hat_train, y_train)\n",
    "        return {'train': np.mean(np.square(model.predict(X_full_hat_train) - y_train)),  \n",
    "                'test': np.mean(np.square(model.predict(X_full_hat_test) - y_test))}\n",
    "    else:\n",
    "        model = model.fit(X_missing_train, y_train)\n",
    "        return {'train': np.mean(np.square(model.predict(X_missing_train) - y_train)),  \n",
    "                'test': np.mean(np.square(model.predict(X_missing_test) - y_test))}\n",
    "\n",
    "def get_imput_regress_scores_cv(model, X, y, k=5):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=0)\n",
    "    train_scores = []\n",
    "    test_scores = []\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        scores = get_impute_regress_scores(model, X_train, y_train, X_test, y_test)\n",
    "        train_scores.append(scores['train'])\n",
    "        test_scores.append(scores['test'])\n",
    "\n",
    "    return pd.DataFrame({'split': ['TRAIN'] * len(train_scores) +  ['TEST'] * len(test_scores),\n",
    "                        'MSE': train_scores + test_scores,\n",
    "                        'Fold': list(range(len(train_scores))) + list(range(len(test_scores)))})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7593ac-53b6-41d3-9b28-236dc9f67389",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b3644c-f152-4498-b299-9b259e312eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 13:29:15.641228: W external/xla/xla/service/gpu/nvptx_compiler.cc:765] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002524852752685547,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024864673614501953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024857521057128906,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00238800048828125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0026297569274902344,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0027468204498291016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002561807632446289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0025527477264404297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0026667118072509766,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0026390552520751953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002568483352661133,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002256155014038086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0023241043090820312,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0022585391998291016,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003727436065673828,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002244710922241211,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003108501434326172,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0022840499877929688,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002220630645751953,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0036084651947021484,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/home/asem/GP/env/icenode-dev/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0024268627166748047,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0023849010467529297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002352476119995117,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002348184585571289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 35,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d430c82906bb4db6b0875190b200658b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imputers =  {\n",
    "    'zero_imputer': SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}\n",
    "\n",
    "dfs = []\n",
    "for (ds_name, (X, y)) in zip(['California',\n",
    "                              'Diabetes'\n",
    "                             ],  [(X_miss_california, y_miss_california), \n",
    "                                  (X_miss_diabetes, y_miss_diabetes)\n",
    "                                 ]):\n",
    "    for model_name, model in [('JAX_MLP', get_mlp_regressor(X)),\n",
    "                              ('SKL_MLP', get_sklearn_mlp_regressor(X)),\n",
    "                              ('SKL_RF', get_rf_regressor())\n",
    "                             ]:\n",
    "        for imputer_name, imputer in imputers.items():\n",
    "            res = get_imput_regress_scores_cv((model,imputer), X, y)\n",
    "            res['Dataset'] = ds_name\n",
    "            res['Imputer'] = imputer_name\n",
    "            res['Model'] = model_name\n",
    "            dfs.append(res)\n",
    "    resicnn = get_imput_regress_scores_cv(get_mlp_icnn_regressor(X), X, y)\n",
    "    resicnn['Dataset'] = ds_name\n",
    "    resicnn['Model'] = 'JAX_MLP_ICNN'\n",
    "    resicnn['Imputer'] = ''\n",
    "    dfs.append(resicnn)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9083dbcf-763e-48c5-920f-a262e51fa746",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.concat(dfs)\n",
    "results['Method'] = results['Model'] + '-' + results['Imputer']\n",
    "results[(results.Dataset == 'California') & (results.split == 'TEST')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f06521-855a-46a9-b1a9-f7ab83779d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.barplot(results[(results.Dataset == 'California') & (results.split == 'TEST')], \n",
    "            x=\"MSE\", y=\"Method\", errorbar=None#\"sd\"\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "claifornia_imputer = ICNNObsDecoder(observables_size=X_miss_california.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))\n",
    "diabetes_imputer = ICNNObsDecoder(observables_size=X_miss_diabetes.shape[1], state_size=0,  hidden_size_multiplier=3, depth=10, key=jrandom.PRNGKey(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22286c09-b6d5-48a2-ab66-4266844e9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_scores.append(get_scores_for_icnn_imputer(claifornia_imputer,  X_miss_california, X_california))\n",
    "diabetes_scores.append(get_scores_for_icnn_imputer(diabetes_imputer,  X_miss_diabetes, X_diabetes))\n",
    "x_labels.append(\"ICNN Imputation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc80f18-e2c3-45ec-bd7c-9e029de6c792",
   "metadata": {},
   "outputs": [],
   "source": [
    "california_scores, california_scores_per_feature = zip(*california_scores)\n",
    "diabetes_scores, diabetes_scores_per_feature = zip(*diabetes_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f03300-e9ab-4b03-9f0b-44c02d584322",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'Diabetes': diabetes_scores, #'California': california_scores, \n",
    "                        'Method': x_labels})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b34c3-e1ef-4a75-919c-b3f3d244fe6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_features = [f'feature_{i}' for i in range(len(california_scores_per_feature[0]))]\n",
    "diab_features = [f'feature_{i}' for i in range(len(diabetes_scores_per_feature[0]))]\n",
    "cal_features_res = pd.DataFrame(dict(zip(x_labels, california_scores_per_feature)), index=cal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296101c7-22f2-439d-910d-ea3aa3998f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_features_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d00a2-4dec-4fd2-9fb3-52a1b6ba9089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
