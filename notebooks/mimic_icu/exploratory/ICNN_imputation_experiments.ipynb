{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.base_models import ICNNObsDecoder, ImputerMetrics, ICNN\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8d3fb5-2f0b-4c2c-ba43-973e88359c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbICNNObsDecoder(eqx.Module):\n",
    "    icnn_mean: ICNNObsDecoder\n",
    "    icnn_var: ICNNObsDecoder\n",
    "\n",
    "    def __init__(self, observables_size: int, state_size: int, hidden_size_multiplier: float,\n",
    "                 depth: int,\n",
    "                 optax_optimiser_name: Literal['adam', 'polyak_sgd', 'lamb', 'yogi'] = 'adam', *,\n",
    "                 key: jrandom.PRNGKey):\n",
    "        key_mu, key_sigma = jrandom.split(key, 2)\n",
    "        self.icnn_mean = ICNNObsDecoder(observables_size, state_size, hidden_size_multiplier, depth,\n",
    "                                        optax_optimiser_name,\n",
    "                                        key=key_mu)\n",
    "        self.icnn_var = ICNNObsDecoder(observables_size * 2, state_size, hidden_size_multiplier // 2, depth,\n",
    "                                       optax_optimiser_name,\n",
    "                                       key=key_sigma)\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def prob_partial_input_optimise(self, input: jnp.ndarray, fixed_mask: jnp.ndarray) -> Tuple[\n",
    "        Tuple[jnp.ndarray, jnp.ndarray], ImputerMetrics]:\n",
    "        mu, metrics = self.icnn_mean.partial_input_optimise(input, fixed_mask)\n",
    "\n",
    "        mu_std, _ = self.icnn_var.partial_input_optimise(jnp.hstack((mu, jnp.where(fixed_mask, -4., 10.))),\n",
    "                                                         jnp.hstack((jnp.ones_like(mu), fixed_mask)))\n",
    "        mu, std = jnp.hsplit(mu_std, 2)\n",
    "        std = jnn.softplus(std)\n",
    "        return (mu, std), metrics\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def partial_input_optimise(self, input: jnp.ndarray, fixed_mask: jnp.ndarray) -> Tuple[jnp.ndarray, ImputerMetrics]:\n",
    "        (mu, _), metrics = self.prob_partial_input_optimise(input, fixed_mask)\n",
    "        return mu, metrics\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ProbStackedICNNImputer(ICNNObsDecoder):\n",
    "    f_energy: ICNN\n",
    "\n",
    "    def __init__(self, observables_size: int, hidden_size_multiplier: float, depth: int,\n",
    "                 optax_optimiser_name: Literal['adam', 'polyak_sgd', 'lamb', 'yogi'] = 'adam', *,\n",
    "                 key: jrandom.PRNGKey):\n",
    "        super().__init__(observables_size=observables_size*2, state_size=0, hidden_size_multiplier=hidden_size_multiplier,\n",
    "                        depth=depth, optax_optimiser_name=optax_optimiser_name, key=key)\n",
    "\n",
    "\n",
    "    @eqx.filter_jit\n",
    "    def prob_partial_input_optimise(self, input: jnp.ndarray, fixed_mask: jnp.ndarray) -> Tuple[\n",
    "        Tuple[jnp.ndarray, jnp.ndarray], ImputerMetrics]:\n",
    "        mu_std, metrics = super().partial_input_optimise(jnp.hstack((input, jnp.where(fixed_mask, -4., 10.))), \n",
    "                                                         jnp.hstack((fixed_mask, fixed_mask)))\n",
    "        mu, std = jnp.hsplit(mu_std, 2)\n",
    "        std = jnn.softplus(std)\n",
    "        return (mu, std), metrics\n",
    "        \n",
    "    @eqx.filter_jit\n",
    "    def partial_input_optimise(self, input: jnp.ndarray, fixed_mask: jnp.ndarray) -> Tuple[jnp.ndarray, ImputerMetrics]:\n",
    "        (mu, _), metrics = self.prob_partial_input_optimise(input, fixed_mask)\n",
    "        return mu, metrics\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda298bc-79e7-4631-863f-23c451fb883e",
   "metadata": {},
   "source": [
    "### First Time Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8645d508-5ce0-4e81-a28b-b2b0dccf9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvx = m4aki.TVxAKIMIMICIVDataset.load('/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0cbf73a-2b16-4e1a-9128-f2877a9b954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = [adm.observables  for subject in tvx0.subjects.values() for adm in subject.admissions]\n",
    "# adm_id = sum(([adm.admission_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])\n",
    "# subj_id = sum(([subject.subject_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d25b12a0-f4ed-40dd-bec6-9fef0e79caa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val = np.vstack([obs_i.value for obs_i in obs])\n",
    "# obs_mask = np.vstack([obs_i.mask for obs_i in obs])\n",
    "# obs_time = np.hstack([obs_i.time for obs_i in obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09c8afd5-475a-4a92-b73d-6e66243662cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvx0.scheme.obs\n",
    "# features = list(map(tvx0.scheme.obs.desc.get, tvx0.scheme.obs.codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b3e1440-1b1c-4fe6-806c-1839440ee716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val = pd.DataFrame(obs_val, columns=features)\n",
    "# obs_mask = pd.DataFrame(obs_mask.astype(int), columns=features)\n",
    "# meta = pd.DataFrame({'subject_id': subj_id, 'admission_id': adm_id, 'time': obs_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a784503e-6175-43ab-8522-58447cf5e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_mask = obs_mask.copy()\n",
    "# artificial_mask = obs_mask & np.array(jrandom.bernoulli(jrandom.PRNGKey(0), p=0.5, shape=obs_mask.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28e3b288-d34d-4a43-8f79-98c5965ddb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val.to_csv('missingness_data/missingness_vals.csv')\n",
    "# obs_mask.to_csv('missingness_data/missingness_mask.csv')\n",
    "# meta.to_csv('missingness_data/meta.csv')\n",
    "# artificial_mask.to_csv('missingness_data/missingness_artificial_mask.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808916f3-e3ff-4239-a26b-d34631abd624",
   "metadata": {},
   "source": [
    "### Later Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b42f56-270f-4e17-8c93-e79af7638e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_val = pd.read_csv('missingness_data/missingness_vals.csv', index_col=[0])\n",
    "obs_mask = pd.read_csv('missingness_data/missingness_mask.csv', index_col=[0])\n",
    "artificial_mask = pd.read_csv('missingness_data/missingness_artificial_mask.csv', index_col=[0])\n",
    "meta = pd.read_csv('missingness_data/meta.csv', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "seed = 0\n",
    "indices = jrandom.permutation(jrandom.PRNGKey(seed), len(obs_val))\n",
    "train_idx = indices[:int(split_ratio * len(indices))]\n",
    "test_idx = indices[int(split_ratio * len(indices)):]\n",
    "\n",
    "obs_val_train = jnp.array(obs_val.iloc[train_idx].to_numpy())\n",
    "obs_mask_train = jnp.array(obs_mask.iloc[train_idx].to_numpy())\n",
    "art_mask_train =  jnp.array(artificial_mask.iloc[train_idx].to_numpy())\n",
    "\n",
    "obs_val_test = jnp.array(obs_val.iloc[test_idx].to_numpy())\n",
    "obs_mask_test = jnp.array(obs_mask.iloc[test_idx].to_numpy())\n",
    "art_mask_test =  jnp.array(artificial_mask.iloc[test_idx].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b5fc4-7103-4100-84fd-d689ada680b0",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ICNNObsDecoder(observables_size=obs_mask.shape[1], state_size=0, \n",
    "                       optax_optimiser_name='polyak_sgd',\n",
    "                       hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "\n",
    "p_model = ProbStackedICNNImputer(observables_size=obs_mask.shape[1],\n",
    "                             optax_optimiser_name='polyak_sgd',\n",
    "                             hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8218a0-d3dc-49ae-b84c-05bd4196fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def gaussian_kl(y: Tuple[jnp.ndarray, jnp.ndarray], y_hat: Tuple[jnp.ndarray, jnp.ndarray],\n",
    "                mask: Optional[jnp.ndarray] = None, axis: Optional[int] = None) -> jnp.ndarray:\n",
    "    \"\"\"KL divergence between two Gaussian distributions.\"\"\"\n",
    "    mean, std = y\n",
    "    mean_hat, std_hat = y_hat\n",
    "    kl = jnp.log(std) - jnp.log(std_hat) + (std_hat ** 2 + (mean - mean_hat) ** 2) / (2 * (std ** 2)) - 0.5\n",
    "    return jnp.nanmean(kl, axis=axis, where=mask)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def log_normal(y: Tuple[jnp.ndarray, jnp.ndarray], y_hat: Tuple[jnp.ndarray, jnp.ndarray],\n",
    "               mask: Optional[jnp.ndarray] = None, axis: Optional[int] = None) -> jnp.ndarray:\n",
    "    \"\"\"Log-normal loss.\"\"\"\n",
    "    mean, _ = y\n",
    "    mean_hat, std_hat = y_hat\n",
    "    error = (mean - mean_hat) / (std_hat + 1e-6)\n",
    "    log_normal_loss = 0.5 * (error ** 2 + 2 * jnp.log(std_hat + 1e-6))\n",
    "    return jnp.mean(log_normal_loss, axis=axis, where=mask)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def r_squared(y: jnp.ndarray, y_hat: jnp.ndarray, mask: jnp.ndarray) -> jnp.ndarray:\n",
    "    y = y.squeeze()\n",
    "    y_hat = y_hat.squeeze()\n",
    "    mask = mask.squeeze()\n",
    "\n",
    "\n",
    "    y_bar = jnp.nanmean(y, where=mask)\n",
    "    ss_tot = jnp.nansum((y - y_bar) ** 2, where=mask)\n",
    "    ss_res = jnp.nansum((y - y_hat) ** 2, where=mask)\n",
    "\n",
    "    return jnp.where(mask.sum() > 1, 1 - (ss_res / ss_tot), jnp.nan)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def r_squared_ranked_prob(y: jnp.ndarray, y_hat: jnp.ndarray, mask: jnp.ndarray, sigma: jnp.ndarray, k: int):\n",
    "    sigma = jnp.where(mask, sigma, jnp.inf)\n",
    "    sigma_sorter = jnp.argpartition(sigma, k, axis=0)[:k]\n",
    "    y = np.take_along_axis(y, sigma_sorter, axis=0)\n",
    "    y_hat = np.take_along_axis(y_hat, sigma_sorter, axis=0)\n",
    "    mask = np.take_along_axis(mask, sigma_sorter, axis=0)\n",
    "    return jnp.where(jnp.all(mask), r_squared(y, y_hat, mask), jnp.nan)\n",
    "\n",
    "\n",
    "def mse(X: jnp.ndarray, X_hat: jnp.ndarray, M: jnp.ndarray, axis: Optional[int] = None) -> jnp.ndarray:\n",
    "    return jnp.mean((X.flatten() - X_hat.flatten()) ** 2, where=M.flatten(), axis=axis)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def loss(model: ICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray, batch_M_art: jnp.ndarray) -> Tuple[\n",
    "    jnp.ndarray, ImputerMetrics]:\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    X_imp, aux = eqx.filter_vmap(model.partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    return mse(batch_X, X_imp, (~batch_M_art) & batch_M), aux\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def prob_loss(model: ProbICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray, batch_M_art: jnp.ndarray) -> Tuple[\n",
    "    jnp.ndarray, ImputerMetrics]:\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    (X_imp, std), aux = eqx.filter_vmap(model.prob_partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    mask = ~batch_M_art & batch_M\n",
    "    return log_normal((batch_X, jnp.zeros_like(batch_X) + 0.01), (X_imp, std), mask), aux\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def model_r_squared(model: ICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "                    batch_M_art: jnp.ndarray) -> jnp.ndarray:\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    X_imp, aux = eqx.filter_vmap(model.partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    mask = (~batch_M_art) & batch_M\n",
    "    r2_vec = eqx.filter_vmap(r_squared)(batch_X.T, X_imp.T, mask.T)\n",
    "    return r2_vec, aux\n",
    "\n",
    "    \n",
    "def model_r_squared_ranked_prob(model: ICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "                                batch_M_art: jnp.ndarray, k: int) -> jnp.ndarray:\n",
    "    # Penalise discrepancy with artifially masked-out values.\n",
    "    mask = (~batch_M_art) & batch_M\n",
    "    # Zero for artificially missig values\n",
    "    batch_X_art = jnp.where(batch_M_art, batch_X, 0.)\n",
    "    # Tune for artificially masked-out values, fix mask-in (batch_M_art) values.\n",
    "    (X_imp, std), aux = eqx.filter_vmap(model.prob_partial_input_optimise)(batch_X_art, batch_M_art)\n",
    "    r2_vec = eqx.filter_vmap(r_squared_ranked_prob)(batch_X.T, X_imp.T, mask.T, std.T, k)\n",
    "    return r2_vec, aux\n",
    "\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def loss_grad(model: ICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "              batch_M_art: jnp.ndarray) -> Tuple[\n",
    "    jnp.ndarray, ImputerMetrics]:\n",
    "    return loss(model, batch_X, batch_M, batch_M_art)\n",
    "\n",
    "\n",
    "@eqx.filter_value_and_grad(has_aux=True)\n",
    "def prob_loss_grad(model: ProbICNNObsDecoder, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "                   batch_M_art: jnp.ndarray) -> Tuple[\n",
    "    jnp.ndarray, ImputerMetrics]:\n",
    "    return prob_loss(model, batch_X, batch_M, batch_M_art)\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_step(model: ICNNObsDecoder, opt_state, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "              batch_M_art: jnp.ndarray):\n",
    "    (loss, aux), grads = loss_grad(model, batch_X, batch_M, batch_M_art)\n",
    "    updates, opt_state = optim.update(grads, opt_state,\n",
    "                                      params=eqx.filter(model, eqx.is_inexact_array),\n",
    "                                      value=loss, grad=grads,\n",
    "                                      value_fn=lambda m: loss(eqx.combine(m, model), batch_X, batch_y))\n",
    "\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return (loss, aux), model, opt_state\n",
    "\n",
    "\n",
    "@eqx.filter_jit\n",
    "def make_prob_step(model: ProbICNNObsDecoder, opt_state, batch_X: jnp.ndarray, batch_M: jnp.ndarray,\n",
    "                   batch_M_art: jnp.ndarray):\n",
    "    (loss, aux), grads = prob_loss_grad(model, batch_X, batch_M, batch_M_art)\n",
    "    updates, opt_state = optim.update(grads, opt_state,\n",
    "                                      params=eqx.filter(model, eqx.is_inexact_array),\n",
    "                                      value=loss, grad=grads,\n",
    "                                      value_fn=lambda m: prob_loss(eqx.combine(m, model), batch_X, batch_M,\n",
    "                                                                   batch_M_art))\n",
    "\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return (loss, aux), model, opt_state\n",
    "\n",
    "\n",
    "def dataloader(arrays, batch_size, *, key):\n",
    "    dataset_size = arrays[0].shape[0]\n",
    "    indices = jnp.arange(dataset_size)\n",
    "    while True:\n",
    "        perm = jrandom.permutation(key, indices)\n",
    "        (key,) = jrandom.split(key, 1)\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        while end < dataset_size:\n",
    "            batch_perm = perm[start:end]\n",
    "            yield tuple(array[batch_perm] for array in arrays)\n",
    "            start = end\n",
    "            end = start + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a80153-56a6-4010-a3f8-0fcc51cce898",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "steps=1000000\n",
    "train_batch_size=256\n",
    "test_batch_size=1024\n",
    "# train_batch_size=1\n",
    "# test_batch_size=1\n",
    "eval_frequency = 10\n",
    "\n",
    "optim = optax.novograd(lr)\n",
    "opt_state = optim.init(eqx.filter(p_model, eqx.is_inexact_array))\n",
    "data_train = (obs_val_train, obs_mask_train, art_mask_train)\n",
    "data_test = (obs_val_test, obs_mask_test, art_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9bc138-8411-4272-9f87-a7667dee68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = dataloader(data_train, train_batch_size, key=jrandom.PRNGKey(0))\n",
    "test_batches = iter(dataloader(data_test, train_batch_size, key=jrandom.PRNGKey(0)))\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667916bf-3ecb-49b2-84b2-fa701c4ddade",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = tqdm(range(steps))\n",
    "\n",
    "for step, batch_train in zip(progress, train_batches):\n",
    "    start = time.time()\n",
    "    (train_loss, train_aux), p_model, opt_state = make_prob_step(p_model, opt_state, *batch_train)\n",
    "    r2_vec, _ =  model_r_squared(p_model, *batch_train)\n",
    "    r2_vec_rank, _ = model_r_squared_ranked_prob(p_model, *batch_train, k=5)\n",
    "    r2_vec = np.array(r2_vec)\n",
    "    train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "    train_history['R2'].append(r2_vec)\n",
    "    train_history['R2_rank5'].append(r2_vec_rank)\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['n_opt_steps'].append(train_nsteps)\n",
    "    \n",
    "    end = time.time()\n",
    "    if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "        batch_test = next(test_batches)\n",
    "        test_loss, _ = prob_loss(p_model, *batch_test)\n",
    "        r2_vec_test, _ = model_r_squared(p_model, *batch_test)\n",
    "        r2_vec_rank_test, _ = model_r_squared_ranked_prob(p_model, *batch_test, k=10)\n",
    "        r2_vec_test = np.array(r2_vec_test)\n",
    "        test_history['loss'].append(test_loss)\n",
    "        test_history['R2'].append(r2_vec_test)\n",
    "        test_history['R2_rank10'].append(r2_vec_rank_test)\n",
    "\n",
    "    progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-R2: ({np.nanmax(r2_vec_rank):.2f}, {np.nanmin(r2_vec_rank):.2f}, {np.nanmean(r2_vec_rank):.2f}, {np.nanmedian(r2_vec_rank):.2f}),  Trn-N-steps: {train_nsteps}, \" \n",
    "                             f\"Tst-L:  {test_loss:.3f}, Tst-R2:  ({np.nanmax(r2_vec_rank_test):.2f}, {np.nanmin(r2_vec_rank_test):.2f}, {np.nanmean(r2_vec_rank_test):.2f}, {np.nanmedian(r2_vec_rank_test):.2f}), \"\n",
    "                             f\"Computation time: {end - start:.2f}, \")\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0da92e8-d693-4cb7-b31e-bfcd368dd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = pd.DataFrame(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78844f69-101e-4089-8bc6-bdd36b99c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_stats.zloss > train_stats.loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b7bd88-323c-4716-959a-7d2423c7fc85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
