{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb380ddbde124e58",
   "metadata": {},
   "source": [
    "# Libs Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663a98dc86faea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.config.update('jax_platforms', 'cpu')\n",
    "\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.icnn_modules import ProbStackedICNNImputer, ImputerMetrics, ProbICNNImputerTrainer\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config, append_params_to_zip, zip_members\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2e44ff7e8206f1",
   "metadata": {},
   "source": [
    "# Experiment Defnitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a517d3ac4b70e972",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_DIR = 'experiment_snapshots_mimic_ProbStackedICNN_kl_normalised'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3513dec9c345a13c",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8391a6767474f1",
   "metadata": {},
   "source": [
    "## First Time Loading and Writing to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d0faeda63f11fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvx = m4aki.TVxAKIMIMICIVDataset.load('/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e3827a5406c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs = [adm.observables  for subject in tvx0.subjects.values() for adm in subject.admissions]\n",
    "# adm_id = sum(([adm.admission_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])\n",
    "# subj_id = sum(([subject.subject_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae80982a5349098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val = np.vstack([obs_i.value for obs_i in obs])\n",
    "# obs_mask = np.vstack([obs_i.mask for obs_i in obs])\n",
    "# obs_time = np.hstack([obs_i.time for obs_i in obs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71441277cc77ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvx0.scheme.obs\n",
    "# features = list(map(tvx0.scheme.obs.desc.get, tvx0.scheme.obs.codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba3cf1dec01ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val = pd.DataFrame(obs_val, columns=features)\n",
    "# obs_mask = pd.DataFrame(obs_mask.astype(int), columns=features)\n",
    "# meta = pd.DataFrame({'subject_id': subj_id, 'admission_id': adm_id, 'time': obs_time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7521703988e88e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artificial_mask = obs_mask.copy()\n",
    "# artificial_mask = obs_mask & np.array(jrandom.bernoulli(jrandom.PRNGKey(0), p=0.8, shape=obs_mask.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497920e58d11e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# obs_val.to_csv('missingness_data/missingness_vals.csv')\n",
    "# obs_mask.to_csv('missingness_data/missingness_mask.csv')\n",
    "# meta.to_csv('missingness_data/meta.csv')\n",
    "# artificial_mask.to_csv('missingness_data/missingness_artificial_mask.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69924cb0815050",
   "metadata": {},
   "source": [
    "## Later Loading from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527c6082e7bb7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_val = pd.read_csv('missingness_data/missingness_vals.csv', index_col=[0])\n",
    "obs_mask = pd.read_csv('missingness_data/missingness_mask.csv', index_col=[0])\n",
    "artificial_mask = pd.read_csv('missingness_data/missingness_artificial_mask.csv', index_col=[0])\n",
    "meta = pd.read_csv('missingness_data/meta.csv', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401516dad02e698",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab0abfa0b469a1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ratio = 0.7\n",
    "seed = 0\n",
    "indices = jrandom.permutation(jrandom.PRNGKey(seed), len(obs_val))\n",
    "train_idx = indices[:int(split_ratio * len(indices))]\n",
    "test_idx = indices[int(split_ratio * len(indices)):]\n",
    "\n",
    "obs_val_train = jnp.array(obs_val.iloc[train_idx].to_numpy())\n",
    "obs_mask_train = jnp.array(obs_mask.iloc[train_idx].to_numpy())\n",
    "art_mask_train =  jnp.array(artificial_mask.iloc[train_idx].to_numpy())\n",
    "\n",
    "obs_val_test = jnp.array(obs_val.iloc[test_idx].to_numpy())\n",
    "obs_mask_test = jnp.array(obs_mask.iloc[test_idx].to_numpy())\n",
    "art_mask_test =  jnp.array(artificial_mask.iloc[test_idx].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd1333-d365-4f8f-8256-6815a6166e51",
   "metadata": {},
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f8178ba-92a5-4d54-a5a8-dab696861d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ICNNObsDecoder(observables_size=obs_mask.shape[1], state_size=0, \n",
    "#                        optax_optimiser_name='polyak_sgd',\n",
    "#                        hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "\n",
    "model = ProbStackedICNNImputer(observables_size=obs_mask.shape[1],\n",
    "                               state_size = 0,\n",
    "                               positivity='abs',\n",
    "                               optax_optimiser_name='polyak_sgd',\n",
    "                               hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "trainer = ProbICNNImputerTrainer(loss='kl_divergence', loss_feature_normalisation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc000648fcc816",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f942829c18b82c",
   "metadata": {},
   "source": [
    "## ICNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9617a8d45820c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=5e-4\n",
    "steps=10000\n",
    "train_batch_size=256\n",
    "test_batch_size=1024\n",
    "# train_batch_size=1\n",
    "# test_batch_size=1\n",
    "eval_frequency = 10\n",
    "model_snapshot_frequency = 100\n",
    "\n",
    "optim = optax.novograd(lr)\n",
    "opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "data_train = (obs_val_train, obs_mask_train, art_mask_train)\n",
    "data_test = (obs_val_test, obs_mask_test, art_mask_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f91327d24c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batches = trainer.dataloader(data_train, train_batch_size, key=jrandom.PRNGKey(0))\n",
    "test_batches = iter(trainer.dataloader(data_test, train_batch_size, key=jrandom.PRNGKey(0)))\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)\n",
    "model_snapshots = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c756777514bcdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "progress = tqdm(range(steps))\n",
    "\n",
    "for step, batch_train in zip(progress, train_batches):\n",
    "    start = time.time()\n",
    "    (train_loss, train_aux), model, opt_state = trainer.make_step(model, optim, opt_state, *batch_train)\n",
    "    r2_vec =  trainer.model_r_squared(model, *batch_train)\n",
    "    r2_vec_rank = trainer.model_r_squared_ranked_prob(model, *batch_train, k=5)\n",
    "    r2_vec = np.array(r2_vec)\n",
    "    train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "    train_history['R2'].append(r2_vec)\n",
    "    train_history['R2_rank5'].append(r2_vec_rank)\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['n_opt_steps'].append(train_nsteps)\n",
    "\n",
    "    end = time.time()\n",
    "    if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "        batch_test = next(test_batches)\n",
    "        test_loss, _ = trainer.loss(model, *batch_test)\n",
    "        r2_vec_test = trainer.model_r_squared(model, *batch_test)\n",
    "        r2_vec_rank_test = trainer.model_r_squared_ranked_prob(model, *batch_test, k=10)\n",
    "        r2_vec_test = np.array(r2_vec_test)\n",
    "        test_history['loss'].append(test_loss)\n",
    "        test_history['R2'].append(r2_vec_test)\n",
    "        test_history['R2_rank10'].append(r2_vec_rank_test)\n",
    "\n",
    "    if (step % model_snapshot_frequency) == 0 or step == steps - 1:\n",
    "        model_snapshots[step] = model\n",
    "        append_params_to_zip(model, f'step{step:04d}.eqx', f'{EXP_DIR}/params.zip')\n",
    "\n",
    "    progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-R2: ({np.nanmax(r2_vec_rank):.2f}, {np.nanmin(r2_vec_rank):.2f}, {np.nanmean(r2_vec_rank):.2f}, {np.nanmedian(r2_vec_rank):.2f}),  Trn-N-steps: {train_nsteps}, \"\n",
    "                             f\"Tst-L:  {test_loss:.3f}, Tst-R2:  ({np.nanmax(r2_vec_rank_test):.2f}, {np.nanmin(r2_vec_rank_test):.2f}, {np.nanmean(r2_vec_rank_test):.2f}, {np.nanmedian(r2_vec_rank_test):.2f}), \"\n",
    "                             f\"Computation time: {end - start:.2f}, \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "896801642a40a284",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_members(f'{EXP_DIR}/params.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bf51459abf3e84",
   "metadata": {},
   "source": [
    "### Dump Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30024a1c3cd9ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN\n",
    "\n",
    "# train_stats = pd.DataFrame(train_history)\n",
    "# test_stats = pd.DataFrame(test_history)\n",
    "\n",
    "# train_stats['split'] = 'Train'\n",
    "# train_stats['iteration'] = train_stats.index + 1\n",
    "# test_stats['split'] = 'Test'\n",
    "# test_stats['iteration'] = (test_stats.index * eval_frequency) + 1\n",
    "# training_stats = pd.concat([train_stats, test_stats])\n",
    "# training_stats_melted = pd.melt(training_stats, value_vars=['loss'], id_vars=['split', 'iteration'], value_name='Loss')\n",
    "# training_stats_melted = training_stats_melted.astype({'Loss': float})\n",
    "\n",
    "# training_stats.to_csv(f'{EXP_DIR}/icnn_training_stats.csv')\n",
    "# training_stats_melted.to_csv(f'{EXP_DIR}/icnn_training_stats_melted.csv')\n",
    "\n",
    "# FIRST TIME - END\n",
    "\n",
    "\n",
    "# LATER TIMES\n",
    "training_stats = pd.read_csv(f'{EXP_DIR}/icnn_training_stats.csv', index_col=[0])\n",
    "training_stats_melted = pd.read_csv(f'{EXP_DIR}/icnn_training_stats_melted.csv', index_col=[0])\n",
    "\n",
    "\n",
    "\n",
    "g2 = sns.lineplot(data=training_stats_melted, x=\"iteration\", y=\"Loss\", hue=\"split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1fb803074a2a5a",
   "metadata": {},
   "source": [
    "## Sklearn Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b6b13c09d651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "\n",
    "sklearn_imputers =  {\n",
    "    'zero_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': lambda: KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': lambda: IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}\n",
    "\n",
    "sklearn_trained_imputers = {k: v().fit(np.where(obs_mask_train, obs_val_train, np.nan)) for k, v in sklearn_imputers.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1fe5998d572e",
   "metadata": {},
   "source": [
    "# Metrics / Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4faa4f9599fab0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask = (1 - art_mask_test) * obs_mask_test\n",
    "feature2index =  dict(zip(obs_val.columns, range(len(obs_val.columns))))\n",
    "n_train = ((1 - art_mask_train) * obs_mask_train).sum(axis=0)\n",
    "n_test = ((1 - art_mask_test) * obs_mask_test).sum(axis=0)\n",
    "n_train_measured = obs_mask_train.sum(axis=0)\n",
    "missingness = 1 - obs_mask.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9dae9d44346e8",
   "metadata": {},
   "source": [
    "## Metrics Evolution with ICNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a6e7643082b4967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN\n",
    "\n",
    "# dataframes = []\n",
    "# for step, model_snap in tqdm(model_snapshots.items()):\n",
    "#     with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#         obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#         (X_test_imp, X_test_std), _ = eqx.filter_vmap(model_snap.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "\n",
    "#     sigma_threshold = [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "#     r2_vec_thresholded = [eqx.filter_vmap(ProbICNNImputerTrainer.r_squared_thresholded_prob)(obs_val_test.T, X_test_imp.T, prediction_mask.T, X_test_std.T,  t)\n",
    "#                           for t in sigma_threshold]\n",
    "\n",
    "#     r2_test_results = pd.DataFrame(np.vstack(r2_vec_thresholded), columns=obs_val.columns)\n",
    "#     r2_test_results['sigma_threshold'] = sigma_threshold\n",
    "#     r2_test_results['step'] = step\n",
    "#     dataframes.append(r2_test_results)\n",
    "\n",
    "# r2_iters_test_results = pd.concat(dataframes)\n",
    "# r2_iters_test_results = pd.melt(r2_iters_test_results, value_vars=list(obs_val.columns), id_vars=['sigma_threshold', 'step'], value_name='R2')\n",
    "\n",
    "# r2_iters_test_results.to_csv(f'{EXP_DIR}/r2_iters_test_results.csv')\n",
    "# FIRST TIME - END\n",
    "r2_iters_test_results = pd.read_csv(f'{EXP_DIR}/r2_iters_test_results.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03de2281-09af-48bd-8348-617d595f230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_iters_test_results['missingness'] = r2_iters_test_results.variable.map(lambda x: missingness[feature2index[x]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58b10df7-57bf-41be-91dd-aa997bff6ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_iters_test_results[r2_iters_test_results.missingness < 0.8].variable.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9010174-25f5-47ee-8e02-92a86b52b2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_iters_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869a539bd87628f3",
   "metadata": {},
   "source": [
    "## Metrics of the Last ICNN Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10b7b110ba7e3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.load_params_from_archive(f'{EXP}/params.zip', 'step9999.eqx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b93a1caad2af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN\n",
    "# with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#     obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#     (X_test_imp, X_test_std), _ = eqx.filter_vmap(model.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "# FIRST TIME - END\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1378083122037b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN\n",
    "# SE = (X_test_imp - obs_val_test) ** 2\n",
    "# SE = jnp.where(prediction_mask, SE, jnp.nan)\n",
    "# X_test_var = jnp.where(prediction_mask, X_test_std ** 2, jnp.nan)\n",
    "\n",
    "# se_data = defaultdict(list)\n",
    "# for i in range(SE.shape[1]):\n",
    "#     se_data['SE'].extend(np.array(SE[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "#     se_data['sigma2'].extend(np.array(X_test_var[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "#     se_data['Feature'].extend([obs_val.columns[i]] * int(prediction_mask[:, i].sum()))\n",
    "\n",
    "# se_df = pd.DataFrame(se_data)\n",
    "# se_df.to_csv(f'{EXP_DIR}/icnn_se_stats.csv')\n",
    "# FIRST TIME - END\n",
    "\n",
    "# LATER TIMES\n",
    "se_df = pd.read_csv(f'{EXP_DIR}/icnn_se_stats.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496ab663978f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN\n",
    "\n",
    "features_r2 = eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, X_test_imp.T, prediction_mask.T)\n",
    "sigma_threshold = [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "r2_vec_thresholded = [eqx.filter_vmap(ProbICNNImputerTrainer.r_squared_thresholded_prob)(obs_val_test.T, X_test_imp.T, prediction_mask.T, X_test_std.T,  t)\n",
    "                      for t in sigma_threshold]\n",
    "r2_test_thresholded_df = pd.DataFrame(np.vstack(r2_vec_thresholded), columns=obs_val.columns)\n",
    "r2_test_thresholded_df['sigma_threshold'] = sigma_threshold\n",
    "\n",
    "r2_test_thresholded_melted_df = pd.melt(r2_test_thresholded_df, value_vars=list(obs_val.columns), id_vars=['sigma_threshold'], value_name='R2')\n",
    "\n",
    "\n",
    "icnn_features_stats = defaultdict(list)\n",
    "n_train = ((1 - art_mask_train) * obs_mask_train).sum(axis=0)\n",
    "\n",
    "for feature, feature_df in se_df.groupby('Feature'):\n",
    "    icnn_features_stats['Feature'].append(feature)\n",
    "    icnn_features_stats['n_training_measured'].append(n_train_measured[feature2index[feature]])\n",
    "    icnn_features_stats['n_training_censored'].append(n_train[feature2index[feature]])\n",
    "    icnn_features_stats['n_test_censored'].append(n_test[feature2index[feature]])\n",
    "    icnn_features_stats['missingness'].append(missingness[feature2index[feature]].item())\n",
    "    icnn_features_stats['R2'].append(features_r2[feature2index[feature]].item())\n",
    "    icnn_features_stats['sigma2_se_spearman'].append(spearmanr(feature_df['SE'], feature_df['sigma2']).statistic)\n",
    "\n",
    "icnn_features_stats_df = pd.DataFrame(icnn_features_stats)\n",
    "\n",
    "\n",
    "r2_test_thresholded_df.to_csv(f'{EXP_DIR}/r2_test_thresholded.csv')\n",
    "r2_test_thresholded_melted_df.to_csv(f'{EXP_DIR}/r2_test_thresholded_melted.csv')\n",
    "icnn_features_stats_df.to_csv(f'{EXP_DIR}/icnn_features_stats.csv')\n",
    "\n",
    "# LATER TIMES\n",
    "r2_test_thresholded_df = pd.read_csv(f'{EXP_DIR}/r2_test_thresholded.csv', index_col=[0])\n",
    "r2_test_thresholded_melted_df = pd.read_csv(f'{EXP_DIR}/r2_test_thresholded_melted.csv', index_col=[0])\n",
    "icnn_features_stats_df = pd.read_csv(f'{EXP_DIR}/icnn_features_stats.csv', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58eca4173e479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.stripplot(data=r2_test_results, x=\"sigma_threshold\", y=\"R2\", hue=\"variable\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa02421db8c00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_se_sigma_all = spearmanr(se_df['SE'], se_df['sigma2']).statistic\n",
    "pearson_se_sigma_all = pearsonr(se_df['SE'], se_df['sigma2']).statistic\n",
    "r2_all = ProbICNNImputerTrainer.r_squared(obs_val_test, X_test_imp, prediction_mask)\n",
    "icnn_global_stats = pd.DataFrame({r'$r_\\text{Pearson}(SE, \\sigma^2)$': [pearson_se_sigma_all],\n",
    "                                  r'$r_\\text{Searson}(SE, \\sigma^2)$': [spearman_se_sigma_all],\n",
    "                                  r'$R^2(z, \\mu)$': [r2_all]})\n",
    "icnn_global_stats.to_csv(f'{EXP_DIR}/icnn_global_stats.csv')\n",
    "icnn_global_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b79b24b3fe9c06",
   "metadata": {},
   "source": [
    "## Metrics of Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97147098a0036cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_imputed_X = {k: v.transform(np.where(art_mask_test, obs_val_test, np.nan)) for k, v in sklearn_trained_imputers.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f76361aa0e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_performance_data = defaultdict(list)\n",
    "sklearn_performance_per_feature_data = defaultdict(list)\n",
    "\n",
    "for sklearn_imputer_name, sklearn_imputed_X_ in sklearn_imputed_X.items():\n",
    "    r2 = ProbICNNImputerTrainer.r_squared(obs_val_test, sklearn_imputed_X_, prediction_mask)\n",
    "    features_r2 = eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, sklearn_imputed_X_.T, prediction_mask.T)\n",
    "\n",
    "    sklearn_performance_data['sklearn_imputer'].append(sklearn_imputer_name)\n",
    "    sklearn_performance_data['R2'].append(r2.item())\n",
    "\n",
    "    sklearn_performance_per_feature_data['R2'].extend(features_r2.tolist())\n",
    "    sklearn_performance_per_feature_data['sklearn_imputer'].extend([sklearn_imputer_name] * len(obs_val.columns))\n",
    "    sklearn_performance_per_feature_data['feature'].extend(obs_val.columns.tolist())\n",
    "    sklearn_performance_per_feature_data['missingness'].extend(missingness.tolist())\n",
    "\n",
    "sklearn_performance_df = pd.DataFrame(sklearn_performance_data)\n",
    "sklearn_performance_per_feature_df = pd.DataFrame(sklearn_performance_per_feature_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c400d782fc6cc940",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_performance_per_feature_df.to_csv(f'{EXP_DIR}/sklearn_features_stats.csv')\n",
    "sklearn_performance_df.to_csv(f'{EXP_DIR}/sklearn_stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841370c9414e503",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950e448ba3533f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_performance_per_feature_df[(sklearn_performance_per_feature_df.missingness < 0.8)].sort_values(['sklearn_imputer', 'R2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb37c49908842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_corrs_df[(feature_corrs_df.missingness < 0.8)].sort_values('R2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a1ce65ddd6ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_test_results = r2_test_results[r2_test_results.R2 >= 0.1]\n",
    "r2_test_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
