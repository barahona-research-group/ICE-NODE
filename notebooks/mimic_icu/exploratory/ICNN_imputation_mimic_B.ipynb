{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "# Libs Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jr \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.config.update('jax_platforms', 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.icnn_modules import ProbStackedICNNImputer, ImputerMetrics, ProbICNNImputerTrainer, ICNNObsDecoder, StandardICNNImputerTrainer\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config, append_params_to_zip, zip_members\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c6026aa-f316-46f6-a762-804061ec8982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?pub_ready_plots.get_mpl_rcParams\n",
    "# !pip install pub-ready-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47821903-74e5-4804-8668-3e3dab89b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pub_ready_plots\n",
    "from pub_ready_plots import get_mpl_rcParams\n",
    "rc_params, fig_width_in, fig_height_in = pub_ready_plots.get_mpl_rcParams(\n",
    "    width_frac=1,  # between 0 and 1\n",
    "    height_frac=0.2,  # between 0 and 1\n",
    "    layout=\"jmlr\"  # or \"iclr\", \"neurips\", \"poster-portrait\", \"poster-landscape\"\n",
    ")\n",
    "rc_params['figure.constrained_layout.use'] = True\n",
    "\n",
    "# rc_params['font.size'] = 10\n",
    "# rc_params['axes.titlesize'] = 12\n",
    "# rc_params['axes.labelsize'] = 10\n",
    "# rc_params['legend.fontsize'] = 10\n",
    "\n",
    "plt.rcParams.update(rc_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "320f1e48-f072-4099-bc5e-6cc4dc90b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rc_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b7608-1d1d-4f35-9610-1f49be0432af",
   "metadata": {},
   "source": [
    "# Experiment Defnitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43fcbc3b-46de-4f21-9805-556534fd5a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROB_MODELS = ('ICNN_LN', 'ICNN_NLN', 'ICNN_KL', 'ICNN_NKL', 'ICNN_KLR', 'ICNN_NKLR', 'ICNN_JSD', 'ICNN_NJSD')\n",
    "DET_MODELS = ('ICNN_MSE', 'ICNN_NMSE')\n",
    "\n",
    "EXP_DIR = {\n",
    "    key: f'snapshots_{key.lower()}' for key in PROB_MODELS + DET_MODELS\n",
    "}\n",
    "\n",
    "\n",
    "def experiment_data(dataset_path: str):\n",
    "    obs_val = pd.read_csv(f'{dataset_path}/missingness_vals.csv', index_col=[0])\n",
    "    obs_mask = pd.read_csv(f'{dataset_path}/missingness_mask.csv', index_col=[0])\n",
    "    artificial_mask = pd.read_csv(f'{dataset_path}/missingness_artificial_mask.csv', index_col=[0])\n",
    "    return obs_val, obs_mask, artificial_mask\n",
    "\n",
    "\n",
    "def experiment_model(exp: str, observables_size: int):\n",
    "    pmodels = {\n",
    "        k: ProbStackedICNNImputer(observables_size=observables_size, state_size=0, optimiser_name='lamb',\n",
    "                                  max_steps=2 ** 9, lr=1e-2,\n",
    "                                  positivity='softplus', hidden_size_multiplier=2, depth=5, key=jr.PRNGKey(0))\n",
    "        for k in PROB_MODELS}\n",
    "    # pmodels['ICNN_LN'] = ProbStackedICNNImputer(observables_size=observables_size, state_size=0, optimiser_name='lamb',\n",
    "    #                               max_steps=2 ** 9, lr=1e-2,\n",
    "    #                               positivity='clipped', hidden_size_multiplier=2, depth=5, key=jr.PRNGKey(0))\n",
    "\n",
    "    dmodels = {k: ICNNObsDecoder(observables_size=observables_size, state_size=0, optimiser_name='lamb',\n",
    "                                 max_steps=2 ** 9, lr=1e-2,\n",
    "                                 positivity='softplus', hidden_size_multiplier=3, depth=5, key=jr.PRNGKey(0))\n",
    "               for k in DET_MODELS}\n",
    "    return (pmodels | dmodels)[exp]\n",
    "\n",
    "\n",
    "def experiment_trainer(e: str):\n",
    "    return {\n",
    "        'ICNN_LN': ProbICNNImputerTrainer(loss='log_normal', optimiser_name='adam'),\n",
    "        'ICNN_NLN': ProbICNNImputerTrainer(loss='log_normal', optimiser_name='adam', loss_feature_normalisation=True),\n",
    "        'ICNN_KL': ProbICNNImputerTrainer(loss='kl_divergence', optimiser_name='adam', ),\n",
    "        'ICNN_NKL': ProbICNNImputerTrainer(loss='kl_divergence', optimiser_name='adam',\n",
    "                                           loss_feature_normalisation=True),\n",
    "        'ICNN_KLR': ProbICNNImputerTrainer(loss='klr_divergence', optimiser_name='adam', ),\n",
    "        'ICNN_NKLR': ProbICNNImputerTrainer(loss='klr_divergence', optimiser_name='adam',\n",
    "                                           loss_feature_normalisation=True),\n",
    "        'ICNN_JSD': ProbICNNImputerTrainer(loss='jsd_gaussian', optimiser_name='adam'),\n",
    "        'ICNN_NJSD': ProbICNNImputerTrainer(loss='jsd_gaussian', optimiser_name='adam',\n",
    "                                            loss_feature_normalisation=True),\n",
    "        'ICNN_MSE': StandardICNNImputerTrainer(optimiser_name='adam'),\n",
    "        'ICNN_NMSE': StandardICNNImputerTrainer(optimiser_name='adam', loss_feature_normalisation=True)\n",
    "    }[e]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d0c2f80-ba34-4308-b6bc-5751b0f8730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'icnn_results_B'\n",
    "EXPERIMENTS_DIR = '/home/asem/GP/ehr-data/icnn_imputation_experiments'\n",
    "DATASET_PATH = '/home/asem/GP/ehr-data/missingness_data'\n",
    "ICNN_RENAMES = {k: f'P-ICNN ({k.split(\"_\")[1]})' for k in PROB_MODELS}  | {k: f'S-ICNN ({k.split(\"_\")[1]})' for k in DET_MODELS}\n",
    "\n",
    "\n",
    "EXP = 'ICNN_NMSE'\n",
    "experiment_dir = f'{EXPERIMENTS_DIR}/{EXP_DIR[EXP]}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9b42f56-270f-4e17-8c93-e79af7638e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_val, obs_mask, artificial_mask = experiment_data(DATASET_PATH)\n",
    "model = experiment_model(EXP, obs_val.shape[1])\n",
    "trainer = experiment_trainer(EXP)\n",
    "\n",
    "split_ratio = 0.7\n",
    "seed = 0\n",
    "indices = jr.permutation(jr.PRNGKey(seed), len(obs_val))\n",
    "train_idx = indices[:int(split_ratio * len(indices))]\n",
    "test_idx = indices[int(split_ratio * len(indices)):]\n",
    "\n",
    "obs_val_train = jnp.array(obs_val.iloc[train_idx].to_numpy())\n",
    "obs_mask_train = jnp.array(obs_mask.iloc[train_idx].to_numpy())\n",
    "art_mask_train = jnp.array(artificial_mask.iloc[train_idx].to_numpy())\n",
    "\n",
    "\n",
    "\n",
    "obs_val_test = jnp.array(obs_val.iloc[test_idx].to_numpy())\n",
    "obs_mask_test = jnp.array(obs_mask.iloc[test_idx].to_numpy())\n",
    "art_mask_test = jnp.array(artificial_mask.iloc[test_idx].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29554212-d63c-4770-892d-fbc66b2d01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooc = obs_mask.T.dot(obs_mask)\n",
    "# cooc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82d35d3f-3cb5-47df-8580-4ce74e545308",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sns.heatmap(np.log10(cooc + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c41bc77d-53b5-47c9-b9ea-1172bf807cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(obs_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f86a6f9-0dff-4451-84a8-767c4b7171d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "p_mask = pd.DataFrame({'abundance': obs_mask.mean(axis=0)})\n",
    "\n",
    "\n",
    "# sns.kdeplot(data=p_mask, x=\"abundance\", log_scale=True)\n",
    "# sns.rugplot(data=p_mask, x=\"abundance\")\n",
    "sns.set_theme(style=\"ticks\")\n",
    "# sns.kdeplot(data=p_mask, x=\"abundance\", log_scale=True)\n",
    "g = sns.rugplot(data=p_mask, x=\"abundance\")\n",
    "g.set_xscale('log')\n",
    "\n",
    "sns.histplot(\n",
    "    p_mask,\n",
    "    x=\"abundance\", \n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    log_scale=True,\n",
    ")\n",
    "g.get_figure().set_size_inches(fig_width_in, fig_height_in * 1.5)\n",
    "g.get_figure().savefig(f\"{RESULTS_DIR}/features_abundance.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafd8d9d-dbca-41b7-bce3-6f186af0d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c557df37-73c9-407e-91d9-22f7f0049d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip_members(f'{EXP_DIR}/params.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6fd8da-08b1-4cd1-aed8-0e3bd3e05e0b",
   "metadata": {},
   "source": [
    "### Dump Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55fb9a75-66da-4c40-817c-ffc978260f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN \n",
    "\n",
    "# train_stats = pd.DataFrame(train_history)\n",
    "# test_stats = pd.DataFrame(test_history)\n",
    "\n",
    "# train_stats['split'] = 'Train'\n",
    "# train_stats['iteration'] = train_stats.index + 1\n",
    "# test_stats['split'] = 'Test'\n",
    "# test_stats['iteration'] = (test_stats.index * eval_frequency) + 1\n",
    "# training_stats = pd.concat([train_stats, test_stats])\n",
    "# training_stats_melted = pd.melt(training_stats, value_vars=['loss'], id_vars=['split', 'iteration'], value_name='Loss')\n",
    "# training_stats_melted = training_stats_melted.astype({'Loss': float})\n",
    "\n",
    "# training_stats.to_csv(f'{RESULTS_DIR}/{EXP}_training_stats.csv')  \n",
    "# training_stats_melted.to_csv(f'{RESULTS_DIR}/{EXP}_training_stats_melted.csv')  \n",
    "\n",
    "# FIRST TIME - END \n",
    "\n",
    "\n",
    "# LATER TIMES\n",
    "# training_stats = pd.read_csv(f'{RESULTS_DIR}/{EXP}_training_stats.csv', index_col=[0])  \n",
    "# training_stats_melted = pd.read_csv(f'{RESULTS_DIR}/{EXP}_training_stats_melted.csv', index_col=[0])  \n",
    "\n",
    "\n",
    "\n",
    "# g2 = sns.lineplot(data=training_stats_melted, x=\"iteration\", y=\"Loss\", hue=\"split\")\n",
    "# g2.get_figure().set_size_inches(fig_width_in, fig_height_in)\n",
    "# g2.get_figure().savefig(f\"{RESULTS_DIR}/{EXP}_training_stats.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eb079d-85a1-496a-90ef-33d1e80f1541",
   "metadata": {},
   "source": [
    "## Sklearn Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5569883-85ef-4376-87cb-a183073031e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "\n",
    "sklearn_imputers =  {\n",
    "    'zero_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': lambda: KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': lambda: IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}\n",
    "\n",
    "# sklearn_trained_imputers = {k: v().fit(np.where(obs_mask_train, obs_val_train, np.nan)) for k, v in sklearn_imputers.items()} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927aead-36dd-4806-ba36-99e5f1d3c74a",
   "metadata": {},
   "source": [
    "# Metrics / Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9da35ee-5429-492b-81e8-bb0a29273588",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask = (1 - art_mask_test) * obs_mask_test\n",
    "feature2index =  dict(zip(obs_val.columns, range(len(obs_val.columns))))\n",
    "n_train = ((1 - art_mask_train) * obs_mask_train).sum(axis=0)\n",
    "n_test = ((1 - art_mask_test) * obs_mask_test).sum(axis=0)\n",
    "n_train_measured = obs_mask_train.sum(axis=0)\n",
    "missingness = 1 - obs_mask.mean(axis=0)\n",
    "validation_missingness = 1 - pd.DataFrame(art_mask_test, columns=obs_mask.columns).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc7be4d1-41e2-4edd-a808-9610b7f2b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_censored = pd.Series(prediction_mask.sum(axis=0), index=obs_val.columns)\n",
    "p_test_censored = n_test_censored / len(prediction_mask)\n",
    "vars_n300 = n_test_censored[n_test_censored >= 300].index\n",
    "vars_n300_r = n_test_censored[n_test_censored < 300].index\n",
    "vars_n300, len(vars_n300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2a091cb-8df8-4d80-9468-86d5678d02fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_map = {'blood_chemistry.albumin': 'Albumin',  'blood_chemistry.aniongap': 'Aniongap',  \n",
    "                'blood_chemistry.bicarbonate': 'bc.Bicarbonate',  'blood_chemistry.bun': 'Urea Nitrogen', \n",
    "                'blood_chemistry.calcium': 'bc.Calcium',  'blood_chemistry.chloride': 'bc.Chloride',  \n",
    "                'blood_chemistry.creatinine': 'bc.Creatinine',  'blood_chemistry.globulin': 'Globulin',  \n",
    "                'blood_chemistry.glucose': 'bc.Glucose',  'blood_chemistry.potassium': 'bc.Potassium',  \n",
    "                'blood_chemistry.sodium': 'bc.Sodium',  'blood_chemistry.total_protein': 'Protein Total', \n",
    "                'blood_diff.atypical_lymphocytes': 'Atypical Lymphocytes',  'blood_diff.bands': 'Bands (%)',  \n",
    "                'blood_diff.basophils': 'Basophils',  'blood_diff.basophils_abs': 'Abs Basophils', \n",
    "                'blood_diff.eosinophils': 'Eosinophils',  'blood_diff.eosinophils_abs': 'Abs Eosinophils', \n",
    "                'blood_diff.immature_granulocytes': 'Immature Granulocytes',  'blood_diff.lymphocytes': 'Lymphocytes',\n",
    "                'blood_diff.lymphocytes_abs': 'Abs Lymphocytes',  'blood_diff.metamyelocytes': 'Metamyelocytes', \n",
    "                'blood_diff.monocytes': 'Monocytes',  'blood_diff.monocytes_abs': 'Abs Monocytes', \n",
    "                'blood_diff.neutrophils': 'Neutrophils',  'blood_diff.neutrophils_abs': 'Abs Neutrophil', \n",
    "                'blood_diff.nrbc': 'NRBC',  'blood_gas.aado2': 'AaDO2',  'blood_gas.aado2_calc': 'AaDO2_calc',\n",
    "                'blood_gas.baseexcess': 'Base excess',  'blood_gas.bicarbonate': 'bg.Bicarbonate',  'blood_gas.calcium': 'bg.Calcium',  \n",
    "                'blood_gas.carboxyhemoglobin': 'Carboxyhemoglobin',  'blood_gas.chloride': 'bg.Chloride',  'blood_gas.fio2': 'FiO2',  \n",
    "                'blood_gas.fio2_chartevents': 'FiO2_chartevents',  'blood_gas.glucose': 'bg.Glucose',  \n",
    "                'blood_gas.hematocrit': 'bg.Hematocrit',  'blood_gas.hemoglobin': 'bg.Hemoglobin',  'blood_gas.lactate': 'Lactate', \n",
    "                'blood_gas.methemoglobin': 'Methemoglobin',  'blood_gas.pao2fio2ratio': 'pO2/FiO2 ratio',  'blood_gas.pco2': 'pCO2',\n",
    "                'blood_gas.ph': 'pH',  'blood_gas.po2': 'pO2',  'blood_gas.potassium': 'bg.Potassium',  'blood_gas.so2': 'sO2', \n",
    "                'blood_gas.sodium': 'bg.Sodium',  'blood_gas.temperature': 'bg.Temperature',  'blood_gas.totalco2': 'CO2 total', \n",
    "                'cardiac_marker.ck_mb': 'Creatinine Kinase, MB',  'cardiac_marker.ntprobnp': 'NT-proBNP', \n",
    "                'cardiac_marker.troponin_t2': 'Troponin T',  'cbc.hematocrit': 'cbc.Hematocrit',  'cbc.hemoglobin': 'cbc.Hemoglobin', \n",
    "                'cbc.mch': 'MCH',  'cbc.mchc': 'MCHC',  'cbc.mcv': 'MCV',  'cbc.platelet': 'Platelet',  'cbc.rbc': 'RBC', \n",
    "                'cbc.rdw': 'RDW',  'cbc.wbc': 'WBC',  'coagulation.d_dimer': 'D-Dimer',  'coagulation.fibrinogen': 'Fibrinogen', \n",
    "                'coagulation.inr': 'INR',  'coagulation.pt': 'PT',  'coagulation.ptt': 'PTT',  'coagulation.thrombin': 'Thrombin',\n",
    "                'enzymes.alp': 'ALP',  'enzymes.alt': 'ALT',  'enzymes.amylase': 'Amylase',  'enzymes.ast': 'AST', \n",
    "                'enzymes.bilirubin_direct': 'Bilirubin direct',  'enzymes.bilirubin_indirect': 'Bilirubin indirect',\n",
    "                'enzymes.bilirubin_total': 'Bilirubin total',  'enzymes.ck_cpk': 'CK-CPK',  'enzymes.ck_mb':'CK-MB', \n",
    "                'enzymes.ggt': 'GGT',  'enzymes.ld_ldh': 'ld_ldh',  'icp.icp': 'Intra-cranial Press.',\n",
    "                'inflammation.crp': 'CRP',  'renal_aki.aki_binary': 'AKI (binary)',  'renal_aki.aki_stage_smoothed': 'AKI', \n",
    "                'renal_creat.creat': 'renal.Creatinine',  'renal_out.uo_rt_12hr': 'Urine out 12h',  'renal_out.uo_rt_24hr': 'Urine out 24h',\n",
    "                'renal_out.uo_rt_6hr': 'Urine out 6h',  'sofa.sofa_24hours': 'SOFA',  'vital.dbp': 'Diastolic BP', \n",
    "                'vital.dbp_ni': 'NI-Diastolic BP',  'vital.glucose': 'vital.Glucose',  'vital.heart_rate': 'Heart Rate',  \n",
    "                'vital.mbp':  'Mean BP',  'vital.mbp_ni': 'NI Mean BP',  'vital.resp_rate': 'Respiratory Rate', \n",
    "                'vital.sbp': 'Systolic BP',  'vital.sbp_ni':  'NI-Systolic BP',  'vital.spo2': 'SpO2',  \n",
    "                'vital.temperature': 'vital.Temperature',  'weight.weight': 'Weight'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e8839-9dab-4409-952a-4c0a67b9b64f",
   "metadata": {},
   "source": [
    "## Metrics Evolution with ICNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d6b7bd88-323c-4716-959a-7d2423c7fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN \n",
    "\n",
    "# dataframes = []\n",
    "# for step, model_snap in tqdm(model_snapshots.items()):\n",
    "#     with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#         obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#         (X_test_imp, X_test_std), _ = eqx.filter_vmap(model_snap.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "    \n",
    "#     sigma_threshold = [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "#     r2_vec_thresholded = [eqx.filter_vmap(ProbICNNImputerTrainer.r_squared_thresholded_prob)(obs_val_test.T, X_test_imp.T, prediction_mask.T, X_test_std.T,  t)\n",
    "#                           for t in sigma_threshold]\n",
    "    \n",
    "#     r2_test_results = pd.DataFrame(np.vstack(r2_vec_thresholded), columns=obs_val.columns)\n",
    "#     r2_test_results['sigma_threshold'] = sigma_threshold\n",
    "#     r2_test_results['step'] = step\n",
    "#     dataframes.append(r2_test_results)\n",
    "\n",
    "# r2_iters_test_results = pd.concat(dataframes)\n",
    "# r2_iters_test_results = pd.melt(r2_iters_test_results, value_vars=list(obs_val.columns), id_vars=['sigma_threshold', 'step'], value_name='R2')\n",
    "\n",
    "# r2_iters_test_results.to_csv(f'{RESULTS_DIR}/{EXP}_r2_iters_test_results.csv')\n",
    "# FIRST TIME - END \n",
    "# r2_iters_test_results = pd.read_csv(f'{RESULTS_DIR}/{EXP}_r2_iters_test_results.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2312e999-64cf-49a5-a346-1eb934034609",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "409180ae-f0b9-408c-8203-50c344e05454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r2_iters_test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02237fc8-9f6c-48c3-afe0-06d3ffe641eb",
   "metadata": {},
   "source": [
    "## Metrics of the Last ICNN Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c43011-35a5-4845-b3a5-e7af9abe28ef",
   "metadata": {},
   "source": [
    "### Inference with Last ICNN Snapshot (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "019d2522-c9c6-4684-9dc4-a2cccd8df430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN \n",
    "# model = model.load_params_from_archive(f'{EXP_DIR[EXP]}/params.zip', 'step9999.eqx')\n",
    "# with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#     obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#     (X_test_imp, X_test_std), _ = eqx.filter_vmap(model.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "\n",
    "# X_test_imp_df = pd.DataFrame(X_test_imp, columns=obs_val.columns)\n",
    "# X_test_std_df = pd.DataFrame(X_test_std, columns=obs_val.columns)\n",
    "\n",
    "# X_test_imp_df.to_csv(f'{RESULTS_DIR}/{EXP}_pred_X_test_imp.csv')\n",
    "# X_test_std_df.to_csv(f'{RESULTS_DIR}/{EXP}_pred_X_test_std.csv')\n",
    "# FIRST TIME - END "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9cdcc2-5454-4d10-a53c-d7a7ca2b719c",
   "metadata": {},
   "source": [
    "### Ablation Study - Optimiser / max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5160d28e-be0f-42b3-b193-12f1ca152929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  experiment_model(EXP, obs_val_test.shape[1])\n",
    "# # model = model.load_params_from_archive(f'{experiment_dir}/params.zip', 'step9999.eqx')\n",
    "\n",
    "# sample_index = jr.choice(jr.PRNGKey(42), a=len(art_mask_test), shape=(500,))\n",
    "# sample_obs_test = jnp.where(art_mask_test[sample_index], obs_val_test[sample_index], 0.)\n",
    "# sample_art_mask_test = art_mask_test[sample_index]\n",
    "# energy0 = eqx.filter_vmap(model.f_energy)(sample_obs_test)\n",
    "\n",
    "# with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#     energy = {}\n",
    "#     total_steps = {}\n",
    "#     for opt in tqdm(('bfgs', 'nonlinear_cg'), leave=False):\n",
    "#         model = eqx.tree_at(lambda m: m.optimiser_name, model, opt)\n",
    "#         for max_steps_exp in tqdm((8, 9, 10, 11), leave=False):\n",
    "#             model = eqx.tree_at(lambda m: m.max_steps, model, 2**max_steps_exp)\n",
    "#             _, stats = eqx.filter_vmap(model.partial_input_optimise)(sample_obs_test, sample_art_mask_test)\n",
    "#             energy[(opt, float('nan'), max_steps_exp)] = stats.energy\n",
    "#             total_steps[(opt, float('nan'), max_steps_exp)] = stats.n_steps\n",
    "            \n",
    "#     for opt in tqdm(('adam', \n",
    "#                      'polyak_sgd', \n",
    "#                      'lamb', \n",
    "#                      'yogi',\n",
    "#                ), leave=False):\n",
    "#         for lr in tqdm((1, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5), leave=False):\n",
    "#             for max_steps_exp in tqdm((8, 9, 10, 11), leave=False):\n",
    "#                 model = eqx.tree_at(lambda m: m.optimiser_name, model, opt)\n",
    "#                 model = eqx.tree_at(lambda m: m.max_steps, model, 2**max_steps_exp)\n",
    "#                 model = eqx.tree_at(lambda m: m.lr, model, lr)\n",
    "\n",
    "#                 _, stats = eqx.filter_vmap(model.partial_input_optimise)(sample_obs_test, sample_art_mask_test)\n",
    "#                 energy[(opt, lr, max_steps_exp)] = stats.energy\n",
    "#                 total_steps[(opt, lr, max_steps_exp)] = stats.n_steps\n",
    "\n",
    "# data = defaultdict(list)\n",
    "\n",
    "# for ((opt, lr, max_steps_exp), energy_vec), total_steps_vec in zip(energy.items(), total_steps.values()):\n",
    "#     data['opt'].extend([opt] * len(energy_vec))\n",
    "#     data['max_steps_exp'].extend([max_steps_exp] * len(energy_vec))\n",
    "#     data['lr'].extend([lr] * len(energy_vec))\n",
    "#     data['E'].extend((energy_vec).tolist())\n",
    "#     data['delta_E'].extend((energy0 - energy_vec).tolist())\n",
    "#     data['n_steps'].extend(total_steps_vec.tolist())\n",
    "\n",
    "# energy_df = pd.DataFrame(data)\n",
    "# energy_df['max_steps'] = 2 ** energy_df['max_steps_exp']\n",
    "\n",
    "# energy_df['early_terminate'] = energy_df['n_steps'] < energy_df['max_steps']\n",
    "\n",
    "# energy_df.to_csv(f\"delta_E_{EXP}_untrained.csv\")\n",
    "# # energy_df.to_csv(f\"delta_E_{EXP}_trained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9af8479-ccab-4e1f-a9ac-e0c1cf16f792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXP = 'ICNN_NLN'\n",
    "\n",
    "# energy_trained_df = pd.read_csv(f\"delta_E_{EXP}_trained.csv\")\n",
    "# energy_untrained_df = pd.read_csv(f'delta_E_{EXP}_untrained.csv')\n",
    "# energy_trained_df['sample_index'] = list(range(500)) * (len(energy_trained_df) // 500)\n",
    "# energy_untrained_df['sample_index'] = list(range(500)) * (len(energy_untrained_df) // 500)\n",
    "\n",
    "# energy_trained_df['early_terminate'] = energy_trained_df['n_steps'] < energy_trained_df['max_steps']\n",
    "# energy_untrained_df['early_terminate'] = energy_untrained_df['n_steps'] < energy_untrained_df['max_steps']\n",
    "\n",
    "# energy_trained_df['log_delta_E'] = np.log(energy_trained_df['delta_E'])\n",
    "# energy_untrained_df['log_delta_E'] = np.log(energy_untrained_df['delta_E'])\n",
    "\n",
    "\n",
    "# energy_trained_df['max_delta_E'] = energy_trained_df.sample_index.map(energy_trained_df.groupby('sample_index')['delta_E'].max())\n",
    "# energy_untrained_df['max_delta_E'] = energy_untrained_df.sample_index.map(energy_untrained_df.groupby('sample_index')['delta_E'].max())\n",
    "\n",
    "# energy_trained_df['delta_E_ratio'] = energy_trained_df['delta_E'] / energy_trained_df['max_delta_E']\n",
    "# energy_untrained_df['delta_E_ratio'] = energy_untrained_df['delta_E'] / energy_untrained_df['max_delta_E']\n",
    "\n",
    "# energy_trained_df['log_delta_E_ratio'] = np.log(energy_trained_df['delta_E_ratio'])\n",
    "# energy_untrained_df['log_delta_E_ratio'] = np.log(energy_untrained_df['delta_E_ratio'])\n",
    "\n",
    "\n",
    "# energy_trained_df['min_E'] = energy_trained_df.sample_index.map(energy_trained_df.groupby('sample_index')['E'].min())\n",
    "# energy_untrained_df['min_E'] = energy_untrained_df.sample_index.map(energy_untrained_df.groupby('sample_index')['E'].min())\n",
    "\n",
    "# energy_trained_df['E_l1'] = energy_trained_df['E'] - energy_trained_df['min_E']\n",
    "# energy_trained_df['E_l2'] = (energy_trained_df['E'] - energy_trained_df['min_E'])**2\n",
    "\n",
    "\n",
    "# energy_untrained_df['E_l1'] = energy_untrained_df['E'] - energy_untrained_df['min_E']\n",
    "# energy_untrained_df['E_l2'] = (energy_untrained_df['E'] - energy_untrained_df['min_E'])**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a380f6-8bde-4ddc-9236-acf50c623a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_untrained_df.groupby(['opt', 'max_steps', 'lr'])[['early_terminate']].mean().transpose().to_csv(f\"early_terminate_{EXP}_untrained.csv\")\n",
    "# energy_trained_df.groupby(['opt', 'max_steps', 'lr'])[['early_terminate']].mean().transpose().to_csv(f\"early_terminate_{EXP}_trained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3fd0608a-e4e9-4086-aba3-82cc391a4347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# energy_untrained_df.groupby(['opt', 'max_steps', 'lr'])[['log_delta_E_ratio']].mean().transpose().to_csv(f\"opt_max_steps_{EXP}_untrained.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d589a85-2230-4557-9743-062899ece133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bokeh.io import curdoc\n",
    "# from bokeh.layouts import column, gridplot\n",
    "# from bokeh.core.enums import MarkerType\n",
    "# from bokeh.models import Div, Legend\n",
    "# from bokeh.palettes import Spectral\n",
    "# from bokeh.plotting import figure, show\n",
    "# from bokeh.io import output_notebook, export_svgs, export_png\n",
    "# output_notebook()\n",
    "\n",
    "# def plot_opt(dataframe, opt_name):\n",
    "#     opt_df = dataframe[energy_trained_df.opt == opt_name]\n",
    "#     p = figure(width=400, height=400, \n",
    "#                toolbar_location=None,\n",
    "#                output_backend='svg',\n",
    "#               title=opt_name)\n",
    "#     palette = Spectral[dataframe.lr.nunique(dropna=False)]\n",
    "#     dash_style = [\"solid\", \"dashed\", \"dotted\", \"dotdash\", \"dashdot\"]\n",
    "#     max_steps = dataframe.max_steps_exp.unique()\n",
    "\n",
    "#     if opt_df.lr.nunique(dropna=False) > 1:\n",
    "#         for i, (lr, opt_lr_df) in enumerate(opt_df.groupby(['lr'])):\n",
    "#             log_delta_E_ratio_avg = opt_lr_df.groupby(['max_steps_exp'])['delta_E_ratio'].mean()\n",
    "#             p.line(max_steps, log_delta_E_ratio_avg, line_width=4,\n",
    "#                    legend_label=f\"learning_rate={lr[0]:5f}\".rstrip('0'), \n",
    "#                    line_dash=dash_style[i],\n",
    "#                    line_color=palette[i+1]\n",
    "#                   )\n",
    "#             p.scatter(max_steps, log_delta_E_ratio_avg, \n",
    "#                       marker=list(MarkerType)[i+1], size=14,\n",
    "#                       line_color=\"navy\", fill_color=palette[i+1], \n",
    "#                   )\n",
    "#         p.legend.items = list(reversed(p.legend.items))\n",
    "#         p.legend.visible=False \n",
    "#         p.legend.location = 'right'\n",
    "#     else:\n",
    "#         log_delta_E_ratio_avg = opt_df.groupby(['max_steps_exp'])['delta_E_ratio'].mean()\n",
    "#         p.line(max_steps, log_delta_E_ratio_avg, line_width=4,\n",
    "#                line_dash=dash_style[0],\n",
    "#                line_color=palette[0])\n",
    "#         p.scatter(max_steps, log_delta_E_ratio_avg, \n",
    "#                       marker=list(MarkerType)[1], size=14,\n",
    "#                       line_color=\"navy\", fill_color=palette[0], \n",
    "#                   )\n",
    "            \n",
    "        \n",
    "#     p.xaxis.ticker = max_steps\n",
    "#     p.xaxis.major_label_overrides = {e: rf\"\\[2^{{{e}}}\\]\" \n",
    "#                                      for e in max_steps} \n",
    "#     p.y_range.start = 0#-12\n",
    "#     p.y_range.end = 1.1#0.5\n",
    "    \n",
    "#     p.yaxis.axis_label = r\"$$ \\Delta E / \\Delta E_\\text{max} $$\"\n",
    "#     p.xaxis.axis_label = \"max steps\"\n",
    "\n",
    "#     p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "#     p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "    \n",
    "#     p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "#     p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "#     return p\n",
    "\n",
    "# def plot_opts(dataframe):\n",
    "#     ncg_p = plot_opt(dataframe, 'nonlinear_cg')\n",
    "#     bfgs_p = plot_opt(dataframe, 'bfgs')\n",
    "#     lamp_p = plot_opt(dataframe, 'lamb')\n",
    "#     adam_p = plot_opt(dataframe, 'adam')\n",
    "#     yogi_p = plot_opt(dataframe, 'yogi')\n",
    "#     polyak_p = plot_opt(dataframe, 'polyak_sgd')\n",
    "\n",
    "#     # bfgs_p.add_layout(polyak_p.legend.clone(), 'center')\n",
    "#     polyak_p.legend.visible = True\n",
    "    \n",
    "#     curdoc().theme = 'contrast'\n",
    "    \n",
    "#     grid = gridplot([[ncg_p, bfgs_p], [lamp_p, adam_p], [yogi_p, polyak_p]], \n",
    "#                     toolbar_location=None)\n",
    "#     return grid\n",
    "    \n",
    "# grid = plot_opts(energy_trained_df)\n",
    "# show(grid)\n",
    "# export_png(grid, filename=f\"opt_max_steps_{EXP}_trained.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77caa1e8-171c-4a89-872f-2e84ecb2929e",
   "metadata": {},
   "source": [
    "### Visualise 2D Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c7482aaf-a829-44ea-a7fe-4d87686cb4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "282acae9-e7b8-485d-b7d5-ea271907893c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'ICNN_NMSE'\n",
    "\n",
    "model =  experiment_model(EXP, obs_val_test.shape[1])\n",
    "\n",
    "model = model.load_params_from_archive(f'{EXPERIMENTS_DIR}/{EXP_DIR[EXP]}/params.zip', 'step9999.eqx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "cdfc6b40-e8fd-4dbd-9ae5-6bbcdc9a7b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = jr.choice(jr.PRNGKey(42), a=len(art_mask_test), shape=(500,))\n",
    "sample_obs_test = jnp.where(art_mask_test[sample_index], obs_val_test[sample_index], 0.)\n",
    "sample_art_mask_test = art_mask_test[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "98716c80-25dd-43dd-b886-31edee6aebc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_full_sample_index = np.argsort(obs_mask_test.sum(axis=1))[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "d07414ad-41c5-431c-9550-17e8a75c74bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.array(obs_mask.columns)[np.nonzero(obs_mask_test[i])].tolist() for i in semi_full_sample_index]\n",
    "sample_obs = obs_val_test[semi_full_sample_index[0]]\n",
    "sample_mask = obs_mask_test[semi_full_sample_index[0]]\n",
    "x_imputed, _ = model.partial_input_optimise(sample_obs,  sample_mask)\n",
    "\n",
    "# (x_imputed, std_imputed), _ = model.prob_partial_input_optimise(sample_obs,  sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "fef5e694-6821-4e27-9ed7-6c3fcc2d6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mask.columns[np.nonzero(sample_mask)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "3f1d5ff0-a7a2-432b-999d-f91fbe25700d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_i_name, feature_j_name = 'blood_chemistry.creatinine', 'blood_chemistry.bun'\n",
    "feature_i_name, feature_j_name = 'blood_diff.lymphocytes', 'blood_chemistry.calcium'\n",
    "\n",
    "\n",
    "# feature_i_name, feature_j_name =  'blood_gas.temperature', 'inflammation.crp'\t#-0.705869433419654\n",
    "# feature_i_name, feature_j_name =  'renal_out.uo_rt_12hr',  'renal_out.uo_rt_24hr'\n",
    "\n",
    "feature_i, feature_j = feature2index[feature_i_name], feature2index[feature_j_name]\n",
    "feature_i, feature_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "ff33a709-7636-4de1-b288-77043ff1f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mask.mean().iloc[[feature_i, feature_j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "751eef80-c03a-47eb-a6f5-fc8107983e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_i_grid = jnp.linspace(obs_val.iloc[:, feature_i].min(), obs_val.iloc[:, feature_i].max(), 50)\n",
    "feature_j_grid = jnp.linspace(obs_val.iloc[:, feature_j].min(), obs_val.iloc[:, feature_j].max(), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "f1c39f87-d24a-4d8b-942c-dd5df3bd4416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def energy_2d(model, fixed_point, dim_i, dim_j, grid_i, grid_j):\n",
    "    # mask2d = jnp.ones_like(fixed_point).at[[dim_i, dim_j]].set(0)\n",
    "    energy2d = np.zeros((len(grid_i), len(grid_j)))\n",
    "    for i, row_i in enumerate(grid_i):\n",
    "        for j, row_j in enumerate(grid_j):\n",
    "            point = fixed_point.at[dim_i].set(row_i).at[dim_j].set(row_j)\n",
    "            energy2d[i, j] = model.f_energy(point)\n",
    "    return energy2d.T\n",
    "\n",
    "def imp_i_given_j(model, dim_i, dim_j, grid_j):\n",
    "    mask2d = jnp.zeros((model.observables_size,)).at[dim_j].set(1)\n",
    "    fixed_point = jnp.zeros((model.observables_size,))\n",
    "    \n",
    "    x_i = np.zeros((len(grid_j)))\n",
    "    energy = np.zeros((len(grid_j)))\n",
    "    for j, row_j in enumerate(grid_j):\n",
    "        point = fixed_point.at[dim_j].set(row_j)\n",
    "        x_imp, stat = model.partial_input_optimise(point, mask2d)\n",
    "        x_i[j] = x_imp[dim_i]\n",
    "        energy[j] = stat.energy\n",
    "\n",
    "    return x_i, energy\n",
    "\n",
    "def imp_i_given_j_fixed_point(model, fixed_point, dim_i, dim_j, grid_j):\n",
    "    mask2d = jnp.ones((model.observables_size,)).at[dim_i].set(0)    \n",
    "    x_i = np.zeros((len(grid_j)))\n",
    "    for j, row_j in enumerate(grid_j):\n",
    "        point = fixed_point.at[dim_j].set(row_j)\n",
    "        x_imp, _ = model.partial_input_optimise(point, mask2d)\n",
    "        x_i[j] = x_imp[dim_i]\n",
    "    return x_i\n",
    "\n",
    "def prob_imp_i_given_j(model, dim_i, dim_j, grid_j):\n",
    "    mask2d = jnp.zeros((model.observables_size // 2,)).at[dim_j].set(1)\n",
    "    fixed_point = jnp.zeros((model.observables_size // 2,))\n",
    "    \n",
    "    x_i = np.zeros((len(grid_j)))\n",
    "    energy = np.zeros((len(grid_j)))\n",
    "    for j, row_j in enumerate(grid_j):\n",
    "        point = fixed_point.at[dim_j].set(row_j)\n",
    "        x_imp, stat = model.partial_input_optimise(point, mask2d)\n",
    "        x_i[j] = x_imp[dim_i]\n",
    "        energy[j] = stat.energy\n",
    "\n",
    "    return x_i, energy\n",
    "\n",
    "def prob_imp_i_given_j_fixed_point(model, fixed_point, dim_i, dim_j, grid_j):\n",
    "    mask2d = jnp.ones((model.observables_size // 2,)).at[dim_i].set(0)    \n",
    "    x_i = np.zeros((len(grid_j)))\n",
    "    for j, row_j in enumerate(grid_j):\n",
    "        point = fixed_point.at[dim_j].set(row_j)\n",
    "        x_imp, _ = model.partial_input_optimise(point, mask2d)\n",
    "        x_i[j] = x_imp[dim_i]\n",
    "    return x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e4900170-3c11-4854-ae00-fec74e0bacc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "E2d = energy_2d(model, x_imputed, feature_i, feature_j, feature_i_grid, feature_j_grid)\n",
    "xi_given_xj, Ei_given_xj = imp_i_given_j(model, feature_i, feature_j, feature_j_grid)\n",
    "xj_given_xi, Ej_given_xi = imp_i_given_j(model, feature_j, feature_i, feature_i_grid)\n",
    "\n",
    "xi_given_xj_F = imp_i_given_j_fixed_point(model, x_imputed, feature_i, feature_j, feature_j_grid)\n",
    "xj_given_xi_F = imp_i_given_j_fixed_point(model, x_imputed, feature_j, feature_i, feature_i_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "878cc612-b83d-4a2e-8fe4-8792175bdd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xi_given_xj, Ei_given_xj = prob_imp_i_given_j(model, feature_i, feature_j, feature_j_grid)\n",
    "# xj_given_xi, Ej_given_xi = prob_imp_i_given_j(model, feature_j, feature_i, feature_i_grid)\n",
    "\n",
    "# xi_given_xj_F = prob_imp_i_given_j_fixed_point(model, x_imputed, feature_i, feature_j, feature_j_grid)\n",
    "# xj_given_xi_F = prob_imp_i_given_j_fixed_point(model, x_imputed, feature_j, feature_i, feature_i_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "063a2bb5-c502-443c-8296-2e83979cce91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surface plot for 2d objective function\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import cbook, cm\n",
    "\n",
    "# sample input range uniformly at 0.1 increments\n",
    "z = E2d\n",
    "# create a mesh from the axis\n",
    "x, y = np.meshgrid(feature_i_grid, feature_j_grid)\n",
    "\n",
    "# create a surface plot with the jet color scheme\n",
    "figure = plt.figure()\n",
    "axis = figure.add_subplot(projection='3d', computed_zorder=False)\n",
    "\n",
    "ls = LightSource(azdeg=0, altdeg=45)\n",
    "# To use a custom hillshading mode, override the built-in shading and pass\n",
    "# in the rgb colors of the shaded surface calculated from \"shade\".\n",
    "rgb = ls.shade(z, cmap=cm.YlOrBr, vert_exag=0.1, \n",
    "               blend_mode='soft')\n",
    "axis.plot_surface(x, y, z,  #lw=0.5, rstride=50, cstride=50, \n",
    "                  # alpha=0.2, \n",
    "                  edgecolor='none',\n",
    "                  facecolors=rgb,\n",
    "                  antialiased=False,\n",
    "                 zorder=-1000)\n",
    "# axis.contourf(x, y, results, zdir='z', offset=0, cmap='coolwarm')\n",
    "axis.set(xlabel=variable_map[feature_i_name], \n",
    "         ylabel=variable_map[feature_j_name], \n",
    "         zlabel=r'$Energy$', \n",
    "         xticklabels=[], yticklabels=[],\n",
    "         # zticklabels=[]\n",
    "        )\n",
    "axis.xaxis.label.set_size(12)\n",
    "axis.yaxis.label.set_size(12)\n",
    "axis.zaxis.label.set_size(12)\n",
    "\n",
    "axis.grid(False)\n",
    "axis.view_init(30, -45)\n",
    "axis.set_box_aspect(aspect=None, zoom=0.8)\n",
    "\n",
    "# show the plot\n",
    "plt.savefig(f'{EXP}_{feature_i_name}_{feature_j_name}_3d_surface_sample0.pdf', bbox_inches='tight');\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "1fdf80f7-8036-4d8d-aa56-bed06cdda9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from bokeh.palettes import Sunset8\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "# Data to contour is the sum of two Gaussian functions.\n",
    "x, y = np.meshgrid(feature_i_grid, feature_j_grid)\n",
    "z = E2d\n",
    "\n",
    "p = figure(width=450, height=400, x_range=(feature_i_grid.min().item(), feature_i_grid.max().item()), \n",
    "           y_range=(feature_j_grid.min().item(), feature_j_grid.max().item()),\n",
    "          output_backend=\"svg\")\n",
    "\n",
    "levels = np.linspace(E2d.min(), E2d.max(), 10)\n",
    "contour_renderer = p.contour(x, y, z, levels, fill_color=Sunset8, line_color=\"black\")\n",
    "\n",
    "p.line(xi_given_xj_F, feature_j_grid, line_width=4, line_color=\"navy\",\n",
    "       legend_label=\"x(y)\")\n",
    "p.line(feature_i_grid, xj_given_xi_F, line_width=4, line_color=\"red\",\n",
    "       legend_label=\"y(x)\")\n",
    "\n",
    "p.yaxis.axis_label = f\"y: {variable_map[feature_j_name]}\"\n",
    "p.xaxis.axis_label = f\"x: {variable_map[feature_i_name]}\"\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "p.xaxis.major_label_text_font_size = \"12pt\"\n",
    "p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "colorbar = contour_renderer.construct_color_bar()\n",
    "p.add_layout(colorbar, \"right\")\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "564f5ff5-0f0f-4496-974b-023fa41d9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from bokeh.models import (LinearAxis, Range1d)\n",
    "from bokeh.palettes import Sunset6\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "x = feature_i_grid\n",
    "y = xj_given_xi\n",
    "y2 = Ej_given_xi\n",
    "\n",
    "blue, red = Sunset6[2], Sunset6[5]\n",
    "\n",
    "p = figure(x_range=(feature_i_grid[0].item()-0.1, feature_i_grid[-1].item()), \n",
    "           y_range=(xj_given_xi.min().item(), xj_given_xi.max().item()),\n",
    "          output_backend=\"svg\")\n",
    "\n",
    "\n",
    "p.line(x, y, line_width=4, line_color=\"green\")\n",
    "\n",
    "\n",
    "p.xaxis.axis_label = variable_map[feature_i_name]\n",
    "p.yaxis.axis_label = variable_map[feature_j_name]\n",
    "p.yaxis.axis_label_text_color = \"green\"\n",
    "\n",
    "\n",
    "p.extra_x_ranges['foo'] = Range1d(feature_i_grid[0].item() -0.1, feature_i_grid[-1].item())\n",
    "p.extra_y_ranges['foo'] = Range1d(Ej_given_xi.min().item(), Ej_given_xi.max().item()+0.01)\n",
    "\n",
    "\n",
    "\n",
    "p.line(x, y2, \n",
    "       line_width=4, line_color=\"red\",\n",
    "       line_dash=\"dashed\",\n",
    "        x_range_name=\"foo\",\n",
    "        y_range_name=\"foo\",\n",
    ")\n",
    "\n",
    "ax2 = LinearAxis(\n",
    "    axis_label=\"Energy\",\n",
    "    x_range_name=\"foo\",\n",
    "    y_range_name=\"foo\",\n",
    "    \n",
    ")\n",
    "ax2.axis_label_text_color = \"red\"\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "ax2.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "p.xaxis.major_label_text_font_size = \"12pt\"\n",
    "p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "ax2.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "\n",
    "p.add_layout(ax2, 'right')\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0156ca-10be-473d-b45a-b34c0de0225f",
   "metadata": {},
   "source": [
    "### Load ICNN Inference from Disk (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c537ca0-2502-4e12-81bd-0c9a3d865fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_n300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11619b1-f825-47c7-bc91-1387fc37d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_X_test_imp_df = {}\n",
    "prob_models_X_test_std_df = {}\n",
    "prob_models_X_var_stats_df = []\n",
    "all_models_X_test_se = []\n",
    "all_models_features_stats_df = []\n",
    "all_models_stats_df = []\n",
    "PERCENTILES = (95, 90, 80, 70, 60, 50, 25, 10)\n",
    "\n",
    "for model_name in list(EXP_DIR.keys()) + list(sklearn_imputers.keys()):\n",
    "    x_file = f'{RESULTS_DIR}/{model_name}_pred_X_test_imp.csv'\n",
    "    s_file = f'{RESULTS_DIR}/{model_name}_pred_X_test_std.csv'\n",
    "    if os.path.isfile(x_file):\n",
    "        X_test_imp_ = pd.read_csv(x_file, index_col=[0])\n",
    "        all_models_X_test_imp_df[model_name] = X_test_imp_\n",
    "\n",
    "        # Squared-Errors (per instance)\n",
    "        X_test_se_ = (X_test_imp_ - np.array(obs_val_test))**2\n",
    "        X_test_se_ = X_test_se_.where(prediction_mask.astype(bool), other=np.nan)\n",
    "        X_test_se_ = pd.melt(X_test_se_, value_vars=list(obs_val.columns), value_name='SE')\n",
    "        X_test_se_ = X_test_se_[X_test_se_.SE.notnull()]\n",
    "        X_test_se_['Imputer'] = model_name\n",
    "        all_models_X_test_se.append(X_test_se_)\n",
    "\n",
    "\n",
    "    if os.path.isfile(s_file):\n",
    "        X_test_std_ = pd.read_csv(s_file, index_col=[0])\n",
    "        prob_models_X_test_std_df[model_name] = X_test_std_\n",
    "        \n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), X_test_std_ ** 2, np.nan)\n",
    "        SE_ = (all_models_X_test_imp_df[model_name] - np.array(obs_val_test)) ** 2\n",
    "        SE_ = np.where(prediction_mask.astype(bool), SE_, np.nan)\n",
    "        se_data_ = defaultdict(list)\n",
    "        for i in range(SE_.shape[1]):\n",
    "            se_data_['SE'].extend(np.array(SE_[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "            se_data_[r'$\\hat{\\sigma}^2$'].extend(np.array(X_test_var_[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "            se_data_['Feature'].extend([obs_val.columns[i]] * int(prediction_mask[:, i].sum()))\n",
    "        se_df_ = pd.DataFrame(se_data_)\n",
    "        se_df_['Imputer'] = model_name\n",
    "        \n",
    "        prob_models_X_var_stats_df.append(se_df_)\n",
    "\n",
    "    if model_name not in all_models_X_test_imp_df:\n",
    "        continue\n",
    "\n",
    "    # R2/MSE (per feature)\n",
    "    X_test_imp_ = jnp.array(all_models_X_test_imp_df[model_name])\n",
    "    features_r2_ = eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, X_test_imp_.T, prediction_mask.T)\n",
    "    se_ = (np.array(all_models_X_test_imp_df[model_name]) - np.array(obs_val_test)) ** 2\n",
    "    mse_ = np.nanmean(se_, axis=0, where=prediction_mask.astype(bool))\n",
    "    features_stats_df_ = pd.DataFrame({r'$R^2$': np.array(features_r2_), \n",
    "                                       'MSE': mse_,\n",
    "                                       'Feature': all_models_X_test_imp_df[model_name].columns,\n",
    "                                       'Imputer': [model_name] * len(mse_)})\n",
    "\n",
    "    # r_spearman(SE, sigma2) (per feature)\n",
    "    if model_name in prob_models_X_test_std_df:\n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), prob_models_X_test_std_df[model_name] ** 2, np.nan)\n",
    "        features_stats_df_[r'$r_\\text{Spearman}(SE, \\hat{\\sigma}^2)$'] = [spearmanr(se_i[mi], sigma2_i[mi]).statistic\n",
    "                                                 for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T)]\n",
    "        features_stats_df_[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(se_i[mi], sigma2_i[mi]).statistic if mi.sum() > 2 else float('nan')\n",
    "                                                 for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T) ]\n",
    "\n",
    "        features_stats_df_[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(np.log(se_i[mi]), np.log(sigma2_i[mi])).statistic if mi.sum() > 2 else float('nan')\n",
    "                                         for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T) ]\n",
    "\n",
    "        # After Transpose, shape: (N_percentiles, n_features)\n",
    "        features_percentiles = np.vstack([np.percentile(sigma2_i[mi], PERCENTILES)  for (sigma2_i, mi) in zip(X_test_var_.T, prediction_mask.astype(bool).T)]).T\n",
    "\n",
    "        for percent, percentile in zip(PERCENTILES, features_percentiles):\n",
    "            prediction_mask_p = np.vstack([mi * (sigma2_i <= p_i) for \n",
    "                                           (p_i, sigma2_i, mi) in zip(percentile, X_test_var_.T, prediction_mask.astype(bool).T)]).T\n",
    "            features_stats_df_[rf'$R^2@P{percent}$'] = np.array(eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, X_test_imp_.T, prediction_mask_p.T)).squeeze()\n",
    "            features_stats_df_[f'MSE@P{percent}'] = np.nanmean(se_, axis=0, where=prediction_mask_p).squeeze()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    all_models_features_stats_df.append(features_stats_df_)\n",
    "\n",
    "    # R2/MSE (per model)\n",
    "    features_stats_300_df = features_stats_df_[features_stats_df_.Feature.isin(vars_n300)]\n",
    "    weighted_avg_R2 = np.average(features_stats_300_df[r'$R^2$'], \n",
    "                                 weights=features_stats_300_df['Feature'].map(n_test_censored))\n",
    "    \n",
    "    model_stats_df_ = pd.DataFrame({'Imputer': [model_name],\n",
    "                                    'MSE': [np.nanmean(se_, where=prediction_mask.astype(bool))],\n",
    "                                    r'$R^2$': [ProbICNNImputerTrainer.r_squared(obs_val_test, X_test_imp_, prediction_mask).item()],\n",
    "                                    r'MICRO-AVG($R^2$)': [ProbICNNImputerTrainer.r_squared_micro_average(obs_val_test, X_test_imp_, prediction_mask).item()],\n",
    "                                    r'MACRO-AVG($R^2$)*': [features_stats_300_df[r'$R^2$'].mean()]})\n",
    "\n",
    "    # corr(SE, sigma2) (per model)\n",
    "    if model_name in prob_models_X_test_std_df:\n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), prob_models_X_test_std_df[model_name] ** 2, np.nan).flatten()\n",
    "        m_ = prediction_mask.astype(bool).flatten()\n",
    "        model_stats_df_[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(se_.flatten()[m_], X_test_var_[m_]).statistic]\n",
    "        model_stats_df_[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(np.log(se_.flatten()[m_]), np.log(X_test_var_[m_])).statistic]\n",
    "\n",
    "        model_stats_df_[r'$r_\\text{Spearman}(SE, \\hat{\\sigma}^2)$'] = [spearmanr(se_.flatten()[m_], X_test_var_[m_]).statistic]\n",
    "    all_models_stats_df.append(model_stats_df_)\n",
    "    \n",
    "all_models_X_test_se = pd.concat(all_models_X_test_se)\n",
    "prob_models_X_var_stats_df = pd.concat(prob_models_X_var_stats_df)\n",
    "all_models_features_stats_df = pd.concat(all_models_features_stats_df)\n",
    "all_models_stats_df = pd.concat(all_models_stats_df)\n",
    "\n",
    "prob_models_X_var_stats_df['LN'] = prob_models_X_var_stats_df['SE'] / prob_models_X_var_stats_df[r'$\\hat{\\sigma}^2$'] + np.log(prob_models_X_var_stats_df[r'$\\hat{\\sigma}^2$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "e62f4576-849b-414a-af2b-da3ae5a35b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP = 'ICNN_NLN'\n",
    "\n",
    "spearman_corr = all_models_X_test_imp_df[EXP].corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "04b584c9-9b49-4469-bf7d-b035d6e5a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_corr = []\n",
    "for i, f1 in enumerate(spearman_corr.columns):\n",
    "    for f2 in spearman_corr.columns[i+1:]:\n",
    "        c = spearman_corr.loc[f1, f2]\n",
    "        if abs(c) > 0.6:\n",
    "            important_corr.append((f1, f2, c))\n",
    "important_corr_df = pd.DataFrame(important_corr, columns=['Feature_A', 'Feature_B', 'Spearman'])\n",
    "important_corr_df.to_csv(f'{EXP}_spearman_corr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e3d043a7-5612-4ba9-ac40-5825d3a071a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_models_features_stats_df\n",
    "features_LN = prob_models_X_var_stats_df.groupby(['Imputer', 'Feature'])['LN'].mean()\n",
    "all_models_features_stats_df = all_models_features_stats_df.set_index(['Imputer', 'Feature'])\n",
    "all_models_features_stats_df.loc[features_LN.index, 'LN'] = features_LN\n",
    "all_models_features_stats_df = all_models_features_stats_df.reset_index()\n",
    "all_models_features_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "802a9099-ee2a-44e4-94cb-1151f518c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_LN = prob_models_X_var_stats_df.groupby(['Imputer'])['LN'].mean()\n",
    "all_models_stats_df = all_models_stats_df.set_index('Imputer')\n",
    "all_models_stats_df.loc[models_LN.index, 'LN'] = models_LN\n",
    "all_models_stats_df = all_models_stats_df.reset_index()\n",
    "all_models_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9df03394-8acb-4846-8c41-f3d6f922de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_models_X_var_stats_df.groupby(['Imputer'])['LN'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2c74ebb-16b9-444f-a336-4e05e0a7c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_features_stats_df.Imputer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02b08d3c-9a9b-4de5-b8ae-36edf08eb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_abundance = obs_mask.mean(axis=0)\n",
    "for name, model_df in all_models_features_stats_df.groupby('Imputer'):\n",
    "    df = model_df[model_df.Feature.isin(vars_n300)]\n",
    "    stat = spearmanr(df[r'$R^2$'], df.Feature.map(p_abundance)).statistic\n",
    "    loc = all_models_stats_df.Imputer == name\n",
    "    all_models_stats_df.loc[loc, r'$r_\\text{Spearman}(R^2, \\text{abundance})$'] = stat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e6bc065d-9271-4585-880c-15528fa9c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "471ab510-ca1d-4d6b-833e-67d1b5fd2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_features_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fa41071-d0ef-456d-bd4a-96553488de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_classes = [r'$r > 0.3$', r'$r \\in [0.1, 0.3]$', r'$r \\in [-0.1, 0.1]$', r'$r \\leq -0.1$']\n",
    "R_classes = [r'$R^2 > 0.25$', r'$R^2 \\in (0.1, 0.25]$', r'$R^2 \\in [-0.1, 0.1]$', r'$R^2 \\in (-1, -0.1]$',  r'$R^2 \\in (-9, -1]$', r'$R^2 < -9$']\n",
    "def classify_r(r):\n",
    "    if r > 0.3:\n",
    "        return r_classes[0]\n",
    "    elif r > 0.1:\n",
    "        return r_classes[1]\n",
    "    elif r >= -0.1:\n",
    "        return r_classes[2]\n",
    "    elif r < -0.1:\n",
    "        return r_classes[3]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def classify_R(R):\n",
    "    if R > 0.25:\n",
    "        return R_classes[0]\n",
    "    elif R > 0.1:\n",
    "        return R_classes[1]\n",
    "    elif R >= -0.1:\n",
    "        return R_classes[2]\n",
    "    elif R >= -1:\n",
    "        return R_classes[3] \n",
    "    elif R >= -9:\n",
    "        return R_classes[4]\n",
    "    elif R < -9:\n",
    "        return R_classes[5]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'] = all_models_features_stats_df[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'].map(classify_r)\n",
    "all_models_features_stats_df[r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin'] = all_models_features_stats_df[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'].map(classify_r)\n",
    "\n",
    "all_models_features_stats_df[r'$R^2$ bin'] = all_models_features_stats_df[r'$R^2$'].map(classify_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7650b13f-ca3d-45a5-ac67-36c6f4380659",
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in PERCENTILES:\n",
    "    all_models_features_stats_df[rf'$R^2@P{p}$ bin'] = all_models_features_stats_df[rf'$R^2@P{p}$'].map(classify_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07c93709-d683-4986-940d-66199b086a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_features_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "eaa604c5-4e85-409d-8a2d-f312aa5d6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vars_n300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "20204760-6eb4-4612-9a56-8462105c1be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_models_features_stats_df = all_models_features_stats_df[all_models_features_stats_df[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'].notnull()]\n",
    "prob_models_features_stats_df = prob_models_features_stats_df[prob_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "\n",
    "prob_models_features_stats_df['Imputer'] = prob_models_features_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "\n",
    "r_bins = prob_models_features_stats_df.groupby(['Imputer', r'$r(SE, \\hat{\\sigma}^2)$ bin'])['Feature'].count().reset_index()\n",
    "r_bins.columns = ['Imputer', r'$r(SE, \\hat{\\sigma}^2)$ bin', 'Count']\n",
    "r_bins = r_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$r(SE, \\hat{\\sigma}^2)$ bin')\n",
    "\n",
    "\n",
    "ax = r_bins.plot(y=r_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 2., fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/prob_icnn_r_bins.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4ea4c32b-7c97-4218-96f7-8f384c66bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ablation0 = all_models_stats_df.copy()\n",
    "\n",
    "table_ablation0['Imputer'] = all_models_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "ablation_models = [m for m in table_ablation0.Imputer.unique() if m == m and  m.startswith('P-ICNN')]\n",
    "\n",
    "table_ablation0 = table_ablation0.set_index('Imputer').loc[ablation_models,  ['MSE', r'MICRO-AVG($R^2$)',  r'MACRO-AVG($R^2$)*', 'LN', r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] ].transpose()\n",
    "table_ablation0.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table_ablation0.columns))\n",
    "table_ablation0.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table_ablation0.columns))\n",
    "table_ablation0.columns.name = 'Imputer'\n",
    "# table_ablation0 = table_ablation0.sort_values('MSE', ascending=False, axis=1)\n",
    "table_ablation0 = table_ablation0.transpose()\n",
    "table_ablation0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ee899428-2bc1-4c90-8c5f-4b20ce16ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_stl_ablation0 = (table_ablation0.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'$R^2$'], :])\n",
    "              .background_gradient(cmap='RdYlGn_r', axis=1,  low=0.05, high=0.110,  vmin=0.05, vmax=0.110, subset= pd.IndexSlice[:, ['MSE']])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table_stl_ablation0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "53af7d18-5d7f-4f64-b65f-6cc7c9d248e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ltx_ablation0 = (table_stl_ablation0.to_latex(caption=r\"Ablation study on the effect of the probabilistic loss function choice on the performance of \"\n",
    "                                                    r\"\\texttt{P-ICNN} models. The estimations are made on the validation split.\"\n",
    "                                                    r\"For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in the test split are excluded, \"\n",
    "                                                    r\"of which some have $-\\infty$ values. \"\n",
    "                                                    r\"LN is the lognormal loss (not necessarily used in training).\"\n",
    "                                                    r\" $r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$ is the correlation between the prediction \\gls*{se} and the predicted variance (the higher the better).\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table_ltx_ablation0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "114658a7-01ec-4492-b283-b01916374643",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ablation1 = all_models_stats_df.copy()\n",
    "\n",
    "table_ablation1['Imputer'] = all_models_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "ablation_models = [m for m in table_ablation1.Imputer.unique() if m == m and  m.startswith('S-ICNN')]\n",
    "\n",
    "table_ablation1 = table_ablation1.set_index('Imputer').loc[ablation_models,  ['MSE', r'MICRO-AVG($R^2$)', r'MACRO-AVG($R^2$)*'] ].transpose()\n",
    "table_ablation1.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table_ablation1.columns))\n",
    "table_ablation1.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table_ablation1.columns))\n",
    "table_ablation1.columns.name = 'Imputer'\n",
    "table_ablation1 = table_ablation1.sort_values('MSE', ascending=False, axis=1)\n",
    "table_ablation1 = table_ablation1.transpose()\n",
    "# table_ablation1.columns = table_ablation1.columns.droplevel(0)\n",
    "table_ablation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b079eec-c4b7-4551-8e22-47ba88f67b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_stl_ablation1 = (table_ablation1.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'$R^2$'], :])\n",
    "              .background_gradient(cmap='RdYlGn_r', axis=0,  low=0.05, high=0.110,  vmin=0.05, vmax=0.110, subset= pd.IndexSlice[:, ['MSE']])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table_stl_ablation1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d1a455b6-4c7a-4b52-9ec0-1ac74ba2b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_ltx_ablation1 = (table_stl_ablation1.to_latex(caption=r\"Ablation study on the effect of the loss function choice on the performance of \\texttt{S-ICNN} models. \"\n",
    "                                                    r\"First row: \\gls*{mse} loss across all features on the test split. Second and third rows list the micro and macro average of $R^2$ \"\n",
    "                                                    r\"(higher is better), respectively. For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in the test split are excluded, \"\n",
    "                                                    r\"of which some have $-\\infty$ values.\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table_ltx_ablation1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "cb1e4321-ad39-4ec1-bef3-2f98b835fa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_ICNN = ('ICNN_NMSE', 'ICNN_MSE')\n",
    "P_ICNN = ('ICNN_NKLR', 'ICNN_NLN')\n",
    "# P_ICNN_RENAME = {'ICNN_NKL': 'ICNN (KL)', \n",
    "#                  'ICNN_NLN': 'ICNN (LN)'}\n",
    "\n",
    "final_models_X_test_se = all_models_X_test_se[((all_models_X_test_se.Imputer.str.count('ICNN') == 0) | \n",
    "                                               (all_models_X_test_se.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "\n",
    "final_models_features_stats_df = all_models_features_stats_df[((all_models_features_stats_df.Imputer.str.count('ICNN') == 0) |\n",
    "                                                               (all_models_features_stats_df.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "final_models_stats_df = all_models_stats_df[((all_models_stats_df.Imputer.str.count('ICNN') == 0) |\n",
    "                                             (all_models_stats_df.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "\n",
    "for df in (final_models_X_test_se, final_models_features_stats_df, final_models_stats_df):\n",
    "    df['Imputer'] = df['Imputer'].replace(ICNN_RENAMES)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1a047382-5028-4aae-a51c-711b33612009",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models_stats_df.Imputer.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c97e3b-bff6-4af5-871f-8758e72ddc52",
   "metadata": {},
   "source": [
    "## Metrics of Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "46f68045-44c3-4aa7-8e12-52369f86245e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST TIME - BEGIN \n",
    "# sklearn_imputed_X = {k: v.transform(np.where(art_mask_test, obs_val_test, np.nan)) for k, v in sklearn_trained_imputers.items()} \n",
    "# for sklearn_name, imputed_X_ in sklearn_imputed_X.items():\n",
    "#     X_test_imp_df = pd.DataFrame(imputed_X_, columns=obs_val.columns)    \n",
    "#     X_test_imp_df.to_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_X_test_imp.csv')\n",
    "# FIRST TIME - END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e28fb030-0384-4e69-be55-44cf95715081",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_X_test_se.Imputer.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c4b03ef-3daf-420e-bac6-7876f7ec3d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models_X_test_se['group'] = final_models_X_test_se.variable.str.split('.').map(lambda x: x[0])\n",
    "final_models_X_test_se['Feature'] = final_models_X_test_se.variable.map(variable_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7d686d2d-3c52-4761-b610-b6297f381fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = final_models_X_test_se['group'].unique().tolist()\n",
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "e48bdbbe-e6ac-4a7f-b1ec-83c03b30b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enzymes (except Amylase, Bilirubin indirect, CK-CPK)\n",
    "# renal_creat\n",
    "# renal_aki\n",
    "# renal_out\n",
    "# sofa\n",
    "\n",
    "X_test_se_df_selection = final_models_X_test_se[final_models_X_test_se.group.isin(['renal_out', 'renal_creat', 'renal_aki', 'sofa'])]\n",
    "\n",
    "grid = sns.FacetGrid(data=X_test_se_df_selection, col=\"group\", sharex=False, sharey=False, col_wrap=2,  )\n",
    "\n",
    "grid.map_dataframe(sns.boxplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "                   showmeans=True, meanprops={'marker':'o','markerfacecolor':'white','markeredgecolor':'black','markersize':'5'},\n",
    "                    # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "                    showfliers=False,\n",
    "                    fill=False,\n",
    "                     gap=0.5)\n",
    "\n",
    "# grid.map_dataframe(sns.boxenplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "#                     # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "#                     showfliers=False,\n",
    "#                     fill=False,\n",
    "#                      gap=0.5)\n",
    "\n",
    "grid.add_legend()\n",
    "grid.figure.set_size_inches(fig_width_in * 1.3, fig_height_in * 3.5)\n",
    "grid.savefig(f\"{RESULTS_DIR}/X_test_se_df_selection.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a2e79f9b-9f9a-42c4-97a1-45660c73defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_models_features_stats_df['abundance'] = all_models_features_stats_df.Feature.map(p_abundance)\n",
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[:2]) &\n",
    "                             all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:2]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b6cf9801-1f7a-425b-a2ce-2ef2b85a5be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[:2]) &\n",
    "                             all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[2:]))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6e8b646a-1aa6-40c6-b3ae-27bd7fc0d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              # all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[1:]) &\n",
    "                             all_models_features_stats_df[r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:1]) &\n",
    "                              (all_models_features_stats_df['LN'] < 0))\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0b56500-0949-4b45-b3bb-b0730f48350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For each feature, exclude the points on the upper part of uncertainty, then recompute the metrics again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3577762a-2d96-4082-9010-942933934a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models_stats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b9a40-0c3e-4b0c-8385-5347f3859f2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b7429abd-f196-433d-9f22-e0a8c3b8e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table0 = final_models_stats_df[['Imputer', 'MSE', r'MICRO-AVG($R^2$)', r'MACRO-AVG($R^2$)*']].set_index('Imputer').transpose()\n",
    "table0 = table0[['P-ICNN (NLN)', 'P-ICNN (NKLR)', 'S-ICNN (MSE)', 'S-ICNN (NMSE)', 'zero_imputer', 'mean_imputer', 'knn_imputer', 'iter_imputer']]\n",
    "# table0.columns = list(table0.columns['P-ICNN', 'S-ICNN', 'zero', 'mean', 'knn', 'iter']\n",
    "table0.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table0.columns))\n",
    "table0.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table0.columns))\n",
    "table0.columns.name = 'Imputer'\n",
    "table0 = table0.transpose().sort_values('MSE', axis=0, ascending=False)\n",
    "table0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "04bdeb24-aca1-4934-9136-db0f902b3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "table0_stl = (table0.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'MICRO-AVG($R^2$)'], :])\n",
    "              .background_gradient(cmap='RdYlGn_r', axis=0,  low=0.05, high=0.28,  vmin=0.05, vmax=0.19, subset= pd.IndexSlice[:, ['MSE']])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table0_stl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5782c68e-3a7c-457e-bbad-43cffba2c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "table0_str = (table0_stl.to_latex(caption=r\"Comparison between imputation methods. The estimations are made on the validation split.\"\n",
    "                                          r\"For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in \"\n",
    "                                          r\"the test split are excluded, \"\n",
    "                                          r\"of which some have $-\\infty$ values.\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table0_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "984420b6-2e64-4b90-8086-19543645ee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models_filtered_features_stats_df = final_models_features_stats_df[final_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "R_bins = final_models_filtered_features_stats_df.groupby(['Imputer', r'$R^2$ bin'])['Feature'].count().reset_index()\n",
    "R_bins.columns = ['Imputer', r'$R^2$ bin', 'Count']\n",
    "R_bins = R_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$R^2$ bin')\n",
    "\n",
    "R_bins = R_bins[R_classes]\n",
    "R_bins = R_bins.loc[['P-ICNN (NLN)', 'P-ICNN (NKLR)', 'S-ICNN (MSE)', 'S-ICNN (NMSE)', 'zero_imputer', 'mean_imputer', 'knn_imputer', 'iter_imputer'], :]\n",
    "# R_bins.index = ['P-ICNN', 'S-ICNN', 'zero', 'mean', 'knn', 'iter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "502b2919-f6a1-4c48-aaef-78545cb31d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = R_bins.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 2, fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/R2_bins.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4e615a9f-8207-4636-a950-30fe6a913a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models_filtered_features_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "8b50211b-e3b6-492a-a325-a346499a661a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_cols = ['MSE'] + [f'MSE@P{p}' for p in PERCENTILES]\n",
    "mse_cols_rename = {'MSE': 'P100'} | {f'MSE@P{p}': f'P{p}' for p in PERCENTILES}\n",
    "NLN_mse_percentiles = final_models_filtered_features_stats_df.loc[final_models_filtered_features_stats_df.Imputer == 'P-ICNN (NLN)', ['Feature'] + mse_cols]\n",
    "NLN_mse_percentiles = NLN_mse_percentiles.rename(columns=mse_cols_rename)\n",
    "NLN_mse_percentiles.loc[:, mse_cols_rename.values()] = NLN_mse_percentiles.loc[:, mse_cols_rename.values()].apply(lambda c: c * 100 / NLN_mse_percentiles['P100'], axis=0)\n",
    "NLN_mse_percentiles['Feature'] = NLN_mse_percentiles.Feature.map(variable_map)\n",
    "NLN_mse_percentiles = NLN_mse_percentiles.sort_values('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "fe2c2b76-7cdc-4b08-9c3d-4e971c7a7a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLN_mse_percentiles.sort_values('P50').iloc[:15]['Feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cb2d7f0a-99fb-486a-a98b-32bb7ca3585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorcet as cc\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from bokeh.models import ColumnDataSource, FixedTicker, PrintfTickFormatter, Span\n",
    "from bokeh.plotting import figure, show, curdoc\n",
    "from bokeh.sampledata.perceptions import probly\n",
    "from bokeh.io import output_notebook, export_svgs, export_png\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def ridge(category, data, scale=20):\n",
    "    return list(zip([category]*len(data), scale*data))\n",
    "\n",
    "percentiles_ = list(mse_cols_rename.values())\n",
    "palette = [cc.rainbow[i*15] for i in range(len(percentiles_))]\n",
    "\n",
    "x = np.linspace(-20, 150, 10000)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x))\n",
    "\n",
    "p = figure(y_range=percentiles_[1:], width=650, height=400, \n",
    "           x_range=(-5, 120), \n",
    "           # toolbar_location=None, \n",
    "           output_backend=\"svg\"\n",
    "          )\n",
    "\n",
    "for i, p_i in enumerate(reversed(percentiles_[1:])):\n",
    "    pdf = gaussian_kde(NLN_mse_percentiles[p_i], bw_method=0.1)\n",
    "    y = ridge(p_i, pdf(x))\n",
    "    source.add(y, p_i)\n",
    "    p.patch('x', p_i, color=palette[i], alpha=0.6, line_color=\"black\", source=source)\n",
    "\n",
    "p.add_layout(Span(location=100, dimension='height', line_color='red', line_width=5))\n",
    "\n",
    "# p.y_range.start = '\n",
    "p.outline_line_color = None\n",
    "p.background_fill_color = \"#efefef\"\n",
    "\n",
    "p.xaxis.ticker = FixedTicker(ticks=list(range(0, 110, 10)))\n",
    "p.xaxis.formatter = PrintfTickFormatter(format=\"%d%%\")\n",
    "p.xaxis.axis_label = \"%(Relative MSE)\"\n",
    "p.yaxis.axis_label = r\"\\[\\hat{\\sigma}^2\\]-Percentile (Upper Threshold)\"\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "\n",
    "\n",
    "p.ygrid.grid_line_color = None\n",
    "p.xgrid.grid_line_color = \"#dddddd\"\n",
    "p.xgrid.ticker = p.xaxis.ticker\n",
    "\n",
    "# p.axis.minor_tick_line_color = None\n",
    "# p.axis.major_tick_line_color = None\n",
    "# p.axis.axis_line_color = None\n",
    "\n",
    "p.y_range.range_padding = 0.1\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a8ef826-a2ab-4a9e-ba7e-5b14543758fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLN_mse_percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "552932ad-d5f6-428e-8171-c72d2cdfaac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import colormaps\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "\n",
    "cmap = colormaps['tab20']\n",
    "grey = colormaps['Greys'](0.5)\n",
    "uncertainty_aware_set = sorted(NLN_mse_percentiles.sort_values('P80').iloc[:9]['Feature'])\n",
    "uncertainty_aware_set_colors = {var: cmap(2*i) for i, var in enumerate(uncertainty_aware_set)}\n",
    "\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.gcf().clear()    \n",
    "fig, ax = plt.subplots(figsize=(fig_width_in * 1.5, fig_height_in * 2.5))\n",
    "\n",
    "pd.plotting.parallel_coordinates(NLN_mse_percentiles[~NLN_mse_percentiles.Feature.isin(uncertainty_aware_set)], \n",
    "                                      class_column='Feature', color='grey', linewidth=0.2)\n",
    "pd.plotting.parallel_coordinates(NLN_mse_percentiles[NLN_mse_percentiles.Feature.isin(uncertainty_aware_set)], \n",
    "                                      class_column='Feature', color=uncertainty_aware_set_colors.values(),\n",
    "                                linewidth=2,\n",
    "                                path_effects=[pe.Stroke(linewidth=2.5, foreground='black'), pe.Normal()])\n",
    "\n",
    "# remove the pandas legend\n",
    "plt.gca().legend_.remove()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 110)\n",
    "plt.xlabel(r\"$\\hat{\\sigma}^2$-Percentile (Upper Threshold)\")\n",
    "plt.ylabel(\"%(Relative MSE)\")\n",
    "# plt.title(\"Highlighted Uncertainty-Aware Dimensions\")\n",
    "\n",
    "# add new legend\n",
    "# topHandle =    mlines.Line2D([],[], color='red',   ls=\"-\", label=\"Best\")\n",
    "# midHandleOne = mlines.Line2D([],[], color='blue',  ls=\"-\", label=\"Next Best\")\n",
    "# lowHandle =    mlines.Line2D([],[], color='black', ls=\"-\", label=\"Worst\")\n",
    "plt.legend(handles=[Line2D([],[], color=c,  \n",
    "                           ls=\"-\", label=var, lw=4)  for var, c in uncertainty_aware_set_colors.items()],\n",
    "           loc='upper left', bbox_to_anchor=(1, 1),\n",
    "           prop={'size':10})\n",
    "\n",
    "plt.gcf().set_size_inches(fig_width_in * 1.1, fig_height_in * 2)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{RESULTS_DIR}/LNL_uncertainty_thresholds.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "cb42ab6f-1736-491d-abc0-bdf1d5e572d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_map_r = {label: feature for feature, label in variable_map.items()}\n",
    "\n",
    "NLN_mse_percentiles.sort_values('P60').iloc[:8]['Feature'].map(var_map_r).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "94e26d7e-4cd8-4232-abfe-153db8be1cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_t = all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                             (all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:1])) & \n",
    "                                  (all_models_features_stats_df.abundance > 0.001))]\n",
    "\n",
    "features = _t.Feature.tolist()\n",
    "_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "fa2e8169-80e5-44d5-9964-971fd8b0711b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_censored.loc['cbc.hematocrit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "8d7e17d4-8960-4918-85ff-b0ff279052c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLN_X_var_stats_df = prob_models_X_var_stats_df[prob_models_X_var_stats_df.Imputer == 'ICNN_NLN'].copy()\n",
    "NLN_X_var_stats_df[\"log(SE)\"] = np.log(NLN_X_var_stats_df[\"SE\"])\n",
    "NLN_X_var_stats_df[r'$\\log{\\hat{\\sigma}^2}$'] = np.log(NLN_X_var_stats_df[r'$\\hat{\\sigma}^2$'])\n",
    "\n",
    "\n",
    "NLN_X_var_stats_VARS = ['blood_gas.calcium',\n",
    " 'blood_gas.chloride',\n",
    " 'blood_gas.fio2_chartevents', # 2 *\n",
    " 'blood_gas.ph', #3\n",
    " 'blood_gas.so2',\n",
    " 'blood_gas.temperature',\n",
    " 'blood_gas.totalco2',\n",
    " 'cardiac_marker.ck_mb', #7\n",
    " 'cbc.hematocrit', # 8 *\n",
    " 'coagulation.fibrinogen', #9\n",
    " 'enzymes.bilirubin_indirect', #10\n",
    " 'renal_aki.aki_binary',\n",
    " 'renal_aki.aki_stage_smoothed',\n",
    " 'vital.dbp',\n",
    " 'vital.glucose', #14\n",
    " 'vital.mbp', #\n",
    " 'vital.mbp_ni',\n",
    " 'vital.sbp',\n",
    " 'vital.sbp_ni'] #18\n",
    "\n",
    "p = sns.regplot(data=NLN_X_var_stats_df[NLN_X_var_stats_df.Feature == NLN_X_var_stats_VARS[8]], \n",
    "            y=\"log(SE)\", x=r'$\\log{\\hat{\\sigma}^2}$',\n",
    "            # y=\"SE\", x=r'$\\hat{\\sigma}^2$',\n",
    "\n",
    "             x_bins=np.arange(-5, -0, 0.25), \n",
    "            # x_estimator=np.median,\n",
    "            order=1,\n",
    "            # lowess=True,\n",
    "               ci=95, \n",
    "            marker=\"x\", color=\".3\", \n",
    "                line_kws=dict(color=\"r\"),\n",
    ")\n",
    "p.set_ylabel(r'$\\log{(z - \\hat{\\mu})^2}$')\n",
    "\n",
    "p.set_title(variable_map[NLN_X_var_stats_VARS[8]], y=1.0, pad=-14)\n",
    "\n",
    "p.get_figure().set_size_inches(fig_width_in * 0.5, fig_height_in * 2)\n",
    "p.get_figure().savefig(f\"{RESULTS_DIR}/LNL_se_var_hematocrit.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "de6138b6-0d43-4f6f-b3f7-1a8805b57cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_features_stats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "e09bb7e3-732b-4462-b405-5aa658363c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_features_stats_df[all_models_features_stats_df.Imputer == 'ICNN_NLN'].set_index('Feature')[[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$', 'Imputer']].loc[NLN_X_var_stats_VARS[0]]#.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "42d26b00-4ee8-49f9-bb16-c3f73c7ccc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLN_X_var_stats_df[NLN_X_var_stats_df.Feature == NLN_X_var_stats_VARS[0]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dbdf8511-9e08-46dc-aefc-5b2fdd447016",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(-12, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e603b-3587-4c72-8d6c-d481ff295d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "1eaf8e26-f3ef-4f2c-b7d7-0ebef4ef1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_models_filtered_features_stats_df.columns\n",
    "r2_bin_cols = [r'$R^2$ bin'] + [fr'$R^2@P{p}$ bin' for p in PERCENTILES]\n",
    "# r2_bin_cols_rename = {'MSE': 'P100'} | {f'MSE@P{p}': f'P{p}' for p in PERCENTILES}\n",
    "NLN_R2_bins_percentiles = final_models_filtered_features_stats_df.loc[final_models_filtered_features_stats_df.Imputer == 'P-ICNN (NLN)', ['Feature'] + r2_bin_cols]\n",
    "NLN_R2_bins_percentiles = NLN_R2_bins_percentiles.set_index('Feature')\n",
    "NLN_R2_bins_dist_percentiles = {col: NLN_R2_bins_percentiles.groupby(col)[col].count() for col in r2_bin_cols}\n",
    "NLN_R2_bins_dist_percentiles = pd.DataFrame(NLN_R2_bins_dist_percentiles)[[r2_bin_cols[0], r2_bin_cols[6]]].transpose()\n",
    "NLN_R2_bins_dist_percentiles = NLN_R2_bins_dist_percentiles[R_classes]\n",
    "ax = NLN_R2_bins_dist_percentiles.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, \n",
    "                                                  stacked=True, colormap='RdYlGn_r', ylabel='Features Count', width=0.5)\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 0.8 , fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/NLN_R2_bins_percentiles.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6943ed17-35b1-497c-81d9-c05dbfd9afe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_models_filtered_features_stats_df.columns\n",
    "r2_bin_cols = [r'$R^2$ bin'] + [fr'$R^2@P{p}$ bin' for p in PERCENTILES]\n",
    "# r2_bin_cols_rename = {'MSE': 'P100'} | {f'MSE@P{p}': f'P{p}' for p in PERCENTILES}\n",
    "NLN_R2_bins_percentiles = final_models_filtered_features_stats_df.loc[final_models_filtered_features_stats_df.Imputer == 'P-ICNN (NLN)', ['Feature'] + r2_bin_cols]\n",
    "NLN_R2_bins_percentiles = NLN_R2_bins_percentiles.set_index('Feature')\n",
    "NLN_R2_bins_dist_percentiles = {col: NLN_R2_bins_percentiles.groupby(col)[col].count() for col in r2_bin_cols}\n",
    "NLN_R2_bins_dist_percentiles = pd.DataFrame(NLN_R2_bins_dist_percentiles)[[r2_bin_cols[0], r2_bin_cols[6]]].transpose()\n",
    "NLN_R2_bins_dist_percentiles = NLN_R2_bins_dist_percentiles[R_classes]\n",
    "ax = NLN_R2_bins_dist_percentiles.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, \n",
    "                                                  stacked=True, colormap='RdYlGn_r', ylabel='Features Count', width=0.5)\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 0.8 , fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/NLN_R2_bins_percentiles.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "637b0212-376c-400d-a205-c786ab607e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_bin_cols"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
