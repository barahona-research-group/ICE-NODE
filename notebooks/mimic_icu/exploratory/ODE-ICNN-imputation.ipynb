{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c394ab-9d98-4136-8f54-4e0f42fa89f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlalchemy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.config.update('jax_platforms', 'cpu')\n",
    "\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2\n",
    "    \n",
    "from lib.base import Config, Module\n",
    "from lib.ml.in_models import InICENODELiteICNNImpute\n",
    "from lib.ml.rectilinear_modules import ZeroImputer, MeanImputer, RectilinearImputer\n",
    "from lib.ml.experiment import Experiment\n",
    "from lib.metric.metrics import MetricsCollection\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_transformations import TrainingSplitGroups\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config, append_params_to_zip, zip_members, load_config, translate_path\n",
    "from lib.ml.icnn_modules import  ProbICNNImputerTrainer\n",
    "\n",
    "import pub_ready_plots\n",
    "from pub_ready_plots import get_mpl_rcParams\n",
    "rc_params, fig_width_in, fig_height_in = pub_ready_plots.get_mpl_rcParams(\n",
    "    width_frac=1,  # between 0 and 1\n",
    "    height_frac=0.2,  # between 0 and 1\n",
    "    layout=\"jmlr\"  # or \"iclr\", \"neurips\", \"poster-portrait\", \"poster-landscape\"\n",
    ")\n",
    "rc_params['figure.constrained_layout.use'] = True\n",
    "\n",
    "# rc_params['font.size'] = 10\n",
    "# rc_params['axes.titlesize'] = 12\n",
    "# rc_params['axes.labelsize'] = 10\n",
    "# rc_params['legend.fontsize'] = 10\n",
    "\n",
    "plt.rcParams.update(rc_params)\n",
    "# %reload_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37e7de-160b-4ed4-abc1-5e76514cfac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = f\"aki_evals/seg_auto.sqlite\"\n",
    "\n",
    "def model_name(exp):\n",
    "    if 'AutoODE' in exp:\n",
    "        return 'ODE-ICNN'\n",
    "    if 'AutoKoop' in exp:\n",
    "        return 'Koopman-ICNN'\n",
    "    assert False\n",
    "\n",
    "\n",
    "def batch_size(exp):\n",
    "    if 'B2' in exp:\n",
    "        return 2\n",
    "    if 'B8':\n",
    "        return 8\n",
    "    if 'B16':\n",
    "        return 16\n",
    "    assert False\n",
    "\n",
    "def dyn(exp):\n",
    "    if 'grudyn' in exp:\n",
    "        return 'GRU'\n",
    "    else:\n",
    "        return 'MLP'\n",
    "\n",
    "def opt_name(exp):\n",
    "    if 'lamb' in exp:\n",
    "        return 'lamb'\n",
    "    if 'adam' in exp:\n",
    "        return 'adam'\n",
    "    if 'ademamix' in exp:\n",
    "        return 'ademamix'\n",
    "    if 'novograd' in exp:\n",
    "        return 'novograd'\n",
    "    return 'adam'\n",
    "\n",
    "def lr(exp):\n",
    "    if 'lr2' in exp:\n",
    "        return 0.01\n",
    "    else:\n",
    "        return 0.001\n",
    "\n",
    "\n",
    "\n",
    "def sql2dataframe(db):\n",
    "    engine = sqlalchemy.create_engine(\"sqlite:///%s\" % db, execution_options={\"sqlite_raw_colnames\": True},\n",
    "                                     connect_args={'timeout': 5})\n",
    "    \n",
    "    df = {name: pd.read_sql_table(name, engine) for name in \n",
    "          ('evaluation_runs', 'evaluation_status', 'experiments', 'metrics', 'results')}\n",
    "    df['results']\n",
    "    \n",
    "    metrics = df['metrics'].rename(columns={'name': 'metric', 'id': 'metric_id'})\n",
    "    eval_runs = df['evaluation_runs'].rename(columns={'id': 'evaluation_id'})\n",
    "    experiments = df['experiments'].rename(columns={'name': 'experiment', 'id': 'experiment_id'})\n",
    "    eval_status = df['evaluation_status'].rename(columns={'id': 'status_id', 'name': 'status'})\n",
    "    \n",
    "    res = pd.merge(df['results'], metrics, left_on='metric_id', right_on='metric_id', how='left')\n",
    "    res = pd.merge(res, eval_runs, left_on='evaluation_id', right_on='evaluation_id', how='left')\n",
    "    res = pd.merge(res, experiments, left_on='experiment_id', right_on='experiment_id', how='left')\n",
    "    res = pd.merge(res, eval_status, left_on='status_id', right_on='status_id', how='left')\n",
    "    res['step'] = res.snapshot.str.extract('(\\d+)').astype(int)\n",
    "\n",
    "    res = res.sort_values(['experiment_id', 'step'])\n",
    "    res['last_max'] = float('nan')\n",
    "    res['last_min'] = float('nan')\n",
    "    res['is_max'] = False\n",
    "    res['is_min'] = False\n",
    "    res['max'] = float('nan')\n",
    "    res['min'] = float('nan')\n",
    "    \n",
    "    for exp, exp_df in res.groupby('experiment_id'):\n",
    "        for metric, metric_df in exp_df.groupby('metric'):\n",
    "            index = metric_df.index\n",
    "            res.loc[index, 'last_max'] = metric_df['value'].cummax()\n",
    "            res.loc[index, 'last_min'] = metric_df['value'].cummin()\n",
    "            res.loc[index, 'is_max'] = metric_df['value'] == res.loc[index, 'last_max']\n",
    "            res.loc[index, 'is_min'] = metric_df['value'] == res.loc[index, 'last_min']\n",
    "            res.loc[index, 'max'] = metric_df['value'].max()\n",
    "            res.loc[index, 'min'] = metric_df['value'].min()\n",
    "            \n",
    "    \n",
    "    res = res[[col for col in res.columns if 'id' not in col]]\n",
    "\n",
    "    res['model'] = res.experiment.map(model_name)\n",
    "    res['batch_size'] = res.experiment.map(batch_size)\n",
    "    res['dynamics'] = res.experiment.map(dyn)\n",
    "    res['opt'] = res.experiment.map(opt_name)\n",
    "    res['lr'] = res.experiment.map(lr)\n",
    "\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "def experiment_mincost_snapshots(dataframe, \n",
    "                                 cost_metrics = ['ObsPredictionLossMetric.mse', 'LeadPredictionLossMetric.mse']):\n",
    "    def experiment_step_min_cost(experiment_df):\n",
    "        return pd.Series({'best_step': experiment_df.loc[experiment_df['value'].idxmin(), 'step']})\n",
    "        \n",
    "    results2 = dataframe[dataframe.metric.isin(cost_metrics)]\n",
    "    results2 = results2[['experiment', 'step', 'value']].groupby(['experiment', 'step']).sum().reset_index()\n",
    "    results2 = results2.groupby('experiment').apply(experiment_step_min_cost).reset_index()\n",
    "    return results2.set_index('experiment')['best_step'].to_dict()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dcd94fc-ca8f-4347-9a47-32b252dc64b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVAL_CONFIG_FILE = '/home/asem/GP/ICENODE/experiment_templates/icu/eval_config.json'\n",
    "# metrics_config = Config.from_dict(load_config(translate_path(EVAL_CONFIG_FILE))).metrics\n",
    "# metrics = MetricsCollection(metrics=tuple(Module.import_module(config=config) for config in metrics_config))\n",
    "\n",
    "EXP_DIR = f'{os.environ[\"HOME\"]}/GP/ehr-data/aki_out/seg_auto/AutoODEICNN_mlpdyn_g0_novograd'\n",
    "experiment = Experiment(Config.from_dict(load_config(os.path.join(EXP_DIR, 'config.json'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de492f3b-1669-45e2-bef8-0965c6d8c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_data(tvx):\n",
    "    \n",
    "    obs = [adm.observables  for subject in tvx.subjects.values() for adm in subject.admissions]\n",
    "    adm_id = sum(([adm.admission_id] * len(adm.observables.time)  for subject in tvx.subjects.values() for adm in subject.admissions), [])\n",
    "    subj_id = sum(([subject.subject_id] * len(adm.observables.time)  for subject in tvx.subjects.values() for adm in subject.admissions), [])\n",
    "    \n",
    "    obs_val = np.vstack([obs_i.value for obs_i in obs])\n",
    "    obs_mask = np.vstack([obs_i.mask for obs_i in obs])\n",
    "    obs_time = np.hstack([obs_i.time for obs_i in obs])\n",
    "    obs_time_index = np.hstack([np.arange(len(obs_i.time)) for obs_i in obs])\n",
    "    \n",
    "    tvx.scheme.obs\n",
    "    features = list(map(tvx.scheme.obs.desc.get, tvx.scheme.obs.codes))\n",
    "    \n",
    "    \n",
    "    obs_val = pd.DataFrame(obs_val, columns=features)\n",
    "    obs_mask = pd.DataFrame(obs_mask.astype(int), columns=features)\n",
    "    meta = pd.DataFrame({'subject_id': subj_id, 'admission_id': adm_id, 'time': obs_time, 'time_index': obs_time_index})\n",
    "\n",
    "    artificial_mask = obs_mask.copy()\n",
    "    artificial_mask = obs_mask & np.array(jrandom.bernoulli(jrandom.PRNGKey(0), p=0.8, shape=obs_mask.shape))\n",
    "    return obs_val, obs_mask, artificial_mask, meta\n",
    "\n",
    "def art_mask_tvx(tvx, art_mask, meta):\n",
    "    admission_art_mask = defaultdict(dict)\n",
    "    for (subject_id, admission_id), meta_adm_df in meta.groupby(['subject_id', 'admission_id']):\n",
    "        admission_art_mask[str(subject_id)][str(admission_id)] = art_mask.loc[meta_adm_df.index].to_numpy()\n",
    "    masked_subjects = {}\n",
    "    for subject_id, art_masks in admission_art_mask.items():\n",
    "        masked_subject = tvx.subjects[subject_id]\n",
    "        admissions = {admission.admission_id: admission for admission in masked_subject.admissions}\n",
    "        masked_admissions = {a.admission_id: a for a in masked_subject.admissions if a.admission_id not in art_mask}\n",
    "        for admission_id, art_mask in art_masks.items():\n",
    "            obs = admissions[admission_id].observables\n",
    "            obs = eqx.tree_at(lambda x: x.value, obs, np.where(art_mask, obs.value, 0.0))\n",
    "            obs = eqx.tree_at(lambda x: x.mask, obs, art_mask)\n",
    "            masked_admissions[admission_id] = eqx.tree_at(lambda x: x.observables, admissions[admission_id], obs)\n",
    "        masked_admissions = list(map(masked_admissions.get, (a.admission_id for a in masked_subject.admissions)))\n",
    "        masked_subjects[subject_id] = eqx.tree_at(lambda x: x.admissions, masked_subject, masked_admissions)\n",
    "    return eqx.tree_at(lambda x: x.subjects, tvx, masked_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e754fb8-253e-43d0-af2d-49577119174f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tvx0 = TVxEHR.load(\"/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki_0.h5\")\n",
    "tvx1 = TVxEHR.load(\"/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki_1.h5\")\n",
    "\n",
    "# obs_val0, obs_mask0, art_mask0, meta0 = gen_data(tvx0)\n",
    "# obs_val1, obs_mask1, art_mask1, meta1 = gen_data(tvx1)\n",
    "\n",
    "# obs_val0.to_csv('g0g1_missingness_data/missingness_vals0.csv')\n",
    "# obs_mask0.to_csv('g0g1_missingness_data/missingness_mask0.csv')\n",
    "# art_mask0.to_csv('g0g1_missingness_data/missingness_artificial_mask0.csv')\n",
    "# meta0.to_csv('g0g1_missingness_data/missingness_meta0.csv')\n",
    "\n",
    "# obs_val1.to_csv('g0g1_missingness_data/missingness_vals1.csv')\n",
    "# obs_mask1.to_csv('g0g1_missingness_data/missingness_mask1.csv')\n",
    "# art_mask1.to_csv('g0g1_missingness_data/missingness_artificial_mask1.csv')\n",
    "# meta1.to_csv('g0g1_missingness_data/missingness_meta1.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f3bb399a-2fcc-4ee8-b7f6-4640ac9b54ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31acf523-fb47-4e7a-a504-20dfd35e6044",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_val0 = pd.read_csv('g0g1_missingness_data/missingness_vals0.csv', index_col=[0])\n",
    "obs_mask0 = pd.read_csv('g0g1_missingness_data/missingness_mask0.csv', index_col=[0])\n",
    "art_mask0 = pd.read_csv('g0g1_missingness_data/missingness_artificial_mask0.csv', index_col=[0])\n",
    "meta0 = pd.read_csv('g0g1_missingness_data/missingness_meta0.csv', index_col=[0])\n",
    "\n",
    "obs_val1 = pd.read_csv('g0g1_missingness_data/missingness_vals1.csv', index_col=[0])\n",
    "obs_mask1 = pd.read_csv('g0g1_missingness_data/missingness_mask1.csv', index_col=[0])\n",
    "art_mask1 = pd.read_csv('g0g1_missingness_data/missingness_artificial_mask1.csv', index_col=[0])\n",
    "meta1 = pd.read_csv('g0g1_missingness_data/missingness_meta1.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7933eaec-d725-48bd-9438-67809ee824c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_tvx1 = art_mask_tvx(tvx1, art_mask1, meta1)\n",
    "tvx1_subjects = list(masked_tvx1.subjects.keys())\n",
    "test_size = 1000\n",
    "seed = 0\n",
    "indices = jrandom.permutation(jrandom.PRNGKey(seed), len(tvx1_subjects))\n",
    "test_idx = tuple(tvx1_subjects[i] for i in indices[:test_size].tolist())\n",
    "masked_tvx1_sample = TrainingSplitGroups.subset(masked_tvx1, test_idx)   \n",
    "\n",
    "# sampled_masked_obs_val1, sampled_masked_obs_mask1, _, sampled_masked_meta1 = gen_data(masked_tvx1_sample)\n",
    "# sampled_masked_obs_val1.to_csv('g0g1_missingness_data/missingness_sampled_masked_val1.csv')\n",
    "# sampled_masked_obs_mask1.to_csv('g0g1_missingness_data/missingness_sampled_masked_mask1.csv')\n",
    "# sampled_masked_meta1.to_csv('g0g1_missingness_data/missingness_sampled_masked_meta1.csv')\n",
    "\n",
    "\n",
    "\n",
    "sampled_masked_obs_val1 = pd.read_csv('g0g1_missingness_data/missingness_sampled_masked_val1.csv', index_col=[0])\n",
    "sampled_masked_obs_mask1 = pd.read_csv('g0g1_missingness_data/missingness_sampled_masked_mask1.csv', index_col=[0])\n",
    "sampled_masked_meta1 = pd.read_csv('g0g1_missingness_data/missingness_sampled_masked_meta1.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fc2cb4-05e6-49b8-b44a-40184def6503",
   "metadata": {},
   "outputs": [],
   "source": [
    "tvx_phantom = TVxEHR.load(\"/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki_phantom.h5\")\n",
    "features = list(map(tvx_phantom.scheme.obs.desc.get, tvx_phantom.scheme.obs.codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eeeacc3-ed22-4242-aaab-1fa3e6d26a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'ode-icnn_results'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31edd17d-177f-4cd0-b1af-e0eaafdd5f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_to_dataframe(obs_columns, predictions):\n",
    "    predictions_df = []\n",
    "    meta_df = defaultdict(list)\n",
    "    for subject_id, subject_predictions in predictions.subject_predictions.items():\n",
    "        for admission_prediction in subject_predictions:\n",
    "            if admission_prediction.observables is None:\n",
    "                continue\n",
    "            time = admission_prediction.observables.time\n",
    "            obs = admission_prediction.observables.value\n",
    "            meta_df['subject_id'].extend([subject_id] * len(time))\n",
    "            meta_df['admission_id'].extend([admission_prediction.admission.admission_id] * len(time))\n",
    "            meta_df['time_index'].extend(range(len(time)))\n",
    "            meta_df['time'].extend(time.tolist())\n",
    "            predictions_df.append(obs)\n",
    "\n",
    "    predictions_df = pd.DataFrame(np.vstack(predictions_df), columns=obs_columns)\n",
    "    meta_df = pd.DataFrame(meta_df)\n",
    "    return predictions_df, meta_df\n",
    "\n",
    "def imputations_to_dataframe(obs_columns, predictions):\n",
    "    predictions_df = []\n",
    "    meta_df = defaultdict(list)\n",
    "    for subject_id, subject_predictions in predictions.subject_predictions.items():\n",
    "        for admission_prediction in subject_predictions:\n",
    "            if admission_prediction.imputed_observables is None:\n",
    "                continue\n",
    "            time = admission_prediction.imputed_observables.time\n",
    "            obs = admission_prediction.imputed_observables.value\n",
    "            meta_df['subject_id'].extend([subject_id] * len(time))\n",
    "            meta_df['admission_id'].extend([admission_prediction.admission.admission_id] * len(time))\n",
    "            meta_df['time_index'].extend(range(len(time)))\n",
    "            meta_df['time'].extend(time.tolist())\n",
    "            predictions_df.append(obs)\n",
    "\n",
    "    predictions_df = pd.DataFrame(np.vstack(predictions_df), columns=obs_columns)\n",
    "    meta_df = pd.DataFrame(meta_df)\n",
    "    return predictions_df, meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1395850b-3c5f-4bd0-8532-803bb37deb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_columns = ['subject_id', 'admission_id', 'time_index']\n",
    "\n",
    "sampled_index = sampled_masked_meta1.set_index(id_columns).index\n",
    "sampled_meta1_index = meta1.reset_index().set_index(id_columns).loc[sampled_index].reset_index()['index']\n",
    "assert sampled_masked_meta1[id_columns].equals(sampled_masked_meta1[id_columns])\n",
    "sampled_mask1 = obs_mask1.loc[sampled_meta1_index].reset_index(drop=True)\n",
    "sampled_obs_val1 = obs_val1.loc[sampled_meta1_index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71ae2219-ff52-4674-a409-507d03e243b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "((1 - sampled_masked_obs_mask1) * sampled_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "607f26a3-7d6a-4278-adfb-5b092849bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_mask = (1 - sampled_masked_obs_mask1) * sampled_mask1\n",
    "feature2index =  dict(zip(sampled_mask1.columns, range(len(sampled_mask1.columns))))\n",
    "n_test = prediction_mask.sum(axis=0)\n",
    "\n",
    "missingness = 1 - obs_mask0.mean(axis=0)\n",
    "validation_missingness = 1 - sampled_masked_obs_mask1.mean(axis=0)\n",
    "n_test_censored = pd.Series(prediction_mask.sum(axis=0), index=sampled_mask1.columns)\n",
    "p_test_censored = n_test_censored / len(prediction_mask)\n",
    "vars_n300 = n_test_censored[n_test_censored >= 300].index\n",
    "vars_n300_r = n_test_censored[n_test_censored < 300].index\n",
    "vars_n300, len(vars_n300)\n",
    "variable_map = {'blood_chemistry.albumin': 'Albumin',  'blood_chemistry.aniongap': 'Aniongap',  \n",
    "                'blood_chemistry.bicarbonate': 'bc.Bicarbonate',  'blood_chemistry.bun': 'Urea Nitrogen', \n",
    "                'blood_chemistry.calcium': 'bc.Calcium',  'blood_chemistry.chloride': 'bc.Chloride',  \n",
    "                'blood_chemistry.creatinine': 'bc.Creatinine',  'blood_chemistry.globulin': 'Globulin',  \n",
    "                'blood_chemistry.glucose': 'bc.Glucose',  'blood_chemistry.potassium': 'bc.Potassium',  \n",
    "                'blood_chemistry.sodium': 'bc.Sodium',  'blood_chemistry.total_protein': 'Protein Total', \n",
    "                'blood_diff.atypical_lymphocytes': 'Atypical Lymphocytes',  'blood_diff.bands': 'Bands (%)',  \n",
    "                'blood_diff.basophils': 'Basophils',  'blood_diff.basophils_abs': 'Abs Basophils', \n",
    "                'blood_diff.eosinophils': 'Eosinophils',  'blood_diff.eosinophils_abs': 'Abs Eosinophils', \n",
    "                'blood_diff.immature_granulocytes': 'Immature Granulocytes',  'blood_diff.lymphocytes': 'Lymphocytes',\n",
    "                'blood_diff.lymphocytes_abs': 'Abs Lymphocytes',  'blood_diff.metamyelocytes': 'Metamyelocytes', \n",
    "                'blood_diff.monocytes': 'Monocytes',  'blood_diff.monocytes_abs': 'Abs Monocytes', \n",
    "                'blood_diff.neutrophils': 'Neutrophils',  'blood_diff.neutrophils_abs': 'Abs Neutrophil', \n",
    "                'blood_diff.nrbc': 'NRBC',  'blood_gas.aado2': 'AaDO2',  'blood_gas.aado2_calc': 'AaDO2_calc',\n",
    "                'blood_gas.baseexcess': 'Base excess',  'blood_gas.bicarbonate': 'bg.Bicarbonate',  'blood_gas.calcium': 'bg.Calcium',  \n",
    "                'blood_gas.carboxyhemoglobin': 'Carboxyhemoglobin',  'blood_gas.chloride': 'bg.Chloride',  'blood_gas.fio2': 'FiO2',  \n",
    "                'blood_gas.fio2_chartevents': 'FiO2_chartevents',  'blood_gas.glucose': 'bg.Glucose',  \n",
    "                'blood_gas.hematocrit': 'bg.Hematocrit',  'blood_gas.hemoglobin': 'bg.Hemoglobin',  'blood_gas.lactate': 'Lactate', \n",
    "                'blood_gas.methemoglobin': 'Methemoglobin',  'blood_gas.pao2fio2ratio': 'pO2/FiO2 ratio',  'blood_gas.pco2': 'pCO2',\n",
    "                'blood_gas.ph': 'pH',  'blood_gas.po2': 'pO2',  'blood_gas.potassium': 'bg.Potassium',  'blood_gas.so2': 'sO2', \n",
    "                'blood_gas.sodium': 'bg.Sodium',  'blood_gas.temperature': 'bg.Temperature',  'blood_gas.totalco2': 'CO2 total', \n",
    "                'cardiac_marker.ck_mb': 'Creatinine Kinase, MB',  'cardiac_marker.ntprobnp': 'NT-proBNP', \n",
    "                'cardiac_marker.troponin_t2': 'Troponin T',  'cbc.hematocrit': 'cbc.Hematocrit',  'cbc.hemoglobin': 'cbc.Hemoglobin', \n",
    "                'cbc.mch': 'MCH',  'cbc.mchc': 'MCHC',  'cbc.mcv': 'MCV',  'cbc.platelet': 'Platelet',  'cbc.rbc': 'RBC', \n",
    "                'cbc.rdw': 'RDW',  'cbc.wbc': 'WBC',  'coagulation.d_dimer': 'D-Dimer',  'coagulation.fibrinogen': 'Fibrinogen', \n",
    "                'coagulation.inr': 'INR',  'coagulation.pt': 'PT',  'coagulation.ptt': 'PTT',  'coagulation.thrombin': 'Thrombin',\n",
    "                'enzymes.alp': 'ALP',  'enzymes.alt': 'ALT',  'enzymes.amylase': 'Amylase',  'enzymes.ast': 'AST', \n",
    "                'enzymes.bilirubin_direct': 'Bilirubin direct',  'enzymes.bilirubin_indirect': 'Bilirubin indirect',\n",
    "                'enzymes.bilirubin_total': 'Bilirubin total',  'enzymes.ck_cpk': 'CK-CPK',  'enzymes.ck_mb':'CK-MB', \n",
    "                'enzymes.ggt': 'GGT',  'enzymes.ld_ldh': 'ld_ldh',  'icp.icp': 'Intra-cranial Press.',\n",
    "                'inflammation.crp': 'CRP',  'renal_aki.aki_binary': 'AKI (binary)',  'renal_aki.aki_stage_smoothed': 'AKI', \n",
    "                'renal_creat.creat': 'renal.Creatinine',  'renal_out.uo_rt_12hr': 'Urine out 12h',  'renal_out.uo_rt_24hr': 'Urine out 24h',\n",
    "                'renal_out.uo_rt_6hr': 'Urine out 6h',  'sofa.sofa_24hours': 'SOFA',  'vital.dbp': 'Diastolic BP', \n",
    "                'vital.dbp_ni': 'NI-Diastolic BP',  'vital.glucose': 'vital.Glucose',  'vital.heart_rate': 'Heart Rate',  \n",
    "                'vital.mbp':  'Mean BP',  'vital.mbp_ni': 'NI Mean BP',  'vital.resp_rate': 'Respiratory Rate', \n",
    "                'vital.sbp': 'Systolic BP',  'vital.sbp_ni':  'NI-Systolic BP',  'vital.spo2': 'SpO2',  \n",
    "                'vital.temperature': 'vital.Temperature',  'weight.weight': 'Weight'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04b053-a90c-4c94-9c9e-62bf113ac051",
   "metadata": {},
   "source": [
    "## Imputation with Mean-RectLinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1823acc-c7a2-43cd-8ba4-c06de2f2e119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rect_imputer = RectilinearImputer.from_tvx_ehr(tvx0)\n",
    "# rect_preds = rect_imputer.batch_predict(masked_tvx1_sample)\n",
    "# rect_predictions_df, rect_meta_df = predictions_to_dataframe(features, rect_preds)\n",
    "\n",
    "# rect_predictions_df.to_csv(f'{RESULTS_DIR}/RECTLIN_pred_X_test_imp.csv')\n",
    "# rect_meta_df.to_csv(f'{RESULTS_DIR}/RECTLIN_pred_meta.csv')\n",
    "rect_predictions_df = pd.read_csv(f'{RESULTS_DIR}/RECTLIN_pred_X_test_imp.csv', index_col=[0])\n",
    "rect_meta_df = pd.read_csv(f'{RESULTS_DIR}/RECTLIN_pred_meta.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4661e3e-f941-4878-8b69-5955236e9715",
   "metadata": {},
   "source": [
    "## Imputation with ODEICNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9154d-7f67-4ce1-a233-0d686fccf235",
   "metadata": {},
   "outputs": [],
   "source": [
    "SNAPSHOT_ID = f\"{2750:04d}\"\n",
    "SNAPSHOT = f'step{SNAPSHOT_ID}.eqx'\n",
    "\n",
    "odeicnn = experiment.load_model(tvx_phantom, 0).load_params_from_archive(os.path.join(EXP_DIR, 'params.zip'), SNAPSHOT)\n",
    "odeicnn_preds = odeicnn.batch_predict(masked_tvx1_sample)\n",
    "\n",
    "odeicnn_predictions_df, odeicnn_meta_df = imputations_to_dataframe(features, odeicnn_preds)\n",
    "odeicnn_predictions_df.to_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_X_test_imp.csv')\n",
    "odeicnn_meta_df.to_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_imp_meta.csv')\n",
    "\n",
    "odeicnn_forcs_df, odeicnn_forcs_meta_df = predictions_to_dataframe(features, odeicnn_preds)\n",
    "odeicnn_forcs_df.to_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_X_test_forcs.csv')\n",
    "odeicnn_forcs_meta_df.to_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_forcs_meta.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63a0661-9263-4658-be63-217075c0f3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "odeicnn_predictions_df = pd.read_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_X_test_imp.csv', index_col=[0])\n",
    "odeicnn_forcs_df = pd.read_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_X_test_forcs.csv', index_col=[0])\n",
    "odeicnn_meta_df = pd.read_csv(f'{RESULTS_DIR}/ODEICNN_{SNAPSHOT_ID}_pred_imp_meta.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126d0e1-ebbd-4bd8-ba97-e9923f5ef881",
   "metadata": {},
   "source": [
    "## Sklearn Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b004194e-5e7e-4d9d-b7fa-45613fcbe4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "\n",
    "sklearn_imputers =  {\n",
    "    'zero_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': lambda: KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': lambda: IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd2e485c-7743-44d7-b4c8-cabaf350a783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn_trained_imputers = {k: v().fit(np.where(obs_mask0, obs_val0, np.nan)) \n",
    "#                             for k, v in sklearn_imputers.items()} \n",
    "\n",
    "# sklearn_imputed_X = {k: v.transform(np.where(sampled_masked_obs_mask1, sampled_masked_obs_val1, np.nan)) \n",
    "#                      for k, v in sklearn_trained_imputers.items()} \n",
    "\n",
    "# for sklearn_name, imputed_X_ in sklearn_imputed_X.items():\n",
    "#     X_test_imp_df = pd.DataFrame(imputed_X_, columns=sampled_masked_obs_val1.columns)    \n",
    "#     X_test_imp_df.to_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_X_test_imp.csv')\n",
    "#     sampled_masked_meta1.to_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_imp_meta.csv')\n",
    "\n",
    "sklearn_imputed_X = {}\n",
    "sklearn_meta = {}\n",
    "for sklearn_name in sklearn_imputers.keys():\n",
    "    sklearn_imputed_X[sklearn_name] = pd.read_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_X_test_imp.csv', index_col=[0])\n",
    "    sklearn_meta[sklearn_name] = pd.read_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_imp_meta.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29d00e4f-7636-41c4-be54-f23760b922bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_X_test_imp_df = {'ODE-ICNN': odeicnn_predictions_df,  'Mean-RectLin': rect_predictions_df} | sklearn_imputed_X\n",
    "all_models_meta = {'ODE-ICNN': odeicnn_meta_df,  'Mean-RectLin': rect_meta_df} | sklearn_meta\n",
    "reference_meta = all_models_meta['ODE-ICNN']\n",
    "\n",
    "all_models_features_stats_df = []\n",
    "all_models_stats_df = []\n",
    "all_models_X_test_se = []\n",
    "\n",
    "M_ = prediction_mask.to_numpy().astype(bool)\n",
    "Z_ = sampled_obs_val1.to_numpy()\n",
    "for model_name in tqdm(list(all_models_X_test_imp_df.keys())):\n",
    "    x_file = f'{RESULTS_DIR}/{model_name}_pred_X_test_imp.csv'\n",
    "    \n",
    "    Z_hat_df = all_models_X_test_imp_df[model_name]\n",
    "    Z_hat = Z_hat_df.to_numpy()\n",
    "    meta_ = all_models_meta[model_name]\n",
    "    assert meta_[id_columns].equals(reference_meta[id_columns])\n",
    "    \n",
    "    # Squared-Errors (per instance)\n",
    "    X_test_se_ = (Z_hat_df - Z_)**2\n",
    "    X_test_se_ = X_test_se_.where(M_, other=np.nan)\n",
    "    X_test_se_arr = jnp.array(X_test_se_.to_numpy())\n",
    "    \n",
    "    X_test_se_melt = pd.melt(X_test_se_, value_vars=list(sampled_masked_obs_val1.columns), value_name='SE')\n",
    "    X_test_se_melt = X_test_se_melt[X_test_se_melt.SE.notnull()]\n",
    "    X_test_se_melt['Imputer'] = model_name\n",
    "\n",
    "    all_models_X_test_se.append(X_test_se_melt)\n",
    "\n",
    "    # R2/MSE (per feature)\n",
    "    features_r2_ = eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(Z_.T, Z_hat.T, M_.T)\n",
    "\n",
    "    mse_ = np.nanmean(X_test_se_arr, axis=0, where=M_)\n",
    "    features_stats_df_ = pd.DataFrame({r'$R^2$': np.array(features_r2_), \n",
    "                                       'MSE': mse_,\n",
    "                                       'Feature': X_test_se_.columns,\n",
    "                                       'Imputer': [model_name] * len(mse_)})\n",
    "        \n",
    "\n",
    "    all_models_features_stats_df.append(features_stats_df_)\n",
    "\n",
    "    # R2/MSE (per model)\n",
    "    features_stats_300_df = features_stats_df_[features_stats_df_.Feature.isin(vars_n300)]\n",
    "    weighted_avg_R2 = np.average(features_stats_300_df[r'$R^2$'], \n",
    "                                 weights=features_stats_300_df['Feature'].map(n_test_censored))\n",
    "    \n",
    "    all_models_stats_df.append(pd.DataFrame({'Imputer': [model_name],\n",
    "                                    'MSE': [np.nanmean(X_test_se_arr, where=M_)],\n",
    "                                    r'$R^2$': [ProbICNNImputerTrainer.r_squared(Z_, Z_hat, M_).item()],\n",
    "                                    r'MICRO-AVG($R^2$)': [ProbICNNImputerTrainer.r_squared_micro_average(Z_, Z_hat, M_).item()],\n",
    "                                    r'MACRO-AVG($R^2$)*': [features_stats_300_df[r'$R^2$'].mean()]}))\n",
    "    \n",
    "all_models_X_test_se = pd.concat(all_models_X_test_se)\n",
    "all_models_features_stats_df = pd.concat(all_models_features_stats_df)\n",
    "all_models_stats_df = pd.concat(all_models_stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef49649a-3f49-4a64-ac99-a500f6ef0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_classes = [r'$R^2 > 0.25$', r'$R^2 \\in (0.1, 0.25]$', r'$R^2 \\in [-0.1, 0.1]$', r'$R^2 \\in (-1, -0.1]$',  r'$R^2 \\in (-9, -1]$', r'$R^2 < -9$']\n",
    "\n",
    "\n",
    "def classify_R(R):\n",
    "    if R > 0.25:\n",
    "        return R_classes[0]\n",
    "    elif R > 0.1:\n",
    "        return R_classes[1]\n",
    "    elif R >= -0.1:\n",
    "        return R_classes[2]\n",
    "    elif R >= -1:\n",
    "        return R_classes[3] \n",
    "    elif R >= -9:\n",
    "        return R_classes[4]\n",
    "    elif R < -9:\n",
    "        return R_classes[5]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "\n",
    "all_models_features_stats_df[r'$R^2$ bin'] = all_models_features_stats_df[r'$R^2$'].map(classify_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "facbf888-5ca1-4d23-b123-023abab09131",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_filtered_features_stats_df = all_models_features_stats_df[all_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "R_bins = models_filtered_features_stats_df.groupby(['Imputer', r'$R^2$ bin'])['Feature'].count().reset_index()\n",
    "R_bins.columns = ['Imputer', r'$R^2$ bin', 'Count']\n",
    "R_bins = R_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$R^2$ bin')\n",
    "R_bins = R_bins[R_classes]\n",
    "ax = R_bins.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 1.2, fig_height_in * 2)\n",
    "# ax.get_figure().savefig(f\"{RESULTS_DIR}/R2_bins.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3e815ac-3589-4bc0-b7c7-ae9803c5cb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a1c529-14a9-4e43-a5f5-008d5a390861",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
