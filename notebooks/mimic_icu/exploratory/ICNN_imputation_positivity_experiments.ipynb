{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "## Libs\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.config.update('jax_platforms', 'cpu')\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.icnn_modules import ProbStackedICNNImputer, ImputerMetrics, ProbICNNImputerTrainer\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config\n",
    " "
   ],
   "id": "8eb72581cf817701"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Loading",
   "id": "ff341aaaf35553f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### First Time Loading",
   "id": "d47d0042e62af6d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# tvx = m4aki.TVxAKIMIMICIVDataset.load('/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki.h5')",
   "id": "5b0db334e50240b1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# obs = [adm.observables  for subject in tvx0.subjects.values() for adm in subject.admissions]\n",
    "# adm_id = sum(([adm.admission_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])\n",
    "# subj_id = sum(([subject.subject_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])"
   ],
   "id": "ed5958c790f5aed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# obs_val = np.vstack([obs_i.value for obs_i in obs])\n",
    "# obs_mask = np.vstack([obs_i.mask for obs_i in obs])\n",
    "# obs_time = np.hstack([obs_i.time for obs_i in obs])"
   ],
   "id": "d70ba4fdc381ddc4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# tvx0.scheme.obs\n",
    "# features = list(map(tvx0.scheme.obs.desc.get, tvx0.scheme.obs.codes))"
   ],
   "id": "6cfd63efa874a6b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# obs_val = pd.DataFrame(obs_val, columns=features)\n",
    "# obs_mask = pd.DataFrame(obs_mask.astype(int), columns=features)\n",
    "# meta = pd.DataFrame({'subject_id': subj_id, 'admission_id': adm_id, 'time': obs_time})\n"
   ],
   "id": "340119bec8547294"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# artificial_mask = obs_mask.copy()\n",
    "# artificial_mask = obs_mask & np.array(jrandom.bernoulli(jrandom.PRNGKey(0), p=0.75, shape=obs_mask.shape))\n"
   ],
   "id": "e2019e4dcf2755aa"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# obs_val.to_csv('missingness_data/missingness_vals.csv')\n",
    "# obs_mask.to_csv('missingness_data/missingness_mask.csv')\n",
    "# meta.to_csv('missingness_data/meta.csv')\n",
    "# artificial_mask.to_csv('missingness_data/missingness_artificial_mask.csv')\n"
   ],
   "id": "eb27be5e3596c64b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Later Loading",
   "id": "5bc60308e2170168"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "obs_val = pd.read_csv('missingness_data/missingness_vals.csv', index_col=[0])\n",
    "obs_mask = pd.read_csv('missingness_data/missingness_mask.csv', index_col=[0])\n",
    "artificial_mask = pd.read_csv('missingness_data/missingness_artificial_mask.csv', index_col=[0])\n",
    "meta = pd.read_csv('missingness_data/meta.csv', index_col=[0])\n"
   ],
   "id": "5339d9a6fd8794f0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Split",
   "id": "4645e4242e08b8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "split_ratio = 0.7\n",
    "seed = 0\n",
    "indices = jrandom.permutation(jrandom.PRNGKey(seed), len(obs_val))\n",
    "train_idx = indices[:int(split_ratio * len(indices))]\n",
    "test_idx = indices[int(split_ratio * len(indices)):]\n",
    "\n",
    "obs_val_train = jnp.array(obs_val.iloc[train_idx].to_numpy())\n",
    "obs_mask_train = jnp.array(obs_mask.iloc[train_idx].to_numpy())\n",
    "art_mask_train =  jnp.array(artificial_mask.iloc[train_idx].to_numpy())\n",
    "\n",
    "obs_val_test = jnp.array(obs_val.iloc[test_idx].to_numpy())\n",
    "obs_mask_test = jnp.array(obs_mask.iloc[test_idx].to_numpy())\n",
    "art_mask_test =  jnp.array(artificial_mask.iloc[test_idx].to_numpy())"
   ],
   "id": "884d5e5ca628ebe0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Model Configuration",
   "id": "636b80ea66a08f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# model = ICNNObsDecoder(observables_size=obs_mask.shape[1], state_size=0, \n",
    "#                        optax_optimiser_name='polyak_sgd',\n",
    "#                        hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "\n",
    "model = ProbStackedICNNImputer(observables_size=obs_mask.shape[1],\n",
    "                               state_size = 0,\n",
    "                               positivity='abs',\n",
    "                               optax_optimiser_name='polyak_sgd',\n",
    "                               hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "trainer = ProbICNNImputerTrainer(loss='kl_divergence')"
   ],
   "id": "6e499a4a500d1fe4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "f1bce3566d4dfecc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lr=1e-3\n",
    "steps=10000\n",
    "train_batch_size=256\n",
    "test_batch_size=1024\n",
    "# train_batch_size=1\n",
    "# test_batch_size=1\n",
    "eval_frequency = 10\n",
    "model_snapshot_frequency = 100\n",
    "\n",
    "optim = optax.novograd(lr)\n",
    "opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "data_train = (obs_val_train, obs_mask_train, art_mask_train)\n",
    "data_test = (obs_val_test, obs_mask_test, art_mask_test)"
   ],
   "id": "aab5f64f6bca26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_batches = trainer.dataloader(data_train, train_batch_size, key=jrandom.PRNGKey(0))\n",
    "test_batches = iter(trainer.dataloader(data_test, train_batch_size, key=jrandom.PRNGKey(0)))\n",
    "train_history = defaultdict(list)\n",
    "test_history = defaultdict(list)\n",
    "model_snapshots = {}"
   ],
   "id": "3ba3ad99d4d4be5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "progress = tqdm(range(steps))\n",
    "\n",
    "for step, batch_train in zip(progress, train_batches):\n",
    "    start = time.time()\n",
    "    (train_loss, train_aux), model, opt_state = trainer.make_step(model, optim, opt_state, *batch_train)\n",
    "    r2_vec =  trainer.model_r_squared(model, *batch_train)\n",
    "    r2_vec_rank = trainer.model_r_squared_ranked_prob(model, *batch_train, k=5)\n",
    "    r2_vec = np.array(r2_vec)\n",
    "    train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "    train_history['R2'].append(r2_vec)\n",
    "    train_history['R2_rank5'].append(r2_vec_rank)\n",
    "    train_history['loss'].append(train_loss)\n",
    "    train_history['n_opt_steps'].append(train_nsteps)\n",
    "    \n",
    "    end = time.time()\n",
    "    if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "        batch_test = next(test_batches)\n",
    "        test_loss, _ = trainer.loss(model, *batch_test)\n",
    "        r2_vec_test = trainer.model_r_squared(model, *batch_test)\n",
    "        r2_vec_rank_test = trainer.model_r_squared_ranked_prob(model, *batch_test, k=10)\n",
    "        r2_vec_test = np.array(r2_vec_test)\n",
    "        test_history['loss'].append(test_loss)\n",
    "        test_history['R2'].append(r2_vec_test)\n",
    "        test_history['R2_rank10'].append(r2_vec_rank_test)\n",
    "\n",
    "    if (step % model_snapshot_frequency) == 0 or step == steps - 1:\n",
    "        model_snapshots[step] = model\n",
    "\n",
    "    progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-R2: ({np.nanmax(r2_vec_rank):.2f}, {np.nanmin(r2_vec_rank):.2f}, {np.nanmean(r2_vec_rank):.2f}, {np.nanmedian(r2_vec_rank):.2f}),  Trn-N-steps: {train_nsteps}, \" \n",
    "                             f\"Tst-L:  {test_loss:.3f}, Tst-R2:  ({np.nanmax(r2_vec_rank_test):.2f}, {np.nanmin(r2_vec_rank_test):.2f}, {np.nanmean(r2_vec_rank_test):.2f}, {np.nanmedian(r2_vec_rank_test):.2f}), \"\n",
    "                             f\"Computation time: {end - start:.2f}, \")\n",
    "                            "
   ],
   "id": "8badc3e399696adc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "print('x')",
   "id": "62cf72ff69d61473"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_stats = pd.DataFrame(train_history)\n",
    "test_stats = pd.DataFrame(test_history)\n",
    "train_stats['split'] = 'Train'\n",
    "train_stats['iteration'] = train_stats.index + 1\n",
    "test_stats['split'] = 'Test'\n",
    "test_stats['iteration'] = (test_stats.index * eval_frequency) + 1\n",
    "stats = pd.concat([train_stats, test_stats])\n",
    "stats_melted = pd.melt(stats, value_vars=['loss'], id_vars=['split', 'iteration'], value_name='Loss')\n",
    "stats_melted = stats_melted.astype({'Loss': float})"
   ],
   "id": "a1eafbe59d3072f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import seaborn as sns\n",
    "g2 = sns.lineplot(data=stats_melted, x=\"iteration\", y=\"Loss\", hue=\"split\")\n",
    "g2.set(ylim=(-10., 10000.))\n"
   ],
   "id": "8cb351248b83416b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataframes = []\n",
    "for step, model_snap in tqdm(model_snapshots.items()):\n",
    "    with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "        obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "        (X_test_imp, X_test_std), _ = eqx.filter_vmap(model_snap.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "    \n",
    "    sigma_threshold = [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "    predicted_mask = (1 - art_mask_test) * obs_mask_test\n",
    "    r2_vec_thresholded = [eqx.filter_vmap(ProbICNNImputerTrainer.r_squared_thresholded_prob)(obs_val_test.T, X_test_imp.T, predicted_mask.T, X_test_std.T,  t)\n",
    "                          for t in sigma_threshold]\n",
    "    \n",
    "    r2_test_results = pd.DataFrame(np.vstack(r2_vec_thresholded), columns=obs_val.columns)\n",
    "    r2_test_results['sigma_threshold'] = sigma_threshold\n",
    "    r2_test_results['step'] = step\n",
    "    dataframes.append(r2_test_results)\n",
    "\n",
    "r2_test_results = pd.concat(dataframes)\n",
    "r2_test_results = pd.melt(r2_test_results, value_vars=list(obs_val.columns), id_vars=['sigma_threshold'], value_name='R2')"
   ],
   "id": "2c33421dfe003fa4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "33e31c04951a3646"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
