{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d59416-2f91-473a-8103-a3cd6343ac3d",
   "metadata": {},
   "source": [
    "# Libs Import\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c28bbb-0bea-4165-9bee-f54dad24ccc6",
   "metadata": {},
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from typing import Optional, Tuple, Literal\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom \n",
    "import jax.nn as jnn\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "jax.config.update('jax_platforms', 'cpu')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# jax.config.update('jax_check_tracer_leaks', True) \n",
    "sys.path.append(\"../../..\")\n",
    "from lib.ml.icnn_modules import ProbStackedICNNImputer, ImputerMetrics, ProbICNNImputerTrainer, ICNNObsDecoder, StandardICNNImputerTrainer\n",
    "import lib.ehr.example_datasets.mimiciv_aki as m4aki\n",
    "from lib.ehr.tvx_ehr import TVxEHR\n",
    "from lib.utils import modified_environ, write_config, append_params_to_zip, zip_members\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6026aa-f316-46f6-a762-804061ec8982",
   "metadata": {},
   "source": [
    "# ?pub_ready_plots.get_mpl_rcParams\n",
    "# !pip install pub-ready-plots"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47821903-74e5-4804-8668-3e3dab89b297",
   "metadata": {},
   "source": [
    "import pub_ready_plots\n",
    "from pub_ready_plots import get_mpl_rcParams\n",
    "rc_params, fig_width_in, fig_height_in = pub_ready_plots.get_mpl_rcParams(\n",
    "    width_frac=1,  # between 0 and 1\n",
    "    height_frac=0.2,  # between 0 and 1\n",
    "    layout=\"jmlr\"  # or \"iclr\", \"neurips\", \"poster-portrait\", \"poster-landscape\"\n",
    ")\n",
    "rc_params['figure.constrained_layout.use'] = True\n",
    "\n",
    "# rc_params['font.size'] = 10\n",
    "# rc_params['axes.titlesize'] = 12\n",
    "# rc_params['axes.labelsize'] = 10\n",
    "# rc_params['legend.fontsize'] = 10\n",
    "\n",
    "plt.rcParams.update(rc_params)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320f1e48-f072-4099-bc5e-6cc4dc90b31b",
   "metadata": {},
   "source": [
    "rc_params"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ae6b7608-1d1d-4f35-9610-1f49be0432af",
   "metadata": {},
   "source": [
    "# Experiment Defnitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0c2f80-ba34-4308-b6bc-5751b0f8730c",
   "metadata": {},
   "source": [
    "RESULTS_DIR = 'icnn_results_A'\n",
    "EXP_DIR = {\n",
    "    'ICNN_LN': 'experiment_snapshots_mimic_ProbStackedICNN_lognormal',\n",
    "    'ICNN_NLN': 'experiment_snapshots_mimic_ProbStackedICNN_lognormal_normalised',\n",
    "    'ICNN_KL': 'experiment_snapshots_mimic_ProbStackedICNN_kl',\n",
    "    'ICNN_NKL': 'experiment_snapshots_mimic_ProbStackedICNN_kl_normalised',    \n",
    "    'ICNN_MSE': 'experiment_snapshots_mimic_ProbStackedICNN_mse',\n",
    "    'ICNN_NMSE': 'experiment_snapshots_mimic_ProbStackedICNN_mse_normalised',\n",
    "}\n",
    "PROP_MODELS = ('ICNN_LN', 'ICNN_NLN', 'ICNN_KL', 'ICNN_NKL')\n",
    "DET_MODELS = ('ICNN_MSE', 'ICNN_NMSE')\n",
    "\n",
    "\n",
    "ICNN_RENAMES = {\n",
    "    'ICNN_LN': 'P-ICNN (LN)',\n",
    "    'ICNN_NLN': 'P-ICNN (NLN)',\n",
    "    'ICNN_KL': 'P-ICNN (KL)',\n",
    "    'ICNN_NKL': 'P-ICNN (NKL)',    \n",
    "    'ICNN_MSE': 'S-ICNN (MSE)',\n",
    "    'ICNN_NMSE': 'S-ICNN (NMSE)',\n",
    "}\n",
    "\n",
    "EXP = 'ICNN_NLN'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bedd275f-c187-456f-9624-228e685e2531",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda298bc-79e7-4631-863f-23c451fb883e",
   "metadata": {},
   "source": [
    "## First Time Loading and Writing to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8645d508-5ce0-4e81-a28b-b2b0dccf9644",
   "metadata": {},
   "source": [
    "# tvx = m4aki.TVxAKIMIMICIVDataset.load('/home/asem/GP/ehr-data/mimic4aki-cohort/tvx_aki.h5')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0cbf73a-2b16-4e1a-9128-f2877a9b954d",
   "metadata": {},
   "source": [
    "# obs = [adm.observables  for subject in tvx0.subjects.values() for adm in subject.admissions]\n",
    "# adm_id = sum(([adm.admission_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])\n",
    "# subj_id = sum(([subject.subject_id] * len(adm.observables.time)  for subject in tvx0.subjects.values() for adm in subject.admissions), [])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25b12a0-f4ed-40dd-bec6-9fef0e79caa6",
   "metadata": {},
   "source": [
    "# obs_val = np.vstack([obs_i.value for obs_i in obs])\n",
    "# obs_mask = np.vstack([obs_i.mask for obs_i in obs])\n",
    "# obs_time = np.hstack([obs_i.time for obs_i in obs])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c8afd5-475a-4a92-b73d-6e66243662cc",
   "metadata": {},
   "source": [
    "# tvx0.scheme.obs\n",
    "# features = list(map(tvx0.scheme.obs.desc.get, tvx0.scheme.obs.codes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b3e1440-1b1c-4fe6-806c-1839440ee716",
   "metadata": {},
   "source": [
    "# obs_val = pd.DataFrame(obs_val, columns=features)\n",
    "# obs_mask = pd.DataFrame(obs_mask.astype(int), columns=features)\n",
    "# meta = pd.DataFrame({'subject_id': subj_id, 'admission_id': adm_id, 'time': obs_time})\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a784503e-6175-43ab-8522-58447cf5e222",
   "metadata": {},
   "source": [
    "# artificial_mask = obs_mask.copy()\n",
    "# artificial_mask = obs_mask & np.array(jrandom.bernoulli(jrandom.PRNGKey(0), p=0.8, shape=obs_mask.shape))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28e3b288-d34d-4a43-8f79-98c5965ddb03",
   "metadata": {},
   "source": [
    "# obs_val.to_csv('missingness_data/missingness_vals.csv')\n",
    "# obs_mask.to_csv('missingness_data/missingness_mask.csv')\n",
    "# meta.to_csv('missingness_data/meta.csv')\n",
    "# artificial_mask.to_csv('missingness_data/missingness_artificial_mask.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "808916f3-e3ff-4239-a26b-d34631abd624",
   "metadata": {},
   "source": [
    "## Later Loading from Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9b42f56-270f-4e17-8c93-e79af7638e72",
   "metadata": {},
   "source": [
    "obs_val = pd.read_csv('missingness_data/missingness_vals.csv', index_col=[0])\n",
    "obs_mask = pd.read_csv('missingness_data/missingness_mask.csv', index_col=[0])\n",
    "artificial_mask = pd.read_csv('missingness_data/missingness_artificial_mask.csv', index_col=[0])\n",
    "meta = pd.read_csv('missingness_data/meta.csv', index_col=[0])\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1e678fa0-e9a7-4120-aba9-5c17792af3d7",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed9fabd6-6809-460f-a454-9572153c8299",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "split_ratio = 0.7\n",
    "seed = 0\n",
    "indices = jrandom.permutation(jrandom.PRNGKey(seed), len(obs_val))\n",
    "train_idx = indices[:int(split_ratio * len(indices))]\n",
    "test_idx = indices[int(split_ratio * len(indices)):]\n",
    "\n",
    "obs_val_train = jnp.array(obs_val.iloc[train_idx].to_numpy())\n",
    "obs_mask_train = jnp.array(obs_mask.iloc[train_idx].to_numpy())\n",
    "art_mask_train =  jnp.array(artificial_mask.iloc[train_idx].to_numpy())\n",
    "\n",
    "obs_val_test = jnp.array(obs_val.iloc[test_idx].to_numpy())\n",
    "obs_mask_test = jnp.array(obs_mask.iloc[test_idx].to_numpy())\n",
    "art_mask_test =  jnp.array(artificial_mask.iloc[test_idx].to_numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29554212-d63c-4770-892d-fbc66b2d01de",
   "metadata": {},
   "source": [
    "cooc = obs_mask.T.dot(obs_mask)\n",
    "cooc"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82d35d3f-3cb5-47df-8580-4ce74e545308",
   "metadata": {},
   "source": [
    "\n",
    "sns.heatmap(np.log10(cooc + 1))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c41bc77d-53b5-47c9-b9ea-1172bf807cbf",
   "metadata": {},
   "source": [
    "np.mean(obs_mask)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f86a6f9-0dff-4451-84a8-767c4b7171d7",
   "metadata": {},
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "p_mask = pd.DataFrame({'abundance': obs_mask.mean(axis=0)})\n",
    "\n",
    "\n",
    "# sns.kdeplot(data=p_mask, x=\"abundance\", log_scale=True)\n",
    "# sns.rugplot(data=p_mask, x=\"abundance\")\n",
    "sns.set_theme(style=\"ticks\")\n",
    "# sns.kdeplot(data=p_mask, x=\"abundance\", log_scale=True)\n",
    "g = sns.rugplot(data=p_mask, x=\"abundance\")\n",
    "g.set_xscale('log')\n",
    "\n",
    "sns.histplot(\n",
    "    p_mask,\n",
    "    x=\"abundance\", \n",
    "    edgecolor=\".3\",\n",
    "    linewidth=.5,\n",
    "    log_scale=True,\n",
    ")\n",
    "g.get_figure().set_size_inches(fig_width_in, fig_height_in * 1.5)\n",
    "g.get_figure().savefig(f\"{RESULTS_DIR}/features_abundance.pdf\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bafd8d9d-dbca-41b7-bce3-6f186af0d885",
   "metadata": {},
   "source": [
    "obs_mask.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c89b5fc4-7103-4100-84fd-d689ada680b0",
   "metadata": {},
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3439194b-9c52-4feb-9b8a-dec561659ffd",
   "metadata": {},
   "source": [
    "\n",
    "def models(e):\n",
    "    pmodels = {k: ProbStackedICNNImputer(observables_size=obs_mask.shape[1], state_size = 0, optax_optimiser_name='polyak_sgd',  \n",
    "                                         positivity='abs', hidden_size_multiplier=2, depth=4, key=jrandom.PRNGKey(0))\n",
    "               for k in PROP_MODELS}\n",
    "    dmodels =  {k: ICNNObsDecoder(observables_size=obs_mask.shape[1], state_size = 0, optax_optimiser_name='polyak_sgd',\n",
    "                                  positivity='abs', hidden_size_multiplier=3, depth=5, key=jrandom.PRNGKey(0)) \n",
    "                for k in DET_MODELS}\n",
    "    return (pmodels | dmodels)[e]\n",
    "    \n",
    "def trainers(e):\n",
    "    return {\n",
    "        'ICNN_LN': ProbICNNImputerTrainer(loss='log_normal'),\n",
    "        'ICNN_NLN': ProbICNNImputerTrainer(loss='log_normal', loss_feature_normalisation=True),\n",
    "        'ICNN_KL': ProbICNNImputerTrainer(loss='kl_divergence'),\n",
    "        'ICNN_NKL': ProbICNNImputerTrainer(loss='kl_divergence', loss_feature_normalisation=True),\n",
    "        'ICNN_MSE': StandardICNNImputerTrainer(),\n",
    "        'ICNN_NMSE': StandardICNNImputerTrainer(loss_feature_normalisation=True)\n",
    "    }[e]\n",
    "\n",
    "model = models(EXP)\n",
    "# trainer = trainers(EXP)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e32931-6d99-4286-b059-12a62c61358d",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcafbf5f-d168-4c7c-a217-b978da951f9a",
   "metadata": {},
   "source": [
    "## ICNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5a80153-56a6-4010-a3f8-0fcc51cce898",
   "metadata": {},
   "source": [
    "# lr=1e-3\n",
    "# steps=10000\n",
    "# train_batch_size=256\n",
    "# test_batch_size=1024\n",
    "# # train_batch_size=1\n",
    "# # test_batch_size=1\n",
    "# eval_frequency = 10\n",
    "# model_snapshot_frequency = 100\n",
    "\n",
    "# optim = optax.novograd(lr)\n",
    "# opt_state = optim.init(eqx.filter(model, eqx.is_inexact_array))\n",
    "# data_train = (obs_val_train, obs_mask_train, art_mask_train)\n",
    "# data_test = (obs_val_test, obs_mask_test, art_mask_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e9bc138-8411-4272-9f87-a7667dee68d4",
   "metadata": {},
   "source": [
    "# train_batches = trainer.dataloader(data_train, train_batch_size, key=jrandom.PRNGKey(0))\n",
    "# test_batches = iter(trainer.dataloader(data_test, train_batch_size, key=jrandom.PRNGKey(0)))\n",
    "# train_history = defaultdict(list)\n",
    "# test_history = defaultdict(list)\n",
    "# model_snapshots = {}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "667916bf-3ecb-49b2-84b2-fa701c4ddade",
   "metadata": {},
   "source": [
    "# progress = tqdm(range(steps))\n",
    "\n",
    "# for step, batch_train in zip(progress, train_batches):\n",
    "#     start = time.time()\n",
    "#     (train_loss, train_aux), model, opt_state = trainer.make_step(model, optim, opt_state, *batch_train)\n",
    "#     r2_vec =  trainer.model_r_squared(model, *batch_train)\n",
    "#     r2_vec_rank = trainer.model_r_squared_ranked_prob(model, *batch_train, k=5)\n",
    "#     r2_vec = np.array(r2_vec)\n",
    "#     train_nsteps = int(sum(train_aux.n_steps) / len(train_aux.n_steps))\n",
    "#     train_history['R2'].append(r2_vec)\n",
    "#     train_history['R2_rank5'].append(r2_vec_rank)\n",
    "#     train_history['loss'].append(train_loss)\n",
    "#     train_history['n_opt_steps'].append(train_nsteps)\n",
    "    \n",
    "#     end = time.time()\n",
    "#     if (step % eval_frequency) == 0 or step == steps - 1:\n",
    "#         batch_test = next(test_batches)\n",
    "#         test_loss, _ = trainer.loss(model, *batch_test)\n",
    "#         r2_vec_test = trainer.model_r_squared(model, *batch_test)\n",
    "#         r2_vec_rank_test = trainer.model_r_squared_ranked_prob(model, *batch_test, k=10)\n",
    "#         r2_vec_test = np.array(r2_vec_test)\n",
    "#         test_history['loss'].append(test_loss)\n",
    "#         test_history['R2'].append(r2_vec_test)\n",
    "#         test_history['R2_rank10'].append(r2_vec_rank_test)\n",
    "\n",
    "#     if (step % model_snapshot_frequency) == 0 or step == steps - 1:\n",
    "#         model_snapshots[step] = model\n",
    "#         append_params_to_zip(model, f'step{step:04d}.eqx', f'{EXP_DIR[EXP]}/params.zip')\n",
    "\n",
    "#     progress.set_description(f\"Trn-L: {train_loss:.3f}, Trn-R2: ({np.nanmax(r2_vec_rank):.2f}, {np.nanmin(r2_vec_rank):.2f}, {np.nanmean(r2_vec_rank):.2f}, {np.nanmedian(r2_vec_rank):.2f}),  Trn-N-steps: {train_nsteps}, \" \n",
    "#                              f\"Tst-L:  {test_loss:.3f}, Tst-R2:  ({np.nanmax(r2_vec_rank_test):.2f}, {np.nanmin(r2_vec_rank_test):.2f}, {np.nanmean(r2_vec_rank_test):.2f}, {np.nanmedian(r2_vec_rank_test):.2f}), \"\n",
    "#                              f\"Computation time: {end - start:.2f}, \")\n",
    "                            "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c557df37-73c9-407e-91d9-22f7f0049d83",
   "metadata": {},
   "source": [
    "# zip_members(f'{EXP_DIR}/params.zip')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3a6fd8da-08b1-4cd1-aed8-0e3bd3e05e0b",
   "metadata": {},
   "source": [
    "### Dump Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55fb9a75-66da-4c40-817c-ffc978260f33",
   "metadata": {},
   "source": [
    "# FIRST TIME - BEGIN \n",
    "\n",
    "# train_stats = pd.DataFrame(train_history)\n",
    "# test_stats = pd.DataFrame(test_history)\n",
    "\n",
    "# train_stats['split'] = 'Train'\n",
    "# train_stats['iteration'] = train_stats.index + 1\n",
    "# test_stats['split'] = 'Test'\n",
    "# test_stats['iteration'] = (test_stats.index * eval_frequency) + 1\n",
    "# training_stats = pd.concat([train_stats, test_stats])\n",
    "# training_stats_melted = pd.melt(training_stats, value_vars=['loss'], id_vars=['split', 'iteration'], value_name='Loss')\n",
    "# training_stats_melted = training_stats_melted.astype({'Loss': float})\n",
    "\n",
    "# training_stats.to_csv(f'{RESULTS_DIR}/{EXP}_training_stats.csv')  \n",
    "# training_stats_melted.to_csv(f'{RESULTS_DIR}/{EXP}_training_stats_melted.csv')  \n",
    "\n",
    "# FIRST TIME - END \n",
    "\n",
    "\n",
    "# LATER TIMES\n",
    "# training_stats = pd.read_csv(f'{RESULTS_DIR}/{EXP}_training_stats.csv', index_col=[0])  \n",
    "# training_stats_melted = pd.read_csv(f'{RESULTS_DIR}/{EXP}_training_stats_melted.csv', index_col=[0])  \n",
    "\n",
    "\n",
    "\n",
    "# g2 = sns.lineplot(data=training_stats_melted, x=\"iteration\", y=\"Loss\", hue=\"split\")\n",
    "# g2.get_figure().set_size_inches(fig_width_in, fig_height_in)\n",
    "# g2.get_figure().savefig(f\"{RESULTS_DIR}/{EXP}_training_stats.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "29eb079d-85a1-496a-90ef-33d1e80f1541",
   "metadata": {},
   "source": [
    "## Sklearn Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5569883-85ef-4376-87cb-a183073031e0",
   "metadata": {},
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer, KNNImputer, SimpleImputer\n",
    "\n",
    "sklearn_imputers =  {\n",
    "    'zero_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"constant\", fill_value=0),\n",
    "    'mean_imputer': lambda: SimpleImputer(missing_values=np.nan, add_indicator=False, strategy=\"mean\", fill_value=0),\n",
    "    'knn_imputer': lambda: KNNImputer(missing_values=np.nan),\n",
    "    'iter_imputer': lambda: IterativeImputer(\n",
    "        missing_values=np.nan,\n",
    "        add_indicator=False,\n",
    "        random_state=0,\n",
    "        n_nearest_features=5,\n",
    "        max_iter=5,\n",
    "        sample_posterior=True,\n",
    "    )\n",
    "}\n",
    "\n",
    "# sklearn_trained_imputers = {k: v().fit(np.where(obs_mask_train, obs_val_train, np.nan)) for k, v in sklearn_imputers.items()} "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c927aead-36dd-4806-ba36-99e5f1d3c74a",
   "metadata": {},
   "source": [
    "# Metrics / Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9da35ee-5429-492b-81e8-bb0a29273588",
   "metadata": {},
   "source": [
    "prediction_mask = (1 - art_mask_test) * obs_mask_test\n",
    "feature2index =  dict(zip(obs_val.columns, range(len(obs_val.columns))))\n",
    "n_train = ((1 - art_mask_train) * obs_mask_train).sum(axis=0)\n",
    "n_test = ((1 - art_mask_test) * obs_mask_test).sum(axis=0)\n",
    "n_train_measured = obs_mask_train.sum(axis=0)\n",
    "missingness = 1 - obs_mask.mean(axis=0)\n",
    "validation_missingness = 1 - pd.DataFrame(art_mask_test, columns=obs_mask.columns).mean(axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc7be4d1-41e2-4edd-a808-9610b7f2b949",
   "metadata": {},
   "source": [
    "n_test_censored = pd.Series(prediction_mask.sum(axis=0), index=obs_val.columns)\n",
    "p_test_censored = n_test_censored / len(prediction_mask)\n",
    "vars_n300 = n_test_censored[n_test_censored >= 300].index\n",
    "vars_n300_r = n_test_censored[n_test_censored < 300].index\n",
    "vars_n300, len(vars_n300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f2a091cb-8df8-4d80-9468-86d5678d02fa",
   "metadata": {},
   "source": [
    "variable_map = {'blood_chemistry.albumin': 'Albumin',  'blood_chemistry.aniongap': 'Aniongap',  \n",
    "                'blood_chemistry.bicarbonate': 'bc.Bicarbonate',  'blood_chemistry.bun': 'Urea Nitrogen', \n",
    "                'blood_chemistry.calcium': 'bc.Calcium',  'blood_chemistry.chloride': 'bc.Chloride',  \n",
    "                'blood_chemistry.creatinine': 'bc.Creatinine',  'blood_chemistry.globulin': 'Globulin',  \n",
    "                'blood_chemistry.glucose': 'bc.Glucose',  'blood_chemistry.potassium': 'bc.Potassium',  \n",
    "                'blood_chemistry.sodium': 'bc.Sodium',  'blood_chemistry.total_protein': 'Protein Total', \n",
    "                'blood_diff.atypical_lymphocytes': 'Atypical Lymphocytes',  'blood_diff.bands': 'Bands (%)',  \n",
    "                'blood_diff.basophils': 'Basophils',  'blood_diff.basophils_abs': 'Abs Basophils', \n",
    "                'blood_diff.eosinophils': 'Eosinophils',  'blood_diff.eosinophils_abs': 'Abs Eosinophils', \n",
    "                'blood_diff.immature_granulocytes': 'Immature Granulocytes',  'blood_diff.lymphocytes': 'Lymphocytes',\n",
    "                'blood_diff.lymphocytes_abs': 'Abs Lymphocytes',  'blood_diff.metamyelocytes': 'Metamyelocytes', \n",
    "                'blood_diff.monocytes': 'Monocytes',  'blood_diff.monocytes_abs': 'Abs Monocytes', \n",
    "                'blood_diff.neutrophils': 'Neutrophils',  'blood_diff.neutrophils_abs': 'Abs Neutrophil', \n",
    "                'blood_diff.nrbc': 'NRBC',  'blood_gas.aado2': 'AaDO2',  'blood_gas.aado2_calc': 'AaDO2_calc',\n",
    "                'blood_gas.baseexcess': 'Base excess',  'blood_gas.bicarbonate': 'bg.Bicarbonate',  'blood_gas.calcium': 'bg.Calcium',  \n",
    "                'blood_gas.carboxyhemoglobin': 'Carboxyhemoglobin',  'blood_gas.chloride': 'bg.Chloride',  'blood_gas.fio2': 'FiO2',  \n",
    "                'blood_gas.fio2_chartevents': 'FiO2_chartevents',  'blood_gas.glucose': 'bg.Glucose',  \n",
    "                'blood_gas.hematocrit': 'bg.Hematocrit',  'blood_gas.hemoglobin': 'bg.Hemoglobin',  'blood_gas.lactate': 'Lactate', \n",
    "                'blood_gas.methemoglobin': 'Methemoglobin',  'blood_gas.pao2fio2ratio': 'pO2/FiO2 ratio',  'blood_gas.pco2': 'pCO2',\n",
    "                'blood_gas.ph': 'pH',  'blood_gas.po2': 'pO2',  'blood_gas.potassium': 'bg.Potassium',  'blood_gas.so2': 'sO2', \n",
    "                'blood_gas.sodium': 'bg.Sodium',  'blood_gas.temperature': 'bg.Temperature',  'blood_gas.totalco2': 'CO2 total', \n",
    "                'cardiac_marker.ck_mb': 'Creatinine Kinase, MB',  'cardiac_marker.ntprobnp': 'NT-proBNP', \n",
    "                'cardiac_marker.troponin_t2': 'Troponin T',  'cbc.hematocrit': 'cbc.Hematocrit',  'cbc.hemoglobin': 'cbc.Hemoglobin', \n",
    "                'cbc.mch': 'MCH',  'cbc.mchc': 'MCHC',  'cbc.mcv': 'MCV',  'cbc.platelet': 'Platelet',  'cbc.rbc': 'RBC', \n",
    "                'cbc.rdw': 'RDW',  'cbc.wbc': 'WBC',  'coagulation.d_dimer': 'D-Dimer',  'coagulation.fibrinogen': 'Fibrinogen', \n",
    "                'coagulation.inr': 'INR',  'coagulation.pt': 'PT',  'coagulation.ptt': 'PTT',  'coagulation.thrombin': 'Thrombin',\n",
    "                'enzymes.alp': 'ALP',  'enzymes.alt': 'ALT',  'enzymes.amylase': 'Amylase',  'enzymes.ast': 'AST', \n",
    "                'enzymes.bilirubin_direct': 'Bilirubin direct',  'enzymes.bilirubin_indirect': 'Bilirubin indirect',\n",
    "                'enzymes.bilirubin_total': 'Bilirubin total',  'enzymes.ck_cpk': 'CK-CPK',  'enzymes.ck_mb':'CK-MB', \n",
    "                'enzymes.ggt': 'GGT',  'enzymes.ld_ldh': 'ld_ldh',  'icp.icp': 'Intra-cranial Press.',\n",
    "                'inflammation.crp': 'CRP',  'renal_aki.aki_binary': 'AKI (binary)',  'renal_aki.aki_stage_smoothed': 'AKI', \n",
    "                'renal_creat.creat': 'renal.Creatinine',  'renal_out.uo_rt_12hr': 'Urine out 12h',  'renal_out.uo_rt_24hr': 'Urine out 24h',\n",
    "                'renal_out.uo_rt_6hr': 'Urine out 6h',  'sofa.sofa_24hours': 'SOFA',  'vital.dbp': 'Diastolic BP', \n",
    "                'vital.dbp_ni': 'NI-Diastolic BP',  'vital.glucose': 'vital.Glucose',  'vital.heart_rate': 'Heart Rate',  \n",
    "                'vital.mbp':  'Mean BP',  'vital.mbp_ni': 'NI Mean BP',  'vital.resp_rate': 'Respiratory Rate', \n",
    "                'vital.sbp': 'Systolic BP',  'vital.sbp_ni':  'NI-Systolic BP',  'vital.spo2': 'SpO2',  \n",
    "                'vital.temperature': 'vital.Temperature',  'weight.weight': 'Weight'}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4e2e8839-9dab-4409-952a-4c0a67b9b64f",
   "metadata": {},
   "source": [
    "## Metrics Evolution with ICNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b7bd88-323c-4716-959a-7d2423c7fc85",
   "metadata": {},
   "source": [
    "# FIRST TIME - BEGIN \n",
    "\n",
    "# dataframes = []\n",
    "# for step, model_snap in tqdm(model_snapshots.items()):\n",
    "#     with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#         obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#         (X_test_imp, X_test_std), _ = eqx.filter_vmap(model_snap.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "    \n",
    "#     sigma_threshold = [4.0, 3.0, 2.5, 2.0, 1.5, 1.0, 0.5, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "#     r2_vec_thresholded = [eqx.filter_vmap(ProbICNNImputerTrainer.r_squared_thresholded_prob)(obs_val_test.T, X_test_imp.T, prediction_mask.T, X_test_std.T,  t)\n",
    "#                           for t in sigma_threshold]\n",
    "    \n",
    "#     r2_test_results = pd.DataFrame(np.vstack(r2_vec_thresholded), columns=obs_val.columns)\n",
    "#     r2_test_results['sigma_threshold'] = sigma_threshold\n",
    "#     r2_test_results['step'] = step\n",
    "#     dataframes.append(r2_test_results)\n",
    "\n",
    "# r2_iters_test_results = pd.concat(dataframes)\n",
    "# r2_iters_test_results = pd.melt(r2_iters_test_results, value_vars=list(obs_val.columns), id_vars=['sigma_threshold', 'step'], value_name='R2')\n",
    "\n",
    "# r2_iters_test_results.to_csv(f'{RESULTS_DIR}/{EXP}_r2_iters_test_results.csv')\n",
    "# FIRST TIME - END \n",
    "# r2_iters_test_results = pd.read_csv(f'{RESULTS_DIR}/{EXP}_r2_iters_test_results.csv', index_col=[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2312e999-64cf-49a5-a346-1eb934034609",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "409180ae-f0b9-408c-8203-50c344e05454",
   "metadata": {},
   "source": [
    "# r2_iters_test_results"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "02237fc8-9f6c-48c3-afe0-06d3ffe641eb",
   "metadata": {},
   "source": [
    "## Metrics of the Last ICNN Snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c43011-35a5-4845-b3a5-e7af9abe28ef",
   "metadata": {},
   "source": [
    "### Inference with Last ICNN Snapshot (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "019d2522-c9c6-4684-9dc4-a2cccd8df430",
   "metadata": {},
   "source": [
    "# FIRST TIME - BEGIN \n",
    "# model = model.load_params_from_archive(f'{EXP_DIR[EXP]}/params.zip', 'step9999.eqx')\n",
    "# with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "#     obs_test = jnp.where(art_mask_test, obs_val_test, 0.)\n",
    "#     (X_test_imp, X_test_std), _ = eqx.filter_vmap(model.prob_partial_input_optimise)(obs_test, art_mask_test)\n",
    "\n",
    "# X_test_imp_df = pd.DataFrame(X_test_imp, columns=obs_val.columns)\n",
    "# X_test_std_df = pd.DataFrame(X_test_std, columns=obs_val.columns)\n",
    "\n",
    "# X_test_imp_df.to_csv(f'{RESULTS_DIR}/{EXP}_pred_X_test_imp.csv')\n",
    "# X_test_std_df.to_csv(f'{RESULTS_DIR}/{EXP}_pred_X_test_std.csv')\n",
    "# FIRST TIME - END "
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4c9cdcc2-5454-4d10-a53c-d7a7ca2b719c",
   "metadata": {},
   "source": [
    "### Ablation Study - Optimiser / max_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af5499a3-d864-4d1d-9517-cc778b4aa47c",
   "metadata": {},
   "source": [
    "# FIRST TIME - BEGIN \n",
    "model =  models(EXP)#model.load_params_from_archive(f'{EXP_DIR[EXP]}/params.zip', 'step9999.eqx')\n",
    "\n",
    "sample_index = jrandom.choice(jrandom.PRNGKey(42), a=len(art_mask_test), shape=(500,))\n",
    "sample_obs_test = jnp.where(art_mask_test[sample_index], obs_val_test[sample_index], 0.)\n",
    "sample_art_mask_test = art_mask_test[sample_index]\n",
    "energy0 = eqx.filter_vmap(model.energy0)(sample_obs_test, sample_art_mask_test)\n",
    "\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    energy = {}\n",
    "    for opt in tqdm(('adam', \n",
    "                'polyak_sgd', \n",
    "                'lamb', \n",
    "               ), leave=False):\n",
    "        for lr in tqdm((1e-1, 1e-2, 1e-3, 1e-4), leave=False):\n",
    "            for max_steps_exp in tqdm((4, 5, 6, 7, 8, 9, 10, 11), leave=False):\n",
    "                model = eqx.tree_at(lambda m: m.optax_optimiser_name, model, opt)\n",
    "                _, stats = eqx.filter_vmap(lambda x, m: model.prob_partial_input_optimise(x, m, max_steps=2**max_steps_exp))(sample_obs_test, sample_art_mask_test)\n",
    "                energy[(opt, lr, max_steps_exp)] = stats.energy\n",
    "\n",
    "data = defaultdict(list)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e008c232-397a-4143-8d07-54753ec43a03",
   "metadata": {},
   "source": [
    "for (opt, lr, max_steps_exp), energy_vec in energy.items():\n",
    "    data['opt'].extend([opt] * len(energy_vec))\n",
    "    data['max_steps_exp'].extend([max_steps_exp] * len(energy_vec))\n",
    "    data['lr'].extend([lr] * len(energy_vec))\n",
    "    data['E'].extend((energy_vec).tolist())\n",
    "    data['delta_E'].extend((energy0 - energy_vec).tolist())\n",
    "\n",
    "energy_df = pd.DataFrame(data)\n",
    "energy_df['max_steps'] = 2 ** energy_df['max_steps_exp']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0c9b2a6-091a-47c5-a5fb-b8baa9a8b96d",
   "metadata": {},
   "source": [
    "energy_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a9af8479-ccab-4e1f-a9ac-e0c1cf16f792",
   "metadata": {},
   "source": [
    "energy_df = pd.read_csv('delta_E_nmse_step9999.csv')\n",
    "# energy_df = pd.read_csv('delta_E_untrained.csv')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "96846d94-54fc-4812-b0b4-7f7a4be6b512",
   "metadata": {},
   "source": [
    "sns.lineplot(\n",
    "    data=energy_df, x=\"max_steps_exp\", y=\"delta_E\", hue=\"opt\", err_style=\"bars\", errorbar=(\"se\", 2),\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50f17b26-1b42-4cda-983c-4d1fbf5eac81",
   "metadata": {},
   "source": [
    "energy_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdb005bf-3334-4a66-bb36-be38150e2e1c",
   "metadata": {},
   "source": [
    "grid = sns.FacetGrid(data=X_test_se_df_selection, col=\"group\", sharex=False, sharey=False, col_wrap=2,  )\n",
    "\n",
    "grid.map_dataframe(sns.boxplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "                   showmeans=True, meanprops={'marker':'o','markerfacecolor':'white','markeredgecolor':'black','markersize':'5'},\n",
    "                    # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "                    showfliers=False,\n",
    "                    fill=False,\n",
    "                     gap=0.5)\n",
    "\n",
    "# grid.map_dataframe(sns.boxenplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "#                     # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "#                     showfliers=False,\n",
    "#                     fill=False,\n",
    "#                      gap=0.5)\n",
    "\n",
    "grid.add_legend()\n",
    "grid.figure.set_size_inches(fig_width_in * 1.5, fig_height_in * 3)\n",
    "grid.savefig(f\"{RESULTS_DIR}/X_test_se_df_selection.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2f0156ca-10be-473d-b45a-b34c0de0225f",
   "metadata": {},
   "source": [
    "### Load ICNN Inference from Disk (one-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c537ca0-2502-4e12-81bd-0c9a3d865fd0",
   "metadata": {},
   "source": [
    "vars_n300"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e11619b1-f825-47c7-bc91-1387fc37d421",
   "metadata": {},
   "source": [
    "all_models_X_test_imp_df = {}\n",
    "prob_models_X_test_std_df = {}\n",
    "prob_models_X_var_stats_df = []\n",
    "all_models_X_test_se = []\n",
    "all_models_features_stats_df = []\n",
    "all_models_stats_df = []\n",
    "PERCENTILES = (95, 90, 80, 70, 60, 50, 25, 10)\n",
    "\n",
    "for model_name in list(EXP_DIR.keys()) + list(sklearn_imputers.keys()):\n",
    "    x_file = f'{RESULTS_DIR}/{model_name}_pred_X_test_imp.csv'\n",
    "    s_file = f'{RESULTS_DIR}/{model_name}_pred_X_test_std.csv'\n",
    "    if os.path.isfile(x_file):\n",
    "        X_test_imp_ = pd.read_csv(x_file, index_col=[0])\n",
    "        all_models_X_test_imp_df[model_name] = X_test_imp_\n",
    "\n",
    "        # Squared-Errors (per instance)\n",
    "        X_test_se_ = (X_test_imp_ - np.array(obs_val_test))**2\n",
    "        X_test_se_ = X_test_se_.where(prediction_mask.astype(bool), other=np.nan)\n",
    "        X_test_se_ = pd.melt(X_test_se_, value_vars=list(obs_val.columns), value_name='SE')\n",
    "        X_test_se_ = X_test_se_[X_test_se_.SE.notnull()]\n",
    "        X_test_se_['Imputer'] = model_name\n",
    "        all_models_X_test_se.append(X_test_se_)\n",
    "\n",
    "\n",
    "    if os.path.isfile(s_file):\n",
    "        X_test_std_ = pd.read_csv(s_file, index_col=[0])\n",
    "        prob_models_X_test_std_df[model_name] = X_test_std_\n",
    "        \n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), X_test_std_ ** 2, np.nan)\n",
    "        SE_ = (all_models_X_test_imp_df[model_name] - np.array(obs_val_test)) ** 2\n",
    "        SE_ = np.where(prediction_mask.astype(bool), SE_, np.nan)\n",
    "        se_data_ = defaultdict(list)\n",
    "        for i in range(SE_.shape[1]):\n",
    "            se_data_['SE'].extend(np.array(SE_[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "            se_data_[r'$\\hat{\\sigma}^2$'].extend(np.array(X_test_var_[:, i][prediction_mask[:, i].astype(bool)]).tolist())\n",
    "            se_data_['Feature'].extend([obs_val.columns[i]] * int(prediction_mask[:, i].sum()))\n",
    "        se_df_ = pd.DataFrame(se_data_)\n",
    "        se_df_['Imputer'] = model_name\n",
    "        \n",
    "        prob_models_X_var_stats_df.append(se_df_)\n",
    "\n",
    "    if model_name not in all_models_X_test_imp_df:\n",
    "        continue\n",
    "\n",
    "    # R2/MSE (per feature)\n",
    "    X_test_imp_ = jnp.array(all_models_X_test_imp_df[model_name])\n",
    "    features_r2_ = eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, X_test_imp_.T, prediction_mask.T)\n",
    "    se_ = (np.array(all_models_X_test_imp_df[model_name]) - np.array(obs_val_test)) ** 2\n",
    "    mse_ = np.nanmean(se_, axis=0, where=prediction_mask.astype(bool))\n",
    "    features_stats_df_ = pd.DataFrame({r'$R^2$': np.array(features_r2_), \n",
    "                                       'MSE': mse_,\n",
    "                                       'Feature': all_models_X_test_imp_df[model_name].columns,\n",
    "                                       'Imputer': [model_name] * len(mse_)})\n",
    "\n",
    "    # r_spearman(SE, sigma2) (per feature)\n",
    "    if model_name in prob_models_X_test_std_df:\n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), prob_models_X_test_std_df[model_name] ** 2, np.nan)\n",
    "        features_stats_df_[r'$r_\\text{Spearman}(SE, \\hat{\\sigma}^2)$'] = [spearmanr(se_i[mi], sigma2_i[mi]).statistic\n",
    "                                                 for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T)]\n",
    "        features_stats_df_[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(se_i[mi], sigma2_i[mi]).statistic if mi.sum() > 2 else float('nan')\n",
    "                                                 for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T) ]\n",
    "\n",
    "        features_stats_df_[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(np.log(se_i[mi]), np.log(sigma2_i[mi])).statistic if mi.sum() > 2 else float('nan')\n",
    "                                         for se_i, sigma2_i, mi in zip(se_.T, X_test_var_.T, prediction_mask.astype(bool).T) ]\n",
    "\n",
    "        # After Transpose, shape: (N_percentiles, n_features)\n",
    "        features_percentiles = np.vstack([np.percentile(sigma2_i[mi], PERCENTILES)  for (sigma2_i, mi) in zip(X_test_var_.T, prediction_mask.astype(bool).T)]).T\n",
    "\n",
    "        for percent, percentile in zip(PERCENTILES, features_percentiles):\n",
    "            prediction_mask_p = np.vstack([mi * (sigma2_i <= p_i) for \n",
    "                                           (p_i, sigma2_i, mi) in zip(percentile, X_test_var_.T, prediction_mask.astype(bool).T)]).T\n",
    "            features_stats_df_[rf'$R^2@P{percent}$'] = np.array(eqx.filter_vmap(ProbICNNImputerTrainer.r_squared)(obs_val_test.T, X_test_imp_.T, prediction_mask_p.T)).squeeze()\n",
    "            features_stats_df_[f'MSE@P{percent}'] = np.nanmean(se_, axis=0, where=prediction_mask_p).squeeze()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    all_models_features_stats_df.append(features_stats_df_)\n",
    "\n",
    "    # R2/MSE (per model)\n",
    "    features_stats_300_df = features_stats_df_[features_stats_df_.Feature.isin(vars_n300)]\n",
    "    weighted_avg_R2 = np.average(features_stats_300_df[r'$R^2$'], \n",
    "                                 weights=features_stats_300_df['Feature'].map(n_test_censored))\n",
    "    \n",
    "    model_stats_df_ = pd.DataFrame({'Imputer': [model_name],\n",
    "                                    'MSE': [np.nanmean(se_, where=prediction_mask.astype(bool))],\n",
    "                                    r'$R^2$': [ProbICNNImputerTrainer.r_squared(obs_val_test, X_test_imp_, prediction_mask).item()],\n",
    "                                    r'MICRO-AVG($R^2$)': [ProbICNNImputerTrainer.r_squared_micro_average(obs_val_test, X_test_imp_, prediction_mask).item()],\n",
    "                                    r'MACRO-AVG($R^2$)*': [features_stats_300_df[r'$R^2$'].mean()]})\n",
    "\n",
    "    # corr(SE, sigma2) (per model)\n",
    "    if model_name in prob_models_X_test_std_df:\n",
    "        X_test_var_ = np.where(prediction_mask.astype(bool), prob_models_X_test_std_df[model_name] ** 2, np.nan).flatten()\n",
    "        m_ = prediction_mask.astype(bool).flatten()\n",
    "        model_stats_df_[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(se_.flatten()[m_], X_test_var_[m_]).statistic]\n",
    "        model_stats_df_[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'] = [pearsonr(np.log(se_.flatten()[m_]), np.log(X_test_var_[m_])).statistic]\n",
    "\n",
    "        model_stats_df_[r'$r_\\text{Spearman}(SE, \\hat{\\sigma}^2)$'] = [spearmanr(se_.flatten()[m_], X_test_var_[m_]).statistic]\n",
    "    all_models_stats_df.append(model_stats_df_)\n",
    "    \n",
    "all_models_X_test_se = pd.concat(all_models_X_test_se)\n",
    "prob_models_X_var_stats_df = pd.concat(prob_models_X_var_stats_df)\n",
    "all_models_features_stats_df = pd.concat(all_models_features_stats_df)\n",
    "all_models_stats_df = pd.concat(all_models_stats_df)\n",
    "\n",
    "prob_models_X_var_stats_df['LN'] = prob_models_X_var_stats_df['SE'] / prob_models_X_var_stats_df[r'$\\hat{\\sigma}^2$'] + np.log(prob_models_X_var_stats_df[r'$\\hat{\\sigma}^2$'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3d043a7-5612-4ba9-ac40-5825d3a071a0",
   "metadata": {},
   "source": [
    "# all_models_features_stats_df\n",
    "features_LN = prob_models_X_var_stats_df.groupby(['Imputer', 'Feature'])['LN'].mean()\n",
    "all_models_features_stats_df = all_models_features_stats_df.set_index(['Imputer', 'Feature'])\n",
    "all_models_features_stats_df.loc[features_LN.index, 'LN'] = features_LN\n",
    "all_models_features_stats_df = all_models_features_stats_df.reset_index()\n",
    "all_models_features_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802a9099-ee2a-44e4-94cb-1151f518c76b",
   "metadata": {},
   "source": [
    "models_LN = prob_models_X_var_stats_df.groupby(['Imputer'])['LN'].mean()\n",
    "all_models_stats_df = all_models_stats_df.set_index('Imputer')\n",
    "all_models_stats_df.loc[models_LN.index, 'LN'] = models_LN\n",
    "all_models_stats_df = all_models_stats_df.reset_index()\n",
    "all_models_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9df03394-8acb-4846-8c41-f3d6f922de6c",
   "metadata": {},
   "source": [
    "prob_models_X_var_stats_df.groupby(['Imputer'])['LN'].mean()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2c74ebb-16b9-444f-a336-4e05e0a7c34a",
   "metadata": {},
   "source": [
    "all_models_features_stats_df.Imputer.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "02b08d3c-9a9b-4de5-b8ae-36edf08eb137",
   "metadata": {},
   "source": [
    "p_abundance = obs_mask.mean(axis=0)\n",
    "for name, model_df in all_models_features_stats_df.groupby('Imputer'):\n",
    "    df = model_df[model_df.Feature.isin(vars_n300)]\n",
    "    stat = spearmanr(df[r'$R^2$'], df.Feature.map(p_abundance)).statistic\n",
    "    loc = all_models_stats_df.Imputer == name\n",
    "    all_models_stats_df.loc[loc, r'$r_\\text{Spearman}(R^2, \\text{abundance})$'] = stat\n",
    "    "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6bc065d-9271-4585-880c-15528fa9c758",
   "metadata": {},
   "source": [
    "all_models_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "471ab510-ca1d-4d6b-833e-67d1b5fd2c1b",
   "metadata": {},
   "source": [
    "all_models_features_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7fa41071-d0ef-456d-bd4a-96553488de6a",
   "metadata": {},
   "source": [
    "r_classes = [r'$r > 0.3$', r'$r \\in [0.1, 0.3]$', r'$r \\in [-0.1, 0.1]$', r'$r \\leq -0.1$']\n",
    "R_classes = [r'$R^2 > 0.25$', r'$R^2 \\in (0.1, 0.25]$', r'$R^2 \\in [-0.1, 0.1]$', r'$R^2 \\in (-1, -0.1]$',  r'$R^2 \\in (-9, -1]$', r'$R^2 < -9$']\n",
    "def classify_r(r):\n",
    "    if r > 0.3:\n",
    "        return r_classes[0]\n",
    "    elif r > 0.1:\n",
    "        return r_classes[1]\n",
    "    elif r >= -0.1:\n",
    "        return r_classes[2]\n",
    "    elif r < -0.1:\n",
    "        return r_classes[3]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "def classify_R(R):\n",
    "    if R > 0.25:\n",
    "        return R_classes[0]\n",
    "    elif R > 0.1:\n",
    "        return R_classes[1]\n",
    "    elif R >= -0.1:\n",
    "        return R_classes[2]\n",
    "    elif R >= -1:\n",
    "        return R_classes[3] \n",
    "    elif R >= -9:\n",
    "        return R_classes[4]\n",
    "    elif R < -9:\n",
    "        return R_classes[5]\n",
    "    else:\n",
    "        return 'NA'\n",
    "\n",
    "all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'] = all_models_features_stats_df[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'].map(classify_r)\n",
    "all_models_features_stats_df[r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin'] = all_models_features_stats_df[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'].map(classify_r)\n",
    "\n",
    "all_models_features_stats_df[r'$R^2$ bin'] = all_models_features_stats_df[r'$R^2$'].map(classify_R)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7650b13f-ca3d-45a5-ac67-36c6f4380659",
   "metadata": {},
   "source": [
    "for p in PERCENTILES:\n",
    "    all_models_features_stats_df[rf'$R^2@P{p}$ bin'] = all_models_features_stats_df[rf'$R^2@P{p}$'].map(classify_R)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "07c93709-d683-4986-940d-66199b086a25",
   "metadata": {},
   "source": [
    "all_models_features_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "eaa604c5-4e85-409d-8a2d-f312aa5d6333",
   "metadata": {},
   "source": [
    "len(vars_n300)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20204760-6eb4-4612-9a56-8462105c1be6",
   "metadata": {},
   "source": [
    "prob_models_features_stats_df = all_models_features_stats_df[all_models_features_stats_df[r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'].notnull()]\n",
    "prob_models_features_stats_df = prob_models_features_stats_df[prob_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "\n",
    "prob_models_features_stats_df['Imputer'] = prob_models_features_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "\n",
    "r_bins = prob_models_features_stats_df.groupby(['Imputer', r'$r(SE, \\hat{\\sigma}^2)$ bin'])['Feature'].count().reset_index()\n",
    "r_bins.columns = ['Imputer', r'$r(SE, \\hat{\\sigma}^2)$ bin', 'Count']\n",
    "r_bins = r_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$r(SE, \\hat{\\sigma}^2)$ bin')\n",
    "\n",
    "\n",
    "ax = r_bins.plot(y=r_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 1.2, fig_height_in)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/prob_icnn_r_bins.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a74f256b-4cd5-496c-bcfc-0ac5eb4d85e6",
   "metadata": {},
   "source": [
    "# prob_models_features_stats_df = all_models_features_stats_df[all_models_features_stats_df[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$'].notnull()]\n",
    "# prob_models_features_stats_df = prob_models_features_stats_df[prob_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "\n",
    "# prob_models_features_stats_df['Imputer'] = prob_models_features_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "\n",
    "# r_bins = prob_models_features_stats_df.groupby(['Imputer', r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin'])['Feature'].count().reset_index()\n",
    "# r_bins.columns = ['Imputer', r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin', 'Count']\n",
    "# r_bins = r_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin')\n",
    "\n",
    "\n",
    "# ax = r_bins.plot(y=r_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "# _ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "# ax.get_figure().set_size_inches(fig_width_in * 1.2, fig_height_in)\n",
    "# ax.get_figure().savefig(f\"{RESULTS_DIR}/prob_icnn_r_bins.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ea4c32b-7c97-4218-96f7-8f384c66bc0f",
   "metadata": {},
   "source": [
    "table_ablation0 = all_models_stats_df.copy()\n",
    "\n",
    "table_ablation0['Imputer'] = all_models_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "ablation_models = [m for m in table_ablation0.Imputer.unique() if m == m and  m.startswith('P-ICNN')]\n",
    "\n",
    "table_ablation0 = table_ablation0.set_index('Imputer').loc[ablation_models,  ['MSE', r'MICRO-AVG($R^2$)',  r'MACRO-AVG($R^2$)*', 'LN', r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$'] ].transpose()\n",
    "table_ablation0.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table_ablation0.columns))\n",
    "table_ablation0.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table_ablation0.columns))\n",
    "table_ablation0.columns.name = 'Imputer'\n",
    "table_ablation0 = table_ablation0.sort_values('MSE', ascending=False, axis=1)\n",
    "table_ablation0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ee899428-2bc1-4c90-8c5f-4b20ce16ac81",
   "metadata": {},
   "source": [
    "table_stl_ablation0 = (table_ablation0.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'$R^2$'], :])\n",
    "              # .background_gradient(cmap='RdYlGn_r', axis=1,  low=0.08, high=0.110,  vmin=0.08, vmax=0.110, subset= pd.IndexSlice[['MSE'], :])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table_stl_ablation0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "53af7d18-5d7f-4f64-b65f-6cc7c9d248e7",
   "metadata": {},
   "source": [
    "table_ltx_ablation0 = (table_stl_ablation0.to_latex(caption=r\"Ablation study on the effect of the probabilistic loss function choice on the performance of \"\n",
    "                                                    r\"\\texttt{P-ICNN} models. The estimations are made on the validation split.\"\n",
    "                                                    r\"For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in the test split are excluded, \"\n",
    "                                                    r\"of which some have $-\\infty$ values. \"\n",
    "                                                    r\" $r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$ is the correlation between the prediction \\gls*{se} and the predicted variance (the higher the better).\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table_ltx_ablation0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "114658a7-01ec-4492-b283-b01916374643",
   "metadata": {},
   "source": [
    "table_ablation1 = all_models_stats_df.copy()\n",
    "\n",
    "table_ablation1['Imputer'] = all_models_stats_df['Imputer'].map(ICNN_RENAMES)\n",
    "ablation_models = [m for m in table_ablation1.Imputer.unique() if m == m and  m.startswith('S-ICNN')]\n",
    "\n",
    "table_ablation1 = table_ablation1.set_index('Imputer').loc[ablation_models,  ['MSE', r'MICRO-AVG($R^2$)', r'MACRO-AVG($R^2$)*'] ].transpose()\n",
    "table_ablation1.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table_ablation1.columns))\n",
    "table_ablation1.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table_ablation1.columns))\n",
    "table_ablation1.columns.name = 'Imputer'\n",
    "table_ablation1 = table_ablation1.sort_values('MSE', ascending=False, axis=1)\n",
    "table_ablation1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3b079eec-c4b7-4551-8e22-47ba88f67b32",
   "metadata": {},
   "source": [
    "table_stl_ablation1 = (table_ablation1.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'$R^2$'], :])\n",
    "              # .background_gradient(cmap='RdYlGn_r', axis=1,  low=0.08, high=0.110,  vmin=0.08, vmax=0.110, subset= pd.IndexSlice[['MSE'], :])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table_stl_ablation1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d1a455b6-4c7a-4b52-9ec0-1ac74ba2b9c0",
   "metadata": {},
   "source": [
    "table_ltx_ablation1 = (table_stl_ablation1.to_latex(caption=r\"Ablation study on the effect of the loss function choice on the performance of \\texttt{S-ICNN} models. \"\n",
    "                                                    r\"First row: \\gls*{mse} loss across all features on the test split. Second and third rows list the micro and macro average of $R^2$ \"\n",
    "                                                    r\"(higher is better), respectively. For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in the test split are excluded, \"\n",
    "                                                    r\"of which some have $-\\infty$ values.\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table_ltx_ablation1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cb1e4321-ad39-4ec1-bef3-2f98b835fa65",
   "metadata": {},
   "source": [
    "S_ICNN = ('ICNN_NMSE', )\n",
    "P_ICNN = ('ICNN_NKL', 'ICNN_NLN')\n",
    "# P_ICNN_RENAME = {'ICNN_NKL': 'ICNN (KL)', \n",
    "#                  'ICNN_NLN': 'ICNN (LN)'}\n",
    "\n",
    "final_models_X_test_se = all_models_X_test_se[((all_models_X_test_se.Imputer.str.count('ICNN') == 0) | \n",
    "                                               (all_models_X_test_se.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "\n",
    "final_models_features_stats_df = all_models_features_stats_df[((all_models_features_stats_df.Imputer.str.count('ICNN') == 0) |\n",
    "                                                               (all_models_features_stats_df.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "final_models_stats_df = all_models_stats_df[((all_models_stats_df.Imputer.str.count('ICNN') == 0) |\n",
    "                                             (all_models_stats_df.Imputer.isin(S_ICNN + P_ICNN)))]\n",
    "\n",
    "for df in (final_models_X_test_se, final_models_features_stats_df, final_models_stats_df):\n",
    "    df['Imputer'] = df['Imputer'].replace(ICNN_RENAMES)   \n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a047382-5028-4aae-a51c-711b33612009",
   "metadata": {},
   "source": [
    "final_models_stats_df.Imputer.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a6c97e3b-bff6-4af5-871f-8758e72ddc52",
   "metadata": {},
   "source": [
    "## Metrics of Sklearn Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "46f68045-44c3-4aa7-8e12-52369f86245e",
   "metadata": {},
   "source": [
    "# FIRST TIME - BEGIN \n",
    "# sklearn_imputed_X = {k: v.transform(np.where(art_mask_test, obs_val_test, np.nan)) for k, v in sklearn_trained_imputers.items()} \n",
    "# for sklearn_name, imputed_X_ in sklearn_imputed_X.items():\n",
    "#     X_test_imp_df = pd.DataFrame(imputed_X_, columns=obs_val.columns)    \n",
    "#     X_test_imp_df.to_csv(f'{RESULTS_DIR}/{sklearn_name}_pred_X_test_imp.csv')\n",
    "# FIRST TIME - END "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e28fb030-0384-4e69-be55-44cf95715081",
   "metadata": {},
   "source": [
    "all_models_X_test_se.Imputer.unique()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7c4b03ef-3daf-420e-bac6-7876f7ec3d2f",
   "metadata": {},
   "source": [
    "final_models_X_test_se['group'] = final_models_X_test_se.variable.str.split('.').map(lambda x: x[0])\n",
    "final_models_X_test_se['Feature'] = final_models_X_test_se.variable.map(variable_map)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7d686d2d-3c52-4761-b610-b6297f381fbb",
   "metadata": {},
   "source": [
    "groups = final_models_X_test_se['group'].unique().tolist()\n",
    "groups"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e48bdbbe-e6ac-4a7f-b1ec-83c03b30b07a",
   "metadata": {},
   "source": [
    "# enzymes (except Amylase, Bilirubin indirect, CK-CPK)\n",
    "# renal_creat\n",
    "# renal_aki\n",
    "# renal_out\n",
    "# sofa\n",
    "\n",
    "X_test_se_df_selection = final_models_X_test_se[final_models_X_test_se.group.isin(['renal_out', 'renal_creat', 'renal_aki', 'sofa'])]\n",
    "\n",
    "grid = sns.FacetGrid(data=X_test_se_df_selection, col=\"group\", sharex=False, sharey=False, col_wrap=2,  )\n",
    "\n",
    "grid.map_dataframe(sns.boxplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "                   showmeans=True, meanprops={'marker':'o','markerfacecolor':'white','markeredgecolor':'black','markersize':'5'},\n",
    "                    # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "                    showfliers=False,\n",
    "                    fill=False,\n",
    "                     gap=0.5)\n",
    "\n",
    "# grid.map_dataframe(sns.boxenplot, x=\"SE\", y=\"Feature\", hue=\"Imputer\", dodge=True,  palette=\"Set2\",#hue=\"Imputer\",\n",
    "#                     # line_kws=dict(linewidth=1.5, color=\"#cde\"),\n",
    "#                     showfliers=False,\n",
    "#                     fill=False,\n",
    "#                      gap=0.5)\n",
    "\n",
    "grid.add_legend()\n",
    "grid.figure.set_size_inches(fig_width_in * 1.5, fig_height_in * 3)\n",
    "grid.savefig(f\"{RESULTS_DIR}/X_test_se_df_selection.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2e79f9b-9f9a-42c4-97a1-45660c73defd",
   "metadata": {},
   "source": [
    "\n",
    "all_models_features_stats_df['abundance'] = all_models_features_stats_df.Feature.map(p_abundance)\n",
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[:2]) &\n",
    "                             all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:2]))]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6cf9801-1f7a-425b-a2ce-2ef2b85a5be6",
   "metadata": {},
   "source": [
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[:2]) &\n",
    "                             all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[2:]))]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6e8b646a-1aa6-40c6-b3ae-27bd7fc0d4f4",
   "metadata": {},
   "source": [
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                              # all_models_features_stats_df[r'$R^2$ bin'].isin(R_classes[1:]) &\n",
    "                             all_models_features_stats_df[r'$r_\\text{log}(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:1]) &\n",
    "                              (all_models_features_stats_df['LN'] < 0))\n",
    "]\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b0b56500-0949-4b45-b3bb-b0730f48350e",
   "metadata": {},
   "source": [
    "# TODO: For each feature, exclude the points on the upper part of uncertainty, then recompute the metrics again."
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3577762a-2d96-4082-9010-942933934a52",
   "metadata": {},
   "source": [
    "final_models_stats_df.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28b9a40-0c3e-4b0c-8385-5347f3859f2c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b7429abd-f196-433d-9f22-e0a8c3b8e4d2",
   "metadata": {},
   "source": [
    "table0 = final_models_stats_df[['Imputer', 'MSE', r'MICRO-AVG($R^2$)', r'MACRO-AVG($R^2$)*']].set_index('Imputer').transpose()\n",
    "table0 = table0[['P-ICNN (NLN)', 'S-ICNN (NMSE)', 'zero_imputer', 'mean_imputer', 'knn_imputer', 'iter_imputer']]\n",
    "table0.columns = ['P-ICNN', 'S-ICNN', 'zero', 'mean', 'knn', 'iter']\n",
    "table0.columns =  list(map(lambda c: f'\\\\texttt{{{c}}}', table0.columns))\n",
    "table0.columns = list(map(lambda c: c.replace(\"_\", \"\\\\_\"), table0.columns))\n",
    "table0.columns.name = 'Imputer'\n",
    "table0 = table0.sort_values('MSE', axis=1, ascending=False)\n",
    "table0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04bdeb24-aca1-4934-9136-db0f902b3a56",
   "metadata": {},
   "source": [
    "table0_stl = (table0.style\n",
    "              # .background_gradient(cmap='RdYlGn', axis=1, low=-0, high=0.5,  vmin=-0.6, vmax=0.3, subset= pd.IndexSlice[[r'MICRO-AVG($R^2$)'], :])\n",
    "              .background_gradient(cmap='RdYlGn_r', axis=1,  low=0.12, high=0.28,  vmin=0.09, vmax=0.19, subset= pd.IndexSlice[['MSE'], :])\n",
    "              # .apply_index(lambda x: [\"background-color: #E5E4E2;\"] * len(x))\n",
    "              .format(precision=3))\n",
    "table0_stl"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5782c68e-3a7c-457e-bbad-43cffba2c227",
   "metadata": {},
   "source": [
    "table0_str = (table0_stl.to_latex(caption=r\"Comparison between imputation methods. The estimations are made on the validation split.\"\n",
    "                                          r\"For the $\\text{MACRO-AVG}(R^2)*$, features with less than $N<300$ in \"\n",
    "                                          r\"the test split are excluded, \"\n",
    "                                          r\"of which some have $-\\infty$ values.\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "              .replace('\\\\toprule', '\\\\hline').replace('\\\\midrule', '\\\\hline').replace('\\\\bottomrule','\\\\hline'))\n",
    "print(table0_str)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7006bcea-ff4e-401b-a2d6-e74f60218fe3",
   "metadata": {},
   "source": [
    "prob_corr_df = all_models_stats_df.loc[all_models_stats_df.Imputer.isin(['ICNN_LN', 'ICNN_NLN', 'ICNN_NKL', 'ICNN_KL']), ['Imputer', r'$r_\\text{Pearson}(SE, \\hat{\\sigma}^2)$', r'$r_\\text{Spearman}(SE, \\hat{\\sigma}^2)$']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54da231a-51c4-4678-ab82-89864c5ae628",
   "metadata": {},
   "source": [
    "table1_stl = (prob_corr_df.style.format(precision=3).hide())\n",
    "table1_str = table1_stl.to_latex(caption=r\"Correlation between predicted Gaussian variance $\\sigma^2$ by \\texttt{ICNN\\_LN} and the prediction \\gls*{se}.\",\n",
    "                       position_float=\"centering\",\n",
    "                       convert_css=True,\n",
    "                       hrules=True,)\n",
    "print(table1_str)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "984420b6-2e64-4b90-8086-19543645ee17",
   "metadata": {},
   "source": [
    "final_models_filtered_features_stats_df = final_models_features_stats_df[final_models_features_stats_df.Feature.isin(vars_n300)]\n",
    "R_bins = final_models_filtered_features_stats_df.groupby(['Imputer', r'$R^2$ bin'])['Feature'].count().reset_index()\n",
    "R_bins.columns = ['Imputer', r'$R^2$ bin', 'Count']\n",
    "R_bins = R_bins.pivot_table(index=\"Imputer\", values='Count', columns=r'$R^2$ bin')\n",
    "\n",
    "R_bins = R_bins[R_classes]\n",
    "R_bins = R_bins.loc[['P-ICNN (NLN)', 'S-ICNN (NMSE)', 'zero_imputer', 'mean_imputer', 'knn_imputer', 'iter_imputer'], :]\n",
    "R_bins.index = ['P-ICNN', 'S-ICNN', 'zero', 'mean', 'knn', 'iter']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "502b2919-f6a1-4c48-aaef-78545cb31d6a",
   "metadata": {},
   "source": [
    "ax = R_bins.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, stacked=True, colormap='RdYlGn_r', ylabel='Features Count')\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 1.2, fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/R2_bins.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4e615a9f-8207-4636-a950-30fe6a913a00",
   "metadata": {},
   "source": [
    "final_models_filtered_features_stats_df"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8b50211b-e3b6-492a-a325-a346499a661a",
   "metadata": {},
   "source": [
    "mse_cols = ['MSE'] + [f'MSE@P{p}' for p in PERCENTILES]\n",
    "mse_cols_rename = {'MSE': 'P100'} | {f'MSE@P{p}': f'P{p}' for p in PERCENTILES}\n",
    "NLN_mse_percentiles = final_models_filtered_features_stats_df.loc[final_models_filtered_features_stats_df.Imputer == 'P-ICNN (NLN)', ['Feature'] + mse_cols]\n",
    "NLN_mse_percentiles = NLN_mse_percentiles.rename(columns=mse_cols_rename)\n",
    "NLN_mse_percentiles.loc[:, mse_cols_rename.values()] = NLN_mse_percentiles.loc[:, mse_cols_rename.values()].apply(lambda c: c * 100 / NLN_mse_percentiles['P100'], axis=0)\n",
    "NLN_mse_percentiles['Feature'] = NLN_mse_percentiles.Feature.map(variable_map)\n",
    "NLN_mse_percentiles = NLN_mse_percentiles.sort_values('Feature')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fe2c2b76-7cdc-4b08-9c3d-4e971c7a7a0d",
   "metadata": {},
   "source": [
    "NLN_mse_percentiles.sort_values('P50').iloc[:15]['Feature']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "cb2d7f0a-99fb-486a-a98b-32bb7ca3585d",
   "metadata": {},
   "source": [
    "import colorcet as cc\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "from bokeh.models import ColumnDataSource, FixedTicker, PrintfTickFormatter, Span\n",
    "from bokeh.plotting import figure, show, curdoc\n",
    "from bokeh.sampledata.perceptions import probly\n",
    "from bokeh.io import output_notebook, export_svgs, export_png\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "def ridge(category, data, scale=20):\n",
    "    return list(zip([category]*len(data), scale*data))\n",
    "\n",
    "percentiles_ = list(mse_cols_rename.values())\n",
    "palette = [cc.rainbow[i*15] for i in range(len(percentiles_))]\n",
    "\n",
    "x = np.linspace(-20, 150, 10000)\n",
    "\n",
    "source = ColumnDataSource(data=dict(x=x))\n",
    "\n",
    "p = figure(y_range=percentiles_[1:], width=650, height=400, \n",
    "           x_range=(-5, 120), \n",
    "           # toolbar_location=None, \n",
    "           output_backend=\"svg\"\n",
    "          )\n",
    "\n",
    "for i, p_i in enumerate(reversed(percentiles_[1:])):\n",
    "    pdf = gaussian_kde(NLN_mse_percentiles[p_i], bw_method=0.08)\n",
    "    y = ridge(p_i, pdf(x))\n",
    "    source.add(y, p_i)\n",
    "    p.patch('x', p_i, color=palette[i], alpha=0.6, line_color=\"black\", source=source)\n",
    "\n",
    "p.add_layout(Span(location=100, dimension='height', line_color='red', line_width=5))\n",
    "\n",
    "# p.y_range.start = '\n",
    "p.outline_line_color = None\n",
    "p.background_fill_color = \"#efefef\"\n",
    "\n",
    "p.xaxis.ticker = FixedTicker(ticks=list(range(0, 110, 10)))\n",
    "p.xaxis.formatter = PrintfTickFormatter(format=\"%d%%\")\n",
    "p.xaxis.axis_label = \"%(Relative MSE)\"\n",
    "p.yaxis.axis_label = r\"\\[\\hat{\\sigma}^2\\]-Percentile (Upper Threshold)\"\n",
    "\n",
    "p.xaxis.axis_label_text_font_size = \"14pt\"\n",
    "p.yaxis.axis_label_text_font_size = \"14pt\"\n",
    "\n",
    "p.xaxis.major_label_text_font_size = \"10pt\"\n",
    "p.yaxis.major_label_text_font_size = \"12pt\"\n",
    "\n",
    "\n",
    "\n",
    "p.ygrid.grid_line_color = None\n",
    "p.xgrid.grid_line_color = \"#dddddd\"\n",
    "p.xgrid.ticker = p.xaxis.ticker\n",
    "\n",
    "# p.axis.minor_tick_line_color = None\n",
    "# p.axis.major_tick_line_color = None\n",
    "# p.axis.axis_line_color = None\n",
    "\n",
    "p.y_range.range_padding = 0.1\n",
    "\n",
    "show(p)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0a8ef826-a2ab-4a9e-ba7e-5b14543758fa",
   "metadata": {},
   "source": [
    "NLN_mse_percentiles"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "552932ad-d5f6-428e-8171-c72d2cdfaac5",
   "metadata": {},
   "source": [
    "from matplotlib import colormaps\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "\n",
    "cmap = colormaps['tab20']\n",
    "grey = colormaps['Greys'](0.5)\n",
    "uncertainty_aware_set = sorted(NLN_mse_percentiles.sort_values('P70').iloc[:7]['Feature'])\n",
    "uncertainty_aware_set_colors = {var: cmap(2*i) for i, var in enumerate(uncertainty_aware_set)}\n",
    "\n",
    "\n",
    "\n",
    "plt.close()\n",
    "plt.gcf().clear()    \n",
    "fig, ax = plt.subplots(figsize=(fig_width_in * 1.5, fig_height_in * 2.5))\n",
    "\n",
    "pd.plotting.parallel_coordinates(NLN_mse_percentiles[~NLN_mse_percentiles.Feature.isin(uncertainty_aware_set)], \n",
    "                                      class_column='Feature', color='grey', linewidth=0.2)\n",
    "pd.plotting.parallel_coordinates(NLN_mse_percentiles[NLN_mse_percentiles.Feature.isin(uncertainty_aware_set)], \n",
    "                                      class_column='Feature', color=uncertainty_aware_set_colors.values(),\n",
    "                                linewidth=2,\n",
    "                                path_effects=[pe.Stroke(linewidth=2.5, foreground='black'), pe.Normal()])\n",
    "\n",
    "# remove the pandas legend\n",
    "plt.gca().legend_.remove()\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 110)\n",
    "plt.xlabel(r\"$\\hat{\\sigma}^2$-Percentile (Upper Threshold)\")\n",
    "plt.ylabel(\"%(Relative MSE)\")\n",
    "# plt.title(\"Highlighted Uncertainty-Aware Dimensions\")\n",
    "\n",
    "# add new legend\n",
    "# topHandle =    mlines.Line2D([],[], color='red',   ls=\"-\", label=\"Best\")\n",
    "# midHandleOne = mlines.Line2D([],[], color='blue',  ls=\"-\", label=\"Next Best\")\n",
    "# lowHandle =    mlines.Line2D([],[], color='black', ls=\"-\", label=\"Worst\")\n",
    "plt.legend(handles=[Line2D([],[], color=c,  \n",
    "                           ls=\"-\", label=var, lw=4)  for var, c in uncertainty_aware_set_colors.items()],\n",
    "           loc='upper left', bbox_to_anchor=(1, 1),\n",
    "           prop={'size':10})\n",
    "\n",
    "plt.gcf().set_size_inches(fig_width_in * 1.1, fig_height_in * 2)\n",
    "\n",
    "\n",
    "plt.savefig(f\"{RESULTS_DIR}/LNL_uncertainty_thresholds.pdf\")\n",
    "plt.show()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cb42ab6f-1736-491d-abc0-bdf1d5e572d4",
   "metadata": {},
   "source": [
    "var_map_r = {label: feature for feature, label in variable_map.items()}\n",
    "\n",
    "NLN_mse_percentiles.sort_values('P50').iloc[:15]['Feature'].map(var_map_r).tolist()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "94e26d7e-4cd8-4232-abfe-153db8be1cf3",
   "metadata": {},
   "source": [
    "\n",
    "all_models_features_stats_df[((all_models_features_stats_df.Imputer == 'ICNN_NLN') & \n",
    "                             (all_models_features_stats_df[r'$r(SE, \\hat{\\sigma}^2)$ bin'].isin(r_classes[:1])))\n",
    "]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "8d7e17d4-8960-4918-85ff-b0ff279052c2",
   "metadata": {},
   "source": [
    "NLN_X_var_stats_df = prob_models_X_var_stats_df[prob_models_X_var_stats_df.Imputer == 'ICNN_NLN'].copy()\n",
    "NLN_X_var_stats_df[\"log(SE)\"] = np.log(NLN_X_var_stats_df[\"SE\"])\n",
    "NLN_X_var_stats_df[r'$\\log{\\hat{\\sigma}^2}$'] = np.log(NLN_X_var_stats_df[r'$\\hat{\\sigma}^2$'])\n",
    "\n",
    "NLN_X_var_stats_VARS = ['enzymes.ck_mb', # 0\n",
    "                        'enzymes.bilirubin_indirect',\n",
    "                        'enzymes.ck_cpk',  # 2\n",
    "                        'inflammation.crp',\n",
    "                        'blood_chemistry.sodium',\n",
    "                       'blood_gas.ph',\n",
    "                         'vital.glucose',\n",
    "                         'enzymes.ast',\n",
    "                         'cbc.mchc',\n",
    "                         'renal_aki.aki_stage_smoothed',\n",
    "                         'cardiac_marker.ck_mb', # 10\n",
    "                         'enzymes.alt',\n",
    "                         'blood_gas.fio2_chartevents',\n",
    "                         'blood_gas.totalco2',\n",
    "                         'renal_out.uo_rt_24hr',\n",
    "                         'cardiac_marker.troponin_t2']\n",
    "\n",
    "p = sns.regplot(data=NLN_X_var_stats_df[NLN_X_var_stats_df.Feature == NLN_X_var_stats_VARS[0]], \n",
    "            y=\"log(SE)\", x=r'$\\log{\\hat{\\sigma}^2}$',\n",
    "            # y=\"SE\", x=r'$\\hat{\\sigma}^2$',\n",
    "\n",
    "             x_bins=np.arange(-5, -0, 0.25), \n",
    "            # x_estimator=np.median,\n",
    "            order=1,\n",
    "            # lowess=True,\n",
    "               ci=95, \n",
    "            marker=\"x\", color=\".3\", \n",
    "                line_kws=dict(color=\"r\"),\n",
    ")\n",
    "p.set_ylabel(r'$\\log{(z - \\hat{\\mu})^2}$')\n",
    "\n",
    "p.get_figure().set_size_inches(fig_width_in * 0.5, fig_height_in * 2)\n",
    "p.get_figure().savefig(f\"{RESULTS_DIR}/LNL_se_var_ck_mb.pdf\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "de6138b6-0d43-4f6f-b3f7-1a8805b57cbf",
   "metadata": {},
   "source": [
    "all_models_features_stats_df.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e09bb7e3-732b-4462-b405-5aa658363c5d",
   "metadata": {},
   "source": [
    "all_models_features_stats_df[all_models_features_stats_df.Imputer == 'ICNN_NLN'].set_index('Feature')[[r'$r_\\text{Log-Pearson}(SE, \\hat{\\sigma}^2)$', 'Imputer']].loc[NLN_X_var_stats_VARS[0]]#.sort_values(ascending=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "42d26b00-4ee8-49f9-bb16-c3f73c7ccc26",
   "metadata": {},
   "source": [
    "NLN_X_var_stats_df[NLN_X_var_stats_df.Feature == NLN_X_var_stats_VARS[0]].shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "dbdf8511-9e08-46dc-aefc-5b2fdd447016",
   "metadata": {},
   "source": [
    "np.arange(-12, -1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3e603b-3587-4c72-8d6c-d481ff295d09",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1eaf8e26-f3ef-4f2c-b7d7-0ebef4ef1959",
   "metadata": {},
   "source": [
    "# final_models_filtered_features_stats_df.columns\n",
    "r2_bin_cols = [r'$R^2$ bin'] + [fr'$R^2@P{p}$ bin' for p in PERCENTILES]\n",
    "# r2_bin_cols_rename = {'MSE': 'P100'} | {f'MSE@P{p}': f'P{p}' for p in PERCENTILES}\n",
    "NLN_R2_bins_percentiles = final_models_filtered_features_stats_df.loc[final_models_filtered_features_stats_df.Imputer == 'P-ICNN (NLN)', ['Feature'] + r2_bin_cols]\n",
    "NLN_R2_bins_percentiles = NLN_R2_bins_percentiles.set_index('Feature')\n",
    "NLN_R2_bins_dist_percentiles = {col: NLN_R2_bins_percentiles.groupby(col)[col].count() for col in r2_bin_cols}\n",
    "NLN_R2_bins_dist_percentiles = pd.DataFrame(NLN_R2_bins_dist_percentiles)[[r2_bin_cols[0], r2_bin_cols[6]]].transpose()\n",
    "NLN_R2_bins_dist_percentiles = NLN_R2_bins_dist_percentiles[R_classes]\n",
    "ax = NLN_R2_bins_dist_percentiles.iloc[:, :].plot(y=R_classes, kind=\"bar\", rot=0, \n",
    "                                                  stacked=True, colormap='RdYlGn_r', ylabel='Features Count', width=0.5)\n",
    "_ = ax.legend(bbox_to_anchor=(1, 1.02), loc='upper left')\n",
    "ax.get_figure().set_size_inches(fig_width_in * 0.8 , fig_height_in * 2)\n",
    "ax.get_figure().savefig(f\"{RESULTS_DIR}/NLN_R2_bins_percentiles.pdf\")\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6943ed17-35b1-497c-81d9-c05dbfd9afe8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637b0212-376c-400d-a205-c786ab607e8a",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
